{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter2.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supurazako/ml-security-jp/blob/master/ch02/Chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ivcg5OTwyTo"
      },
      "source": [
        "![表紙](https://www.oreilly.co.jp/books/images/picture978-4-87311-907-6.gif)\n",
        "\n",
        "このノートブックはオライリー・ジャパンより発行の書籍[『セキュリティエンジニアのための機械学習』](https://www.oreilly.co.jp/books/9784873119076/)のサンプルコードです。コードの解説等は書籍をご参照ください。なお、このコードを動作させた結果について、著者およびオライリー・ジャパンは一切の責任を負いません。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(for my information)\n",
        "\n",
        "## 夏休みの宿題\n",
        "\n",
        "L1: 練習問題を動かす\n",
        "\n",
        "L2: ノートを完成させる\n",
        "\n",
        "L3: Scikit-learnのドキュメントを読んでみる(今回使ったやつが何しているのか)"
      ],
      "metadata": {
        "id": "uqW4-zS0kcr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## フィッシングサイト\n",
        "\n",
        "- 正規のサイトを偽装するサイト。例えば `goog\"I\"e.com` や様々なものがある\n",
        "- null終端のバグを使ってサイトを詐称するケースなどがあった\n",
        "  - これは少し違うケースだが、null byteを使っている証明書に関連したCVEなど、null byteに関わる脆弱性は多い\n",
        "    - 参照: https://nvd.nist.gov/vuln/detail/CVE-2009-2510"
      ],
      "metadata": {
        "id": "-9zvn_F-UhfH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU0KMWs5x3Z6"
      },
      "source": [
        "##ロジスティック回帰を使用したフィッシング検出器"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ロジスティック回帰とは\n",
        "\n",
        "ロジスティック回帰は、二項分類を行うためによく使われる、手法である。\n",
        "後述する決定木を用いた手法よりも昔からある。機械学習の歴史では、割と古めらしい。\n",
        "\n",
        "## データセットについて\n",
        "\n",
        "UCI Machine Learning Repositoryのフィッシングサイトのデータセットを使用している。(https://archive.ics.uci.edu/ml/datasets/Phishing+Websites)\n",
        "\n",
        "このデータセットはarff形式である。arff形式は、昔はデータサイエンスでよく使われていた。Pythonなどを用いた最近のデータサイエンスではあまり使われない。\n",
        "\n",
        "今回は、用意してある csv形式のデータを使わせていただく。"
      ],
      "metadata": {
        "id": "8x03lwdFj1UE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnfDbq4x8kAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1a13c7-285a-4245-edc0-c7e89ec8e289"
      },
      "source": [
        "!wget https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/dataset.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-15 09:06:34--  https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/dataset.csv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/dataset.csv [following]\n",
            "--2025-07-15 09:06:34--  https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788720 (770K) [text/plain]\n",
            "Saving to: ‘dataset.csv’\n",
            "\n",
            "dataset.csv         100%[===================>] 770.23K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-15 09:06:34 (20.6 MB/s) - ‘dataset.csv’ saved [788720/788720]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7hYR1Y2Ripa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acceae31-51c0-42f9-dab9-84ab41520bc9"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## メモ\n",
        "\n",
        "sklearn -> scikit learn,\n",
        "ML用のモジュール(なんでもいり,でっかい)\n",
        "\n",
        "https://scikit-learn.org/stable/\n",
        "\n",
        "## 2値分類\n",
        "\n",
        "- 2つの領域に分ける\n",
        "- true/falseの判定をする\n",
        "\n",
        "今回でいうと、スパムメールで {ある/ない} などの判定を行う\n",
        "\n"
      ],
      "metadata": {
        "id": "I-6qd8lkV3ad"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwRGDVT7mYeh"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "training_data = np.genfromtxt('dataset.csv', delimiter=',', dtype=np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このまますべてのデータを学習させると、テスト用のデータがなくなってしまう。\n",
        "学習モデルを評価するには、未知のデータが必要だからだ。\n",
        "\n",
        "なので、ここでは学習用に0.2(2割)を割り当てている。\n",
        "このようなデータセットを学習用と評価用に分割し、学習モデルの性能を評価する方法を **ホールドアウト検証** (Hold-out Validatoin)と呼ぶ。"
      ],
      "metadata": {
        "id": "ZvVSo0oEXrLk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aTvRm9-gAXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55e37cc-5c0a-4d4d-c871-37799fb28f61"
      },
      "source": [
        "X = training_data[:,:-1]\n",
        "y = training_data[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, random_state=101)\n",
        "\n",
        "classifier = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "# 訓練用データを使って検出器を訓練する。\n",
        "classifier.fit(X_train, y_train)\n",
        "# 予測させる。\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# このフィッシング検出器の正解率を出力させる。\n",
        "accuracy = 100.0 * accuracy_score(y_test, predictions)\n",
        "print(\"The accuracy of your Logistic Regression on testing data is: {}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of your Logistic Regression on testing data is: 92.17548620533695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 交差検証\n",
        "\n",
        "データを分割し、一部分を学習に使い、残りでテストを行う。←これを分割数の数だけやる\n",
        "\n",
        "ホールドアウト検証と違う点は、3分割以上するという点にある。これにより、どの部分を学習すると一番精度が高いかを検証することが可能になる\n",
        "\n",
        "今回は5分割でやる"
      ],
      "metadata": {
        "id": "X6OXV6mDY9uF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTAgzVwU7G47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b0c6b8-7d70-4191-b22b-175cabe5df6f"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 交差検証(5分割)による汎化性能の評価\n",
        "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
        "# 評価結果の出力\n",
        "print(\"Evaluated score by cross-validation(k=5): {}\".format(100 * scores.mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated score by cross-validation(k=5): 92.8766156199402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータとは\n",
        "\n",
        "ここまでは、データの並び替えはほぼやっていない。データ項目の中でどれが一番効いてくるかは、これまでは経験と勘でやっていた。どの順番で見ると精度が一番上がるかな〜と考えるのがハイパーパラメータチューニングというもの。\n",
        "\n",
        "このパラメータは、機械学習モデルの\"外側\"から調整する。ゆえに、\"ハイパー\"パラメータである。\n",
        "\n",
        "ハイパーパラメータチューニングには、主に「手動で調整する」と「チューニングツールを使用する」という2つの方法がある。手動で調整するのは、速いが経験や勘などが必要で、属人性が高くなってしまう。\n",
        "\n",
        "チューニングツールには、scikit-learnのGridSearchCVがある。しかし、この方法は総当たりなので、効率が悪め。そのため、今回はPreferred Newworksのoptunaを使用する。\n",
        "\n",
        "備考: 今回は時間の節約のため、3つのパラメータに絞って探索を行っている"
      ],
      "metadata": {
        "id": "c9dZ0V_vZsp2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7kMWWXyxlQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20fc2bd-7abd-492a-9cf3-517a1fee3bd9",
        "collapsed": true
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "class Objective:\n",
        "    def __init__(self, X, y):\n",
        "        # 変数X,yの初期化\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        # ターゲットのハイパーパラメータの設定\n",
        "        params = {\n",
        "            # 最適化に使用するアルゴリズムの候補をカテゴリとして指定\n",
        "            'solver' : trial.suggest_categorical('solver',\\\n",
        "                    ['newton-cg', 'lbfgs', \\\n",
        "                    'liblinear', 'sag', 'saga']),\n",
        "            # 正則化の強さに0.0001から10までを指定\n",
        "            'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
        "            # ソルバーが収束するまでの最大反復回数\n",
        "            'max_iter': trial.suggest_int('max_iter', 100, 100000)\n",
        "            }\n",
        "\n",
        "        model = LogisticRegression(**params)\n",
        "\n",
        "        # 評価指標として正解率の最大化を目指す\n",
        "        scores = cross_validate(model,\n",
        "                                X=self.X, y=self.y,\n",
        "                                scoring='accuracy',\n",
        "                                n_jobs=-1)\n",
        "        return scores['test_score'].mean()\n",
        "\n",
        "# ハイパーパラメータの探索\n",
        "objective = Objective(X_train, y_train)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, timeout=60)\n",
        "# ベストのパラメータの出力\n",
        "print('params:', study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-15 09:33:21,508] A new study created in memory with name: no-name-598dcb3a-2b0b-4022-bcf0-2410958182db\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:23,753] Trial 0 finished with value: 0.9288792144243878 and parameters: {'solver': 'newton-cg', 'C': 0.8499863977671922, 'max_iter': 30204}. Best is trial 0 with value: 0.9288792144243878.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:24,192] Trial 1 finished with value: 0.9286530979744161 and parameters: {'solver': 'liblinear', 'C': 0.6580136808930991, 'max_iter': 59847}. Best is trial 0 with value: 0.9288792144243878.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:24,483] Trial 2 finished with value: 0.9285400397494303 and parameters: {'solver': 'lbfgs', 'C': 1.6804976036082802, 'max_iter': 95633}. Best is trial 0 with value: 0.9288792144243878.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:24,781] Trial 3 finished with value: 0.9286530979744161 and parameters: {'solver': 'lbfgs', 'C': 1.2895046716283747, 'max_iter': 68691}. Best is trial 0 with value: 0.9288792144243878.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:25,892] Trial 4 finished with value: 0.9288792144243878 and parameters: {'solver': 'saga', 'C': 1.0283133855526083, 'max_iter': 35916}. Best is trial 0 with value: 0.9288792144243878.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:26,122] Trial 5 finished with value: 0.9292185169932651 and parameters: {'solver': 'newton-cg', 'C': 0.19832151350195928, 'max_iter': 83317}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:26,695] Trial 6 finished with value: 0.9287662201463618 and parameters: {'solver': 'sag', 'C': 0.3946443423730189, 'max_iter': 30024}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:26,913] Trial 7 finished with value: 0.928087678955567 and parameters: {'solver': 'newton-cg', 'C': 0.021335997137870974, 'max_iter': 93207}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:27,402] Trial 8 finished with value: 0.9292185169932651 and parameters: {'solver': 'sag', 'C': 0.20820044222411893, 'max_iter': 3884}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:27,949] Trial 9 finished with value: 0.9286531619213759 and parameters: {'solver': 'sag', 'C': 0.2943504179347028, 'max_iter': 33421}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:28,147] Trial 10 finished with value: 0.9133880634046896 and parameters: {'solver': 'newton-cg', 'C': 0.0007267318007988917, 'max_iter': 78273}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:28,495] Trial 11 finished with value: 0.9285399758024704 and parameters: {'solver': 'sag', 'C': 0.022717152980371667, 'max_iter': 3703}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:30,913] Trial 12 finished with value: 0.9280878068494868 and parameters: {'solver': 'saga', 'C': 8.962032839450687, 'max_iter': 2689}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:31,140] Trial 13 finished with value: 0.9194938470235249 and parameters: {'solver': 'liblinear', 'C': 0.002236092033376893, 'max_iter': 14889}. Best is trial 5 with value: 0.9292185169932651.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:31,378] Trial 14 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.10243003919347543, 'max_iter': 51682}. Best is trial 14 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:31,610] Trial 15 finished with value: 0.9296707498932086 and parameters: {'solver': 'newton-cg', 'C': 0.07117304948266154, 'max_iter': 53751}. Best is trial 14 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:31,817] Trial 16 finished with value: 0.9229990996268056 and parameters: {'solver': 'newton-cg', 'C': 0.004759935071536981, 'max_iter': 49209}. Best is trial 14 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:32,004] Trial 17 finished with value: 0.8839895357194928 and parameters: {'solver': 'newton-cg', 'C': 0.0001467838236119129, 'max_iter': 49358}. Best is trial 14 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:32,236] Trial 18 finished with value: 0.9300099245681661 and parameters: {'solver': 'newton-cg', 'C': 0.08229160332329796, 'max_iter': 62696}. Best is trial 14 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:32,475] Trial 19 finished with value: 0.9291055227152392 and parameters: {'solver': 'newton-cg', 'C': 0.05277503277380431, 'max_iter': 67549}. Best is trial 14 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:32,913] Trial 20 finished with value: 0.9242429958894893 and parameters: {'solver': 'saga', 'C': 0.007939265357055093, 'max_iter': 41792}. Best is trial 14 with value: 0.9301230467401119.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:33,141] Trial 21 finished with value: 0.9303491631900837 and parameters: {'solver': 'newton-cg', 'C': 0.09297420667712418, 'max_iter': 63018}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:33,377] Trial 22 finished with value: 0.9298968663431804 and parameters: {'solver': 'newton-cg', 'C': 0.07707608238030333, 'max_iter': 60281}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:33,594] Trial 23 finished with value: 0.9260521832771026 and parameters: {'solver': 'newton-cg', 'C': 0.013310562133636955, 'max_iter': 72527}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:33,821] Trial 24 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.10305967739994445, 'max_iter': 60613}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:34,220] Trial 25 finished with value: 0.9285399758024704 and parameters: {'solver': 'liblinear', 'C': 3.85706399547239, 'max_iter': 42787}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:34,437] Trial 26 finished with value: 0.9297839360121142 and parameters: {'solver': 'lbfgs', 'C': 0.14406341831583402, 'max_iter': 84255}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:34,656] Trial 27 finished with value: 0.9295577556151825 and parameters: {'solver': 'newton-cg', 'C': 0.03772636546449946, 'max_iter': 55654}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:34,859] Trial 28 finished with value: 0.9215290869141499 and parameters: {'solver': 'newton-cg', 'C': 0.002906250257057585, 'max_iter': 21696}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:35,088] Trial 29 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.12379379969920594, 'max_iter': 75276}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:35,346] Trial 30 finished with value: 0.9292185169932651 and parameters: {'solver': 'newton-cg', 'C': 0.5559052052531039, 'max_iter': 45005}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:35,573] Trial 31 finished with value: 0.9300099245681661 and parameters: {'solver': 'newton-cg', 'C': 0.07923872421471873, 'max_iter': 63089}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:35,854] Trial 32 finished with value: 0.9289923365963336 and parameters: {'solver': 'newton-cg', 'C': 0.027034684830800647, 'max_iter': 64328}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:36,102] Trial 33 finished with value: 0.925938997158197 and parameters: {'solver': 'liblinear', 'C': 0.014347735686901262, 'max_iter': 55657}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:36,399] Trial 34 finished with value: 0.9289923365963336 and parameters: {'solver': 'lbfgs', 'C': 0.5105872323498183, 'max_iter': 58847}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:36,686] Trial 35 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1287208464965237, 'max_iter': 69985}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:38,098] Trial 36 finished with value: 0.9286530979744161 and parameters: {'solver': 'saga', 'C': 1.7495444520676777, 'max_iter': 87761}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:38,349] Trial 37 finished with value: 0.9289922726493737 and parameters: {'solver': 'lbfgs', 'C': 0.9101082048863587, 'max_iter': 79106}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:38,602] Trial 38 finished with value: 0.929218580940225 and parameters: {'solver': 'newton-cg', 'C': 0.042651655092009313, 'max_iter': 63955}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:38,863] Trial 39 finished with value: 0.9288793423183075 and parameters: {'solver': 'newton-cg', 'C': 0.2534660120143006, 'max_iter': 39347}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:39,170] Trial 40 finished with value: 0.9297839360121142 and parameters: {'solver': 'liblinear', 'C': 0.10615672163374687, 'max_iter': 48093}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:39,420] Trial 41 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.06503943074201951, 'max_iter': 63108}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:39,679] Trial 42 finished with value: 0.9286531619213759 and parameters: {'solver': 'newton-cg', 'C': 0.3103759519108672, 'max_iter': 52820}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:39,919] Trial 43 finished with value: 0.9295578195621423 and parameters: {'solver': 'newton-cg', 'C': 0.1816958795589089, 'max_iter': 67594}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:40,291] Trial 44 finished with value: 0.9267306605209376 and parameters: {'solver': 'sag', 'C': 0.015747882886758418, 'max_iter': 60378}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:40,527] Trial 45 finished with value: 0.9293316391652107 and parameters: {'solver': 'newton-cg', 'C': 0.03419019887967943, 'max_iter': 74293}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:40,766] Trial 46 finished with value: 0.930122982793152 and parameters: {'solver': 'newton-cg', 'C': 0.08490218961364585, 'max_iter': 28032}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:41,028] Trial 47 finished with value: 0.9287662201463618 and parameters: {'solver': 'newton-cg', 'C': 0.40767325901500917, 'max_iter': 28995}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:41,470] Trial 48 finished with value: 0.9233385300896024 and parameters: {'solver': 'saga', 'C': 0.006632029479134054, 'max_iter': 8745}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:42,193] Trial 49 finished with value: 0.9285400397494301 and parameters: {'solver': 'sag', 'C': 2.05644874808199, 'max_iter': 26837}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:42,445] Trial 50 finished with value: 0.9291054587682792 and parameters: {'solver': 'newton-cg', 'C': 0.2178117875976205, 'max_iter': 34711}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:42,686] Trial 51 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.10692808742787252, 'max_iter': 57638}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:42,927] Trial 52 finished with value: 0.930122982793152 and parameters: {'solver': 'newton-cg', 'C': 0.08353599992607737, 'max_iter': 51983}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:43,170] Trial 53 finished with value: 0.9291055227152392 and parameters: {'solver': 'newton-cg', 'C': 0.05340071113653022, 'max_iter': 50204}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:43,411] Trial 54 finished with value: 0.9285399758024704 and parameters: {'solver': 'newton-cg', 'C': 0.022529693583403076, 'max_iter': 53523}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:43,652] Trial 55 finished with value: 0.9300099245681661 and parameters: {'solver': 'newton-cg', 'C': 0.07849852389388229, 'max_iter': 37958}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:43,874] Trial 56 finished with value: 0.9295578195621423 and parameters: {'solver': 'lbfgs', 'C': 0.17568354015576654, 'max_iter': 45860}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:44,140] Trial 57 finished with value: 0.9286531619213759 and parameters: {'solver': 'newton-cg', 'C': 0.3064650103206672, 'max_iter': 20983}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:44,381] Trial 58 finished with value: 0.9297839999590739 and parameters: {'solver': 'newton-cg', 'C': 0.03602733557901164, 'max_iter': 52700}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:45,034] Trial 59 finished with value: 0.9291054587682792 and parameters: {'solver': 'saga', 'C': 0.690737186899812, 'max_iter': 70106}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:45,475] Trial 60 finished with value: 0.9300099245681661 and parameters: {'solver': 'sag', 'C': 0.08138328121134168, 'max_iter': 42678}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:45,713] Trial 61 finished with value: 0.9293316391652109 and parameters: {'solver': 'newton-cg', 'C': 0.054182932686998864, 'max_iter': 62681}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:45,954] Trial 62 finished with value: 0.9303491631900837 and parameters: {'solver': 'newton-cg', 'C': 0.09653666381724617, 'max_iter': 66327}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:46,200] Trial 63 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.14845522457303065, 'max_iter': 66365}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:46,447] Trial 64 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.10240087642342763, 'max_iter': 57346}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:46,688] Trial 65 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.10104850268846448, 'max_iter': 57169}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:46,962] Trial 66 finished with value: 0.9278613706647159 and parameters: {'solver': 'liblinear', 'C': 0.018866783473321064, 'max_iter': 58738}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:47,233] Trial 67 finished with value: 0.9288792783713478 and parameters: {'solver': 'newton-cg', 'C': 0.42347783888368296, 'max_iter': 77811}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:47,467] Trial 68 finished with value: 0.9250344674113504 and parameters: {'solver': 'newton-cg', 'C': 0.010282842120424733, 'max_iter': 57166}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:47,708] Trial 69 finished with value: 0.929218580940225 and parameters: {'solver': 'newton-cg', 'C': 0.049800833606789593, 'max_iter': 71026}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:47,973] Trial 70 finished with value: 0.9292185809402248 and parameters: {'solver': 'newton-cg', 'C': 0.03136430334842012, 'max_iter': 48294}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:48,253] Trial 71 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.09048782515747164, 'max_iter': 60440}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:48,569] Trial 72 finished with value: 0.9297838720651542 and parameters: {'solver': 'newton-cg', 'C': 0.11025962796388611, 'max_iter': 66075}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:48,878] Trial 73 finished with value: 0.9291054587682792 and parameters: {'solver': 'newton-cg', 'C': 0.22172533352447632, 'max_iter': 55434}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:49,184] Trial 74 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.11861315710902404, 'max_iter': 45380}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:49,425] Trial 75 finished with value: 0.9033249221765498 and parameters: {'solver': 'lbfgs', 'C': 0.0002608434861812749, 'max_iter': 61527}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:49,722] Trial 76 finished with value: 0.9296708777871283 and parameters: {'solver': 'newton-cg', 'C': 0.16916169648419177, 'max_iter': 60066}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:50,103] Trial 77 finished with value: 0.9291054587682792 and parameters: {'solver': 'liblinear', 'C': 0.06615080027008097, 'max_iter': 55377}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:50,370] Trial 78 finished with value: 0.9288793423183075 and parameters: {'solver': 'newton-cg', 'C': 0.26401004989711135, 'max_iter': 73156}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:50,615] Trial 79 finished with value: 0.9289923365963336 and parameters: {'solver': 'newton-cg', 'C': 0.02736241092645696, 'max_iter': 66175}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:51,038] Trial 80 finished with value: 0.9291055227152392 and parameters: {'solver': 'saga', 'C': 0.0434461011891528, 'max_iter': 50647}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:51,281] Trial 81 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.10062683951716918, 'max_iter': 51519}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:51,544] Trial 82 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.0902463548051695, 'max_iter': 57562}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:51,785] Trial 83 finished with value: 0.9297839360121142 and parameters: {'solver': 'newton-cg', 'C': 0.155838224398049, 'max_iter': 56837}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:52,031] Trial 84 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.10285860124652949, 'max_iter': 60325}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:52,277] Trial 85 finished with value: 0.9294446973901968 and parameters: {'solver': 'newton-cg', 'C': 0.056568333060985, 'max_iter': 68758}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:52,880] Trial 86 finished with value: 0.9286531619213759 and parameters: {'solver': 'sag', 'C': 0.3438760714455341, 'max_iter': 64679}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:53,124] Trial 87 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1270851913019754, 'max_iter': 61120}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:53,397] Trial 88 finished with value: 0.9291054587682792 and parameters: {'solver': 'newton-cg', 'C': 0.22590041777322523, 'max_iter': 53898}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:53,661] Trial 89 finished with value: 0.929218580940225 and parameters: {'solver': 'newton-cg', 'C': 0.04180473305749317, 'max_iter': 46252}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:53,906] Trial 90 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.10664267957654457, 'max_iter': 59498}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:54,150] Trial 91 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.06311491789710053, 'max_iter': 60047}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:54,397] Trial 92 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1480464604685643, 'max_iter': 50596}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:54,650] Trial 93 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.10081936198984931, 'max_iter': 64532}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:54,904] Trial 94 finished with value: 0.9292185169932651 and parameters: {'solver': 'newton-cg', 'C': 0.1958096592175356, 'max_iter': 54568}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:55,127] Trial 95 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.10475062542577858, 'max_iter': 59081}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:55,349] Trial 96 finished with value: 0.9297839360121142 and parameters: {'solver': 'lbfgs', 'C': 0.14152278572426355, 'max_iter': 76426}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:55,576] Trial 97 finished with value: 0.9289923365963336 and parameters: {'solver': 'lbfgs', 'C': 0.48193623174251404, 'max_iter': 51805}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:55,798] Trial 98 finished with value: 0.9285401036963901 and parameters: {'solver': 'lbfgs', 'C': 0.26443739659618726, 'max_iter': 99194}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:56,042] Trial 99 finished with value: 0.9298969302901401 and parameters: {'solver': 'lbfgs', 'C': 0.0637042065861339, 'max_iter': 62299}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:56,334] Trial 100 finished with value: 0.9297839360121142 and parameters: {'solver': 'liblinear', 'C': 0.105228433980426, 'max_iter': 68390}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:56,578] Trial 101 finished with value: 0.9303491631900837 and parameters: {'solver': 'newton-cg', 'C': 0.09542234072210645, 'max_iter': 59463}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:56,821] Trial 102 finished with value: 0.9293317031121706 and parameters: {'solver': 'newton-cg', 'C': 0.04627129972430941, 'max_iter': 58378}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:57,067] Trial 103 finished with value: 0.9298968663431804 and parameters: {'solver': 'newton-cg', 'C': 0.0747151776507948, 'max_iter': 48036}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:57,309] Trial 104 finished with value: 0.929218580940225 and parameters: {'solver': 'lbfgs', 'C': 0.19282377805273881, 'max_iter': 56601}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:57,547] Trial 105 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1257325009758688, 'max_iter': 65180}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:58,069] Trial 106 finished with value: 0.9286531619213759 and parameters: {'solver': 'saga', 'C': 0.32379589156197663, 'max_iter': 54252}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:58,302] Trial 107 finished with value: 0.9292185809402248 and parameters: {'solver': 'newton-cg', 'C': 0.030496636443923746, 'max_iter': 62828}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:58,716] Trial 108 finished with value: 0.9297838081181945 and parameters: {'solver': 'sag', 'C': 0.07246494729059016, 'max_iter': 71563}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:58,960] Trial 109 finished with value: 0.9301230467401119 and parameters: {'solver': 'newton-cg', 'C': 0.10126163270494176, 'max_iter': 58854}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:59,197] Trial 110 finished with value: 0.9297839999590739 and parameters: {'solver': 'newton-cg', 'C': 0.03636353140082722, 'max_iter': 67938}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:59,433] Trial 111 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.09946843872265651, 'max_iter': 61808}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:59,676] Trial 112 finished with value: 0.9296708777871283 and parameters: {'solver': 'newton-cg', 'C': 0.16600366080318577, 'max_iter': 60790}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:33:59,913] Trial 113 finished with value: 0.9294446973901968 and parameters: {'solver': 'newton-cg', 'C': 0.0553921610712898, 'max_iter': 56517}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:00,181] Trial 114 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.1277426652771748, 'max_iter': 52445}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:00,473] Trial 115 finished with value: 0.930122982793152 and parameters: {'solver': 'newton-cg', 'C': 0.08327205878055617, 'max_iter': 63843}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:00,735] Trial 116 finished with value: 0.916554013439093 and parameters: {'solver': 'newton-cg', 'C': 0.0010573015279289944, 'max_iter': 58881}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:01,049] Trial 117 finished with value: 0.9291054587682792 and parameters: {'solver': 'newton-cg', 'C': 0.22162121913042881, 'max_iter': 48636}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:01,348] Trial 118 finished with value: 0.9285399758024704 and parameters: {'solver': 'newton-cg', 'C': 0.02222905791035181, 'max_iter': 62006}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:01,618] Trial 119 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.0970645398447325, 'max_iter': 66911}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:01,905] Trial 120 finished with value: 0.9297838720651542 and parameters: {'solver': 'lbfgs', 'C': 0.06802887332636032, 'max_iter': 69989}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:02,204] Trial 121 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.09713567400399138, 'max_iter': 66216}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:02,435] Trial 122 finished with value: 0.9296708777871283 and parameters: {'solver': 'lbfgs', 'C': 0.16257409673584577, 'max_iter': 65711}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:02,652] Trial 123 finished with value: 0.9293316391652109 and parameters: {'solver': 'lbfgs', 'C': 0.048548658533071824, 'max_iter': 80711}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:02,876] Trial 124 finished with value: 0.9303491631900837 and parameters: {'solver': 'lbfgs', 'C': 0.10162344023997642, 'max_iter': 67726}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:03,117] Trial 125 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.12604387067305275, 'max_iter': 74154}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:03,341] Trial 126 finished with value: 0.9300099245681661 and parameters: {'solver': 'lbfgs', 'C': 0.08246294331782904, 'max_iter': 66874}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:03,558] Trial 127 finished with value: 0.9295577556151825 and parameters: {'solver': 'lbfgs', 'C': 0.06266722133312676, 'max_iter': 72096}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:03,784] Trial 128 finished with value: 0.9295578195621423 and parameters: {'solver': 'lbfgs', 'C': 0.17530424509757742, 'max_iter': 69043}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:04,022] Trial 129 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.10034282456255282, 'max_iter': 63833}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:04,254] Trial 130 finished with value: 0.9301230467401119 and parameters: {'solver': 'lbfgs', 'C': 0.09250526653632742, 'max_iter': 66585}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:04,483] Trial 131 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.12694037983727757, 'max_iter': 64134}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:04,707] Trial 132 finished with value: 0.9298969302901401 and parameters: {'solver': 'lbfgs', 'C': 0.10883479823644761, 'max_iter': 61370}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:04,925] Trial 133 finished with value: 0.9288794062652673 and parameters: {'solver': 'lbfgs', 'C': 0.051973261178468524, 'max_iter': 62772}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:05,149] Trial 134 finished with value: 0.9298969302901401 and parameters: {'solver': 'lbfgs', 'C': 0.07256763969106315, 'max_iter': 67884}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:05,380] Trial 135 finished with value: 0.9285401036963901 and parameters: {'solver': 'lbfgs', 'C': 0.26410905048504274, 'max_iter': 59605}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:05,607] Trial 136 finished with value: 0.9297839360121142 and parameters: {'solver': 'lbfgs', 'C': 0.1432870009030563, 'max_iter': 65083}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:05,820] Trial 137 finished with value: 0.9294446973901966 and parameters: {'solver': 'lbfgs', 'C': 0.03908080902410551, 'max_iter': 71507}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:06,167] Trial 138 finished with value: 0.9296708138401684 and parameters: {'solver': 'liblinear', 'C': 0.20303634200342874, 'max_iter': 69506}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:06,407] Trial 139 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.09282650596476659, 'max_iter': 63065}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:06,626] Trial 140 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.08943625728139296, 'max_iter': 63150}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:06,845] Trial 141 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.09434501648250869, 'max_iter': 63387}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:07,074] Trial 142 finished with value: 0.9296708138401684 and parameters: {'solver': 'lbfgs', 'C': 0.06105637732191755, 'max_iter': 60500}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:07,295] Trial 143 finished with value: 0.9298968663431804 and parameters: {'solver': 'lbfgs', 'C': 0.08095254315118816, 'max_iter': 67078}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:07,522] Trial 144 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.1484365399678663, 'max_iter': 64867}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:07,742] Trial 145 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.09880203761270119, 'max_iter': 62062}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:07,968] Trial 146 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.12270118693142501, 'max_iter': 59045}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:08,197] Trial 147 finished with value: 0.9291055227152392 and parameters: {'solver': 'lbfgs', 'C': 0.047195781187232236, 'max_iter': 55782}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:08,646] Trial 148 finished with value: 0.9297838081181945 and parameters: {'solver': 'saga', 'C': 0.07263275257168733, 'max_iter': 64276}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:09,147] Trial 149 finished with value: 0.9295578195621423 and parameters: {'solver': 'sag', 'C': 0.1773747231672552, 'max_iter': 69954}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:09,374] Trial 150 finished with value: 0.9303491631900837 and parameters: {'solver': 'lbfgs', 'C': 0.10262452983553842, 'max_iter': 66741}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:09,600] Trial 151 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.11498119802019878, 'max_iter': 66974}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:09,861] Trial 152 finished with value: 0.9280878068494868 and parameters: {'solver': 'lbfgs', 'C': 8.219961784900239, 'max_iter': 61644}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:10,088] Trial 153 finished with value: 0.9298968663431804 and parameters: {'solver': 'lbfgs', 'C': 0.08430772381667867, 'max_iter': 58329}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:10,307] Trial 154 finished with value: 0.9296708138401684 and parameters: {'solver': 'lbfgs', 'C': 0.060338480802428866, 'max_iter': 75653}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:10,532] Trial 155 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.14605912322844253, 'max_iter': 73225}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:10,766] Trial 156 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.09919696471956162, 'max_iter': 65834}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:10,992] Trial 157 finished with value: 0.9291054587682792 and parameters: {'solver': 'lbfgs', 'C': 0.2009391608026763, 'max_iter': 62522}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:11,241] Trial 158 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.11363844764915301, 'max_iter': 68535}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:11,539] Trial 159 finished with value: 0.9296708777871283 and parameters: {'solver': 'liblinear', 'C': 0.07866674890839923, 'max_iter': 60664}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:11,754] Trial 160 finished with value: 0.9294446973901968 and parameters: {'solver': 'lbfgs', 'C': 0.05432927706903811, 'max_iter': 64941}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:11,980] Trial 161 finished with value: 0.9301230467401119 and parameters: {'solver': 'lbfgs', 'C': 0.09099958045442666, 'max_iter': 63721}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:12,206] Trial 162 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.12823460434147613, 'max_iter': 63232}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:12,454] Trial 163 finished with value: 0.9297838720651542 and parameters: {'solver': 'lbfgs', 'C': 0.06802431919707586, 'max_iter': 59318}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:12,727] Trial 164 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.09789647140203953, 'max_iter': 67116}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:12,943] Trial 165 finished with value: 0.9296708777871283 and parameters: {'solver': 'lbfgs', 'C': 0.1640672805021991, 'max_iter': 54763}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:13,702] Trial 166 finished with value: 0.9291055227152392 and parameters: {'solver': 'saga', 'C': 0.04254726754898984, 'max_iter': 70891}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:13,995] Trial 167 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.09208580375593702, 'max_iter': 57271}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:14,340] Trial 168 finished with value: 0.9291054587682792 and parameters: {'solver': 'newton-cg', 'C': 0.23761772288054386, 'max_iter': 63630}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:14,832] Trial 169 finished with value: 0.9298969942371 and parameters: {'solver': 'sag', 'C': 0.13220897360450115, 'max_iter': 61149}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:15,049] Trial 170 finished with value: 0.9298969302901401 and parameters: {'solver': 'lbfgs', 'C': 0.06777220583300146, 'max_iter': 65839}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:15,266] Trial 171 finished with value: 0.9298969302901401 and parameters: {'solver': 'lbfgs', 'C': 0.10728244339523216, 'max_iter': 62124}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:15,492] Trial 172 finished with value: 0.9297838081181945 and parameters: {'solver': 'lbfgs', 'C': 0.08559688619385117, 'max_iter': 62435}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:15,719] Trial 173 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.10555946667665635, 'max_iter': 64001}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:15,947] Trial 174 finished with value: 0.9297839360121142 and parameters: {'solver': 'lbfgs', 'C': 0.14991180002473373, 'max_iter': 59848}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:16,166] Trial 175 finished with value: 0.9294446973901968 and parameters: {'solver': 'lbfgs', 'C': 0.05646470782480474, 'max_iter': 68680}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:16,438] Trial 176 finished with value: 0.9298968663431804 and parameters: {'solver': 'newton-cg', 'C': 0.07739909294919396, 'max_iter': 57818}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:16,676] Trial 177 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.11344504283257377, 'max_iter': 66650}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:16,925] Trial 178 finished with value: 0.9296708777871283 and parameters: {'solver': 'newton-cg', 'C': 0.16482285223807142, 'max_iter': 60669}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:17,149] Trial 179 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.0949000460173221, 'max_iter': 62208}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:17,398] Trial 180 finished with value: 0.9298969302901401 and parameters: {'solver': 'newton-cg', 'C': 0.06790605575349833, 'max_iter': 64759}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:17,636] Trial 181 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.09364111320782605, 'max_iter': 66120}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:17,865] Trial 182 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.12456776798580535, 'max_iter': 68221}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:18,100] Trial 183 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.10290574114888344, 'max_iter': 65576}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:18,318] Trial 184 finished with value: 0.9301230467401119 and parameters: {'solver': 'lbfgs', 'C': 0.07796309642064715, 'max_iter': 63038}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:18,565] Trial 185 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.14012108476881224, 'max_iter': 70131}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:18,807] Trial 186 finished with value: 0.9291055227152392 and parameters: {'solver': 'newton-cg', 'C': 0.05295486995703669, 'max_iter': 58854}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:19,046] Trial 187 finished with value: 0.929218580940225 and parameters: {'solver': 'lbfgs', 'C': 0.19578026758255548, 'max_iter': 56496}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:19,288] Trial 188 finished with value: 0.9302361049650978 and parameters: {'solver': 'newton-cg', 'C': 0.09964425736783565, 'max_iter': 61250}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:19,522] Trial 189 finished with value: 0.9298969302901401 and parameters: {'solver': 'lbfgs', 'C': 0.06628439687854741, 'max_iter': 67877}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:19,749] Trial 190 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.12643836052058535, 'max_iter': 65277}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:19,980] Trial 191 finished with value: 0.9301230467401119 and parameters: {'solver': 'lbfgs', 'C': 0.09139772010779305, 'max_iter': 63566}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:20,211] Trial 192 finished with value: 0.9302361049650978 and parameters: {'solver': 'lbfgs', 'C': 0.10302717754086523, 'max_iter': 66581}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:20,439] Trial 193 finished with value: 0.9301230467401119 and parameters: {'solver': 'lbfgs', 'C': 0.08072090158537094, 'max_iter': 71229}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:20,673] Trial 194 finished with value: 0.9297839360121142 and parameters: {'solver': 'lbfgs', 'C': 0.15487318485029883, 'max_iter': 67655}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:20,921] Trial 195 finished with value: 0.9298969942371 and parameters: {'solver': 'newton-cg', 'C': 0.11391817963565778, 'max_iter': 59415}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:21,151] Trial 196 finished with value: 0.9301230467401119 and parameters: {'solver': 'lbfgs', 'C': 0.0921249454924801, 'max_iter': 62559}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:21,447] Trial 197 finished with value: 0.9286531619213759 and parameters: {'solver': 'liblinear', 'C': 0.06384509287927909, 'max_iter': 65279}. Best is trial 21 with value: 0.9303491631900837.\n",
            "/tmp/ipython-input-8-1163332018.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'C': trial.suggest_loguniform('C', 0.0001, 10),\n",
            "[I 2025-07-15 09:34:21,696] Trial 198 finished with value: 0.9298969942371 and parameters: {'solver': 'lbfgs', 'C': 0.13138172558603092, 'max_iter': 69370}. Best is trial 21 with value: 0.9303491631900837.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: {'solver': 'newton-cg', 'C': 0.09297420667712418, 'max_iter': 63018}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "memo: ベイズ統計というものがある\n",
        "\n",
        "## ベイズ統計\n",
        "\n",
        "### ベイズ統計とは\n",
        "\n",
        "ベイズ統計ベイズの定理を基にした統計学の考え方。新しいデータを取り込みながら推定や予測の精度を高めていくという特徴がある。\n",
        "\n",
        "### ベイズの定理の活用例\n",
        "\n",
        "迷惑メールの本文に「無料」という表記があったら迷惑メールなのか?\n",
        "\n",
        "> 迷惑メールの合計は100通の20%で20通、うち30%で無料表記があるので重なり部分は6通。全メールで「無料」表記がある割合は10%（10通）で、うち迷惑メールの6通を除いた4通が通常メールで本文中に「無料」表記あり。迷惑メールではなく、かつ本部中に「無料」表記もないメールは76通。\n",
        "\n",
        "> 迷惑メールのうち本文中に「無料」表記がある割合は30%でしたが、同じデータでも見方を変えると、「無料」表記があるメールのうち迷惑メールである割合は60%となります。重なりの部分（6通）を、迷惑メール側から評価するか、「無料」表記あり側から評価するかの違いです。\n",
        "「ベイズの定理」とは、このベン図の重なりの部分の関係を数式で表したもので、当たり前のことを言っているだけで難しくはありません。見方を変えるという点が「ベイズの定理」のポイントで、データを解釈する際の誤解を排除することができます。同じデータを用いても、違う視点から見ることで、結果に及ぼす要因を正しく評価できます。\n",
        "\n",
        "このようにデータが増えたときに、それによって既存のデータがどのように変わるかを分析し、精度を高めることができる。これがベイズ統計だ！\n",
        "\n",
        "\n",
        "参考: https://www.nri.com/jp/knowledge/glossary/bayesian_statistics.html"
      ],
      "metadata": {
        "id": "KT3Z8X73cupp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 混同行列\n",
        "\n",
        "|||予測結果||\n",
        "|-|-|-|-|\n",
        "|||陰性|陽性|\n",
        "|正解データ|陰性|真陰性(TN)|偽陽性(FP)|\n",
        "||陽性|偽陰性(FN)|真陽性(TP)|\n",
        "\n",
        "端的に言えば上の表のことだ。少し解説すると\n",
        "\n",
        "- 真陽性(TP): フィッシングサイトをフィッシングサイトであると正しく検出できている数\n",
        "- 偽陰性(FN): フィッシングサイトを見逃してしまった数\n",
        "- 真陰性(TN): 非フィッシングサイトを正しく検出できた数\n",
        "- 偽陽性(FP): 非フィッシングサイトをフィッシングサイトと誤検知した数\n",
        "\n",
        "という意味だ。"
      ],
      "metadata": {
        "id": "pGPf3EJDO94-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AAJGkE35Kcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a7fca5-5d16-45b6-caf0-ca9c75ca9efb"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "model = LogisticRegression(\n",
        "    # ハイパーパラメータ探索で特定した値を設定\n",
        "    solver = study.best_params['solver'],\n",
        "    C = study.best_params['C'],\n",
        "    max_iter = study.best_params['max_iter']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "# 正解率の出力\n",
        "print(\"Accuracy: {:.5f} %\".format(100 * accuracy_score(y_test, pred)))\n",
        "# 混同行列の出力\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.35640 %\n",
            "[[ 874   97]\n",
            " [  72 1168]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKZRlpGSDFh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff2400f-5fa7-4dda-9324-8baab4fb018a"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# 適合率の確認\n",
        "print(\"Precision: {:.5f} %\".format(100 * precision_score(y_test, pred)))\n",
        "# 再現率の確認\n",
        "print(\"Recall: {:.5f} %\".format(100 * recall_score(y_test, pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 92.33202 %\n",
            "Recall: 94.19355 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwVXagaQxnDn"
      },
      "source": [
        "##決定木を使用したフィッシング検出器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KyBu4q8xDwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64b0489-616d-45cf-ef96-9d4337681aed",
        "collapsed": true
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "class Objective_DTC:\n",
        "    def __init__(self, X, y):\n",
        "        # 変数X,yの初期化\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        # ターゲットのハイパーパラメータの設定\n",
        "        params = {\n",
        "            'criterion':\\\n",
        "            trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "            'splitter':\\\n",
        "            trial.suggest_categorical('splitter', ['best', 'random']),\n",
        "            'max_features':\\\n",
        "            trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
        "            'min_samples_split':\\\n",
        "            trial.suggest_int('min_samples_split', 2, 64),\n",
        "            'max_depth':\\\n",
        "            trial.suggest_int('max_depth', 2, 64)\n",
        "            }\n",
        "\n",
        "        model = DecisionTreeClassifier(**params)\n",
        "\n",
        "        # 評価指標として正解率の最大化を目指す\n",
        "        scores = cross_validate(model,\n",
        "                                X=self.X, y=self.y,\n",
        "                                scoring='accuracy',\n",
        "                                n_jobs=-1)\n",
        "        return scores['test_score'].mean()\n",
        "\n",
        "objective = Objective_DTC(X_train, y_train)\n",
        "study = optuna.create_study(direction='maximize')\n",
        "# timeoutに60を指定し、最大で1分間探索させる\n",
        "study.optimize(objective, timeout=60)\n",
        "print('params:', study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-15 09:55:21,897] A new study created in memory with name: no-name-4a42ef50-8ce5-4f82-9651-0aff872bc6a2\n",
            "[I 2025-07-15 09:55:22,108] Trial 0 finished with value: 0.9211886332999957 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 6, 'max_depth': 14}. Best is trial 0 with value: 0.9211886332999957.\n",
            "[I 2025-07-15 09:55:22,269] Trial 1 finished with value: 0.9250359381914265 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 16, 'max_depth': 44}. Best is trial 1 with value: 0.9250359381914265.\n",
            "[I 2025-07-15 09:55:22,478] Trial 2 finished with value: 0.9137281972840448 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 40, 'max_depth': 35}. Best is trial 1 with value: 0.9250359381914265.\n",
            "[I 2025-07-15 09:55:22,662] Trial 3 finished with value: 0.9077343208449185 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 34, 'max_depth': 55}. Best is trial 1 with value: 0.9250359381914265.\n",
            "[I 2025-07-15 09:55:22,856] Trial 4 finished with value: 0.9338544797403241 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 50}. Best is trial 4 with value: 0.9338544797403241.\n",
            "[I 2025-07-15 09:55:23,034] Trial 5 finished with value: 0.9199466554461069 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 49, 'max_depth': 61}. Best is trial 4 with value: 0.9338544797403241.\n",
            "[I 2025-07-15 09:55:23,209] Trial 6 finished with value: 0.9066035467541802 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 19, 'max_depth': 11}. Best is trial 4 with value: 0.9338544797403241.\n",
            "[I 2025-07-15 09:55:23,388] Trial 7 finished with value: 0.9035526373005174 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 28, 'max_depth': 11}. Best is trial 4 with value: 0.9338544797403241.\n",
            "[I 2025-07-15 09:55:23,525] Trial 8 finished with value: 0.9094298105379475 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 63, 'max_depth': 34}. Best is trial 4 with value: 0.9338544797403241.\n",
            "[I 2025-07-15 09:55:23,662] Trial 9 finished with value: 0.9099951016628767 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 40, 'max_depth': 30}. Best is trial 4 with value: 0.9338544797403241.\n",
            "[I 2025-07-15 09:55:23,822] Trial 10 finished with value: 0.9470831873211084 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 10 with value: 0.9470831873211084.\n",
            "[I 2025-07-15 09:55:23,981] Trial 11 finished with value: 0.9559030717561626 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:24,140] Trial 12 finished with value: 0.9491191306282916 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 64}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:24,298] Trial 13 finished with value: 0.9313645769652819 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 18, 'max_depth': 64}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:24,464] Trial 14 finished with value: 0.9488925665496011 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 41}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:24,615] Trial 15 finished with value: 0.9318180248574622 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 13, 'max_depth': 24}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:24,764] Trial 16 finished with value: 0.929443802132759 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 25, 'max_depth': 56}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:24,922] Trial 17 finished with value: 0.9341930788926434 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 12, 'max_depth': 58}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:25,096] Trial 18 finished with value: 0.9533022210058089 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:25,246] Trial 19 finished with value: 0.9237897398381886 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 24, 'max_depth': 43}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:25,396] Trial 20 finished with value: 0.9015168218872539 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 64, 'max_depth': 49}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:25,543] Trial 21 finished with value: 0.6480189871313138 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 2}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:25,705] Trial 22 finished with value: 0.9357768532468429 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 10, 'max_depth': 53}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:25,852] Trial 23 finished with value: 0.9422209162831982 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 9, 'max_depth': 63}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:26,027] Trial 24 finished with value: 0.9523986504633596 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 44}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:26,191] Trial 25 finished with value: 0.9292179414706266 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 15, 'max_depth': 39}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:26,347] Trial 26 finished with value: 0.9079608209766492 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 53, 'max_depth': 28}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:26,510] Trial 27 finished with value: 0.9277490158562882 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 21, 'max_depth': 45}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:26,669] Trial 28 finished with value: 0.9487792525367759 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 39}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:26,818] Trial 29 finished with value: 0.9395070073078585 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 8, 'max_depth': 48}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:26,969] Trial 30 finished with value: 0.9296706859462487 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 31, 'max_depth': 21}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:27,131] Trial 31 finished with value: 0.9451615811781077 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 59}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:27,282] Trial 32 finished with value: 0.9462921634279663 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 52}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:27,433] Trial 33 finished with value: 0.9365685166095833 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 13, 'max_depth': 46}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:27,588] Trial 34 finished with value: 0.9441441850471545 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 36}. Best is trial 11 with value: 0.9559030717561626.\n",
            "[I 2025-07-15 09:55:27,740] Trial 35 finished with value: 0.9588425216588353 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:27,893] Trial 36 finished with value: 0.9386026694018913 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 10, 'max_depth': 54}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:28,046] Trial 37 finished with value: 0.9303498666066418 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 16, 'max_depth': 43}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:28,218] Trial 38 finished with value: 0.9562425661659193 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:28,368] Trial 39 finished with value: 0.9364544991802 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 58}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:28,519] Trial 40 finished with value: 0.9225484654008579 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 48, 'max_depth': 52}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:28,680] Trial 41 finished with value: 0.9569209155158344 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:28,832] Trial 42 finished with value: 0.9328366999276121 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 11, 'max_depth': 56}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:28,990] Trial 43 finished with value: 0.943805330106996 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 47}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:29,141] Trial 44 finished with value: 0.9127097140547745 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 40, 'max_depth': 60}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:29,305] Trial 45 finished with value: 0.9539810819314027 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:29,456] Trial 46 finished with value: 0.9456140698658905 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 51}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:29,605] Trial 47 finished with value: 0.9283136675116191 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 20, 'max_depth': 55}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:29,758] Trial 48 finished with value: 0.9258255552514522 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 14, 'max_depth': 61}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:29,908] Trial 49 finished with value: 0.9448223425561901 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 40}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:30,058] Trial 50 finished with value: 0.9283144348751371 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 17, 'max_depth': 57}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:30,226] Trial 51 finished with value: 0.9575986253961514 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:30,317] Trial 52 finished with value: 0.9482140893057662 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 50}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:30,399] Trial 53 finished with value: 0.9556773389879499 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:30,576] Trial 54 finished with value: 0.934420730069651 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 9, 'max_depth': 42}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:30,766] Trial 55 finished with value: 0.93996000757132 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 46}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:30,952] Trial 56 finished with value: 0.9395084780879348 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 12, 'max_depth': 36}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:31,155] Trial 57 finished with value: 0.9366815108876094 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 54}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:31,335] Trial 58 finished with value: 0.9062631570869858 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 60, 'max_depth': 32}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:31,528] Trial 59 finished with value: 0.9424475443088485 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 47}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:31,612] Trial 60 finished with value: 0.9386035007123692 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 9, 'max_depth': 62}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:31,792] Trial 61 finished with value: 0.9557894380085381 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:31,987] Trial 62 finished with value: 0.9563554964969855 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 53}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:32,151] Trial 63 finished with value: 0.9503626432092165 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:32,328] Trial 64 finished with value: 0.9391691755190574 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 56}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:32,480] Trial 65 finished with value: 0.9561291882061342 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:32,631] Trial 66 finished with value: 0.9213032262520177 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 37, 'max_depth': 59}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:32,792] Trial 67 finished with value: 0.9435787660283055 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 48}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:32,947] Trial 68 finished with value: 0.9407513511992613 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 11, 'max_depth': 52}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:33,103] Trial 69 finished with value: 0.9421091369974087 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 38}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:33,258] Trial 70 finished with value: 0.9466324252012409 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 44}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:33,422] Trial 71 finished with value: 0.9507022655128929 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:33,574] Trial 72 finished with value: 0.9575988811839908 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:33,736] Trial 73 finished with value: 0.9404139670391791 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 54}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:33,901] Trial 74 finished with value: 0.937133296158834 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 9, 'max_depth': 57}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:34,053] Trial 75 finished with value: 0.9410909735029376 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 52}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:34,209] Trial 76 finished with value: 0.9462925471097252 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 55}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:34,377] Trial 77 finished with value: 0.9507027770885716 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 18}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:34,530] Trial 78 finished with value: 0.9353243006121004 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 11, 'max_depth': 60}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:34,681] Trial 79 finished with value: 0.9382638144617328 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 64}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:34,837] Trial 80 finished with value: 0.9453880173628786 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 48}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:35,003] Trial 81 finished with value: 0.9551112804995026 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:35,154] Trial 82 finished with value: 0.9140672440650827 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 43, 'max_depth': 50}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:35,319] Trial 83 finished with value: 0.9507006668388971 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:35,474] Trial 84 finished with value: 0.9461789773090608 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 44}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:35,626] Trial 85 finished with value: 0.9294447613371565 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 28, 'max_depth': 58}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:35,778] Trial 86 finished with value: 0.9397342108561475 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 51}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:35,922] Trial 87 finished with value: 0.753380619978565 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 2}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:36,086] Trial 88 finished with value: 0.9336279156616335 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 42}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:36,255] Trial 89 finished with value: 0.9527369938278394 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:36,421] Trial 90 finished with value: 0.9455005000652259 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 47}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:36,573] Trial 91 finished with value: 0.9555637052403254 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:36,726] Trial 92 finished with value: 0.9488919910269626 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 45}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:36,876] Trial 93 finished with value: 0.9462912681705286 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 49}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:37,034] Trial 94 finished with value: 0.9415435900846403 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 50}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:37,188] Trial 95 finished with value: 0.9468580300755342 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:37,345] Trial 96 finished with value: 0.940299054352358 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 10, 'max_depth': 48}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:37,498] Trial 97 finished with value: 0.9298969302901401 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 23, 'max_depth': 54}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:37,652] Trial 98 finished with value: 0.944143993206275 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:37,802] Trial 99 finished with value: 0.9547717860897457 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:37,957] Trial 100 finished with value: 0.9460652156675169 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 51}. Best is trial 35 with value: 0.9588425216588353.\n",
            "[I 2025-07-15 09:55:38,119] Trial 101 finished with value: 0.9591816963337928 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:38,285] Trial 102 finished with value: 0.945613494343252 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 41}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:38,437] Trial 103 finished with value: 0.9414304039657347 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:38,602] Trial 104 finished with value: 0.9406386127090747 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 43}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:38,755] Trial 105 finished with value: 0.9474226177839054 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 27}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:38,918] Trial 106 finished with value: 0.9516065394719003 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:39,081] Trial 107 finished with value: 0.9341935904683221 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:39,238] Trial 108 finished with value: 0.9462924192158055 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:39,404] Trial 109 finished with value: 0.945727255984796 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 56}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:39,557] Trial 110 finished with value: 0.9391691115720977 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 10, 'max_depth': 54}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:39,712] Trial 111 finished with value: 0.9553379085251528 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:39,864] Trial 112 finished with value: 0.9585031551429981 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:40,017] Trial 113 finished with value: 0.9467444602748696 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:40,167] Trial 114 finished with value: 0.9414307876474937 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:40,321] Trial 115 finished with value: 0.9499109218849517 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:40,479] Trial 116 finished with value: 0.9185887417540396 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 58, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:40,645] Trial 117 finished with value: 0.9512671729560633 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:40,799] Trial 118 finished with value: 0.9433520740556952 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:40,962] Trial 119 finished with value: 0.9211926619584652 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 34, 'max_depth': 59}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:41,131] Trial 120 finished with value: 0.9484403975966174 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 56}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:41,283] Trial 121 finished with value: 0.9562423103780799 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:41,438] Trial 122 finished with value: 0.9511543705189167 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 44}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:41,588] Trial 123 finished with value: 0.9417684275954151 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:41,742] Trial 124 finished with value: 0.9547722337184645 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:41,896] Trial 125 finished with value: 0.9431271725979604 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:42,052] Trial 126 finished with value: 0.9545459893745732 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:42,247] Trial 127 finished with value: 0.9434661554320384 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 42}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:42,440] Trial 128 finished with value: 0.9361151966113228 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 54}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:42,649] Trial 129 finished with value: 0.9495703403768777 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:42,831] Trial 130 finished with value: 0.9468574545528956 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:43,027] Trial 131 finished with value: 0.9529630463308514 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:43,223] Trial 132 finished with value: 0.9493450552373839 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:43,417] Trial 133 finished with value: 0.9497970962964478 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 44}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:43,603] Trial 134 finished with value: 0.9382640702495723 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 38}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:43,792] Trial 135 finished with value: 0.9514932894060351 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:43,958] Trial 136 finished with value: 0.9456137501310913 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:44,122] Trial 137 finished with value: 0.953868023706417 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:44,279] Trial 138 finished with value: 0.9422227067980733 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 4, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:44,433] Trial 139 finished with value: 0.9250329966312743 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 45, 'max_depth': 40}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:44,587] Trial 140 finished with value: 0.9471960537052148 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 43}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:44,744] Trial 141 finished with value: 0.9548862511478479 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:44,900] Trial 142 finished with value: 0.9574855032242058 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:45,069] Trial 143 finished with value: 0.9470842104724657 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:45,236] Trial 144 finished with value: 0.950476276956841 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:45,402] Trial 145 finished with value: 0.9453875057871999 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:45,557] Trial 146 finished with value: 0.945048778740961 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 57}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:45,720] Trial 147 finished with value: 0.9555635773464057 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:45,878] Trial 148 finished with value: 0.9471979721140098 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:46,032] Trial 149 finished with value: 0.9338544797403241 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:46,187] Trial 150 finished with value: 0.9530755290331987 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:46,341] Trial 151 finished with value: 0.9542074541692139 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:46,499] Trial 152 finished with value: 0.9542077099570532 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:46,568] Trial 153 finished with value: 0.9534152792307948 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:46,737] Trial 154 finished with value: 0.9457275757195951 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:46,891] Trial 155 finished with value: 0.9257117936099082 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 31, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:47,044] Trial 156 finished with value: 0.9476488621277968 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:47,204] Trial 157 finished with value: 0.9537546457466319 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:47,272] Trial 158 finished with value: 0.9346456954743457 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 42}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:47,436] Trial 159 finished with value: 0.954773256869822 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 33}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:47,590] Trial 160 finished with value: 0.95002302090554 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 44}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:47,768] Trial 161 finished with value: 0.9570339097938605 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:47,921] Trial 162 finished with value: 0.9552254258228056 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:48,088] Trial 163 finished with value: 0.9478751064716879 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:48,250] Trial 164 finished with value: 0.9433524577374544 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:48,405] Trial 165 finished with value: 0.9471976523792106 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:48,560] Trial 166 finished with value: 0.9535288490314594 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:48,714] Trial 167 finished with value: 0.9434660275381187 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:48,867] Trial 168 finished with value: 0.9240169433864776 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 37, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:49,021] Trial 169 finished with value: 0.918475171953375 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 53, 'max_depth': 44}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:49,176] Trial 170 finished with value: 0.9406385487621147 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 8, 'max_depth': 54}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:49,331] Trial 171 finished with value: 0.9526232961332551 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:49,493] Trial 172 finished with value: 0.948214920616244 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 45}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:49,659] Trial 173 finished with value: 0.9522848248748558 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:49,834] Trial 174 finished with value: 0.9475365712663288 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:49,993] Trial 175 finished with value: 0.9099966363899128 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 8}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:50,158] Trial 176 finished with value: 0.9546595591752377 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:50,324] Trial 177 finished with value: 0.9455005000652259 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:50,481] Trial 178 finished with value: 0.9425615617382318 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 43}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:50,635] Trial 179 finished with value: 0.9549991814789142 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:50,794] Trial 180 finished with value: 0.9496845496471407 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:50,958] Trial 181 finished with value: 0.9540934367398306 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:51,116] Trial 182 finished with value: 0.9549989896380346 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:51,290] Trial 183 finished with value: 0.9494576018866911 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:51,457] Trial 184 finished with value: 0.9509277424932663 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:51,614] Trial 185 finished with value: 0.943918324385022 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:51,770] Trial 186 finished with value: 0.9548858035191291 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:51,928] Trial 187 finished with value: 0.9383767447927991 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 58}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:52,092] Trial 188 finished with value: 0.95160666736582 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:52,248] Trial 189 finished with value: 0.9534158547534333 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:52,405] Trial 190 finished with value: 0.9495710437934359 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:52,562] Trial 191 finished with value: 0.9535284014027405 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:52,719] Trial 192 finished with value: 0.9487791246428563 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:52,884] Trial 193 finished with value: 0.953302540740608 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:53,039] Trial 194 finished with value: 0.9461786575742617 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:53,202] Trial 195 finished with value: 0.9433525216844141 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:53,371] Trial 196 finished with value: 0.9497972881373273 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:53,527] Trial 197 finished with value: 0.9496842299123415 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:53,691] Trial 198 finished with value: 0.9530773834950338 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:53,863] Trial 199 finished with value: 0.9435787660283055 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:54,067] Trial 200 finished with value: 0.9523982667816007 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:54,268] Trial 201 finished with value: 0.9519460338816572 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:54,360] Trial 202 finished with value: 0.949232380694157 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:54,556] Trial 203 finished with value: 0.9528508194163432 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:54,753] Trial 204 finished with value: 0.9439185162259015 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:54,856] Trial 205 finished with value: 0.9486668977283481 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:55,043] Trial 206 finished with value: 0.9549990535849945 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:55,239] Trial 207 finished with value: 0.950136846494044 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:55,430] Trial 208 finished with value: 0.9450485869000816 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:55,625] Trial 209 finished with value: 0.9527366740930402 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:55,784] Trial 210 finished with value: 0.9459527329651694 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 52}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:55,942] Trial 211 finished with value: 0.9557909087886143 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:56,099] Trial 212 finished with value: 0.9556771471470702 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:56,261] Trial 213 finished with value: 0.9513809985445671 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:56,426] Trial 214 finished with value: 0.9456147093354887 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:56,586] Trial 215 finished with value: 0.9448231738666679 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:56,745] Trial 216 finished with value: 0.954433378778306 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:56,904] Trial 217 finished with value: 0.9468572627120162 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 44}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:57,076] Trial 218 finished with value: 0.9514934172999547 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 29}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:57,235] Trial 219 finished with value: 0.9409781710657912 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:57,396] Trial 220 finished with value: 0.9343065207993883 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 5, 'max_depth': 47}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:57,553] Trial 221 finished with value: 0.9564688105098107 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 53}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:57,722] Trial 222 finished with value: 0.9523983946755203 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:57,882] Trial 223 finished with value: 0.9484416765358141 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 56}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:58,057] Trial 224 finished with value: 0.9262783636740343 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 26, 'max_depth': 50}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:58,215] Trial 225 finished with value: 0.9220969998644325 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 19, 'max_depth': 48}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:58,377] Trial 226 finished with value: 0.951946097828617 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:58,533] Trial 227 finished with value: 0.9432390158307093 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:58,691] Trial 228 finished with value: 0.9510408007182523 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:58,852] Trial 229 finished with value: 0.9537547096935917 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:59,011] Trial 230 finished with value: 0.9417695146937325 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 24}. Best is trial 101 with value: 0.9591816963337928.\n",
            "[I 2025-07-15 09:55:59,166] Trial 231 finished with value: 0.9598609409411457 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:55:59,328] Trial 232 finished with value: 0.953302540740608 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:55:59,483] Trial 233 finished with value: 0.9479882286436337 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:55:59,643] Trial 234 finished with value: 0.9535287850844995 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:55:59,802] Trial 235 finished with value: 0.9512673647969428 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:55:59,965] Trial 236 finished with value: 0.9466310823150845 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:00,135] Trial 237 finished with value: 0.9547725534532636 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:00,307] Trial 238 finished with value: 0.9457258491516797 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:00,467] Trial 239 finished with value: 0.9555639610281647 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:00,622] Trial 240 finished with value: 0.943692719510729 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:00,789] Trial 241 finished with value: 0.9526236798150143 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:00,955] Trial 242 finished with value: 0.9469715998761987 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:01,122] Trial 243 finished with value: 0.9552255537167251 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:01,308] Trial 244 finished with value: 0.9542069425935352 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:01,476] Trial 245 finished with value: 0.9496846135941006 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:01,645] Trial 246 finished with value: 0.9477617285119031 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 45}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:01,807] Trial 247 finished with value: 0.9568076015030094 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:01,974] Trial 248 finished with value: 0.9459531166469283 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:02,142] Trial 249 finished with value: 0.9546589197056393 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:02,301] Trial 250 finished with value: 0.9481014147625393 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:02,464] Trial 251 finished with value: 0.9595220860009872 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:02,622] Trial 252 finished with value: 0.9458398026341032 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 57}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:02,790] Trial 253 finished with value: 0.949232380694157 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 61}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:02,949] Trial 254 finished with value: 0.9514935451938744 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:03,108] Trial 255 finished with value: 0.9517197895377658 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 56}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:03,272] Trial 256 finished with value: 0.9503626432092165 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 58}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:03,429] Trial 257 finished with value: 0.9568074736090896 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:03,587] Trial 258 finished with value: 0.9544338903539847 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:03,745] Trial 259 finished with value: 0.9336276598737943 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:03,904] Trial 260 finished with value: 0.9487805954229322 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:04,071] Trial 261 finished with value: 0.9429009282540688 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:04,247] Trial 262 finished with value: 0.9396220478885992 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:04,407] Trial 263 finished with value: 0.9559035193848814 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:04,566] Trial 264 finished with value: 0.9531890348869034 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:04,723] Trial 265 finished with value: 0.9481013508155796 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 57}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:04,881] Trial 266 finished with value: 0.9391680884207403 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:05,040] Trial 267 finished with value: 0.9242438271999672 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 22, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:05,197] Trial 268 finished with value: 0.9511548820945954 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:05,362] Trial 269 finished with value: 0.9425604106929548 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:05,524] Trial 270 finished with value: 0.9457266804621576 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 56}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:05,684] Trial 271 finished with value: 0.9565811653182384 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:05,881] Trial 272 finished with value: 0.952397755205922 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:06,087] Trial 273 finished with value: 0.9443698538684074 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:06,294] Trial 274 finished with value: 0.946291523958368 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:06,499] Trial 275 finished with value: 0.9387166868312746 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'log2', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:06,694] Trial 276 finished with value: 0.9251466943258583 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 15, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:06,899] Trial 277 finished with value: 0.9548856116782496 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:07,117] Trial 278 finished with value: 0.9350970331168516 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 58}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:07,316] Trial 279 finished with value: 0.9503620037396182 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:07,511] Trial 280 finished with value: 0.9553365656389964 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:07,680] Trial 281 finished with value: 0.9447089006494453 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:07,840] Trial 282 finished with value: 0.9187019918199049 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 62, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:08,016] Trial 283 finished with value: 0.9470836349498273 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:08,173] Trial 284 finished with value: 0.9545466927911314 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:08,333] Trial 285 finished with value: 0.9309150298376515 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 12}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:08,494] Trial 286 finished with value: 0.942222451010234 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:08,652] Trial 287 finished with value: 0.9505882480835096 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 35}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:08,812] Trial 288 finished with value: 0.9564684907750116 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:08,981] Trial 289 finished with value: 0.939621024737242 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 56}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:09,147] Trial 290 finished with value: 0.9530759766619175 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 57}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:09,309] Trial 291 finished with value: 0.9214162205300436 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 48, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:09,474] Trial 292 finished with value: 0.9468575184998554 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 57}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:09,633] Trial 293 finished with value: 0.9551116641812614 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:09,793] Trial 294 finished with value: 0.9485535837155229 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:09,952] Trial 295 finished with value: 0.9122583124653086 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_features': 'sqrt', 'min_samples_split': 51, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:10,126] Trial 296 finished with value: 0.9436909289958537 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:10,285] Trial 297 finished with value: 0.9435780626117474 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 19}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:10,448] Trial 298 finished with value: 0.9556775308288292 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:10,619] Trial 299 finished with value: 0.9483277230533906 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:10,791] Trial 300 finished with value: 0.9565812292651982 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 45}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:10,962] Trial 301 finished with value: 0.9490063281911452 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 45}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:11,122] Trial 302 finished with value: 0.9196072249833097 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 43, 'max_depth': 60}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:11,291] Trial 303 finished with value: 0.9563547291334675 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:11,456] Trial 304 finished with value: 0.8402289045374205 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 4}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:11,619] Trial 305 finished with value: 0.9573730205218582 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 46}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:11,781] Trial 306 finished with value: 0.9525104936961087 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 45}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:11,945] Trial 307 finished with value: 0.954998861744115 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 31}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:12,106] Trial 308 finished with value: 0.9456141338128502 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 44}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:12,278] Trial 309 finished with value: 0.9493447355025847 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 46}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:12,446] Trial 310 finished with value: 0.950136846494044 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:12,604] Trial 311 finished with value: 0.9554510306970986 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:12,764] Trial 312 finished with value: 0.9456134303962921 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:12,924] Trial 313 finished with value: 0.9545463730563322 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 43}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:13,096] Trial 314 finished with value: 0.9441434816305962 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 56}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:13,255] Trial 315 finished with value: 0.9519462257225365 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 2, 'max_depth': 59}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:13,415] Trial 316 finished with value: 0.9272953121762685 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 31, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:13,574] Trial 317 finished with value: 0.9517198534847257 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:13,744] Trial 318 finished with value: 0.9526246390194117 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:13,904] Trial 319 finished with value: 0.9571469680188465 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:14,083] Trial 320 finished with value: 0.9499107939910321 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:14,251] Trial 321 finished with value: 0.9416570319913851 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 45}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:14,423] Trial 322 finished with value: 0.9526242553376527 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:14,582] Trial 323 finished with value: 0.9277479927049308 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 37, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:14,746] Trial 324 finished with value: 0.9233369314156068 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 57, 'max_depth': 57}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:14,906] Trial 325 finished with value: 0.9458396107932237 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:15,082] Trial 326 finished with value: 0.951154242624997 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:15,242] Trial 327 finished with value: 0.9565816768939172 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:15,415] Trial 328 finished with value: 0.950589271234867 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:15,586] Trial 329 finished with value: 0.9559037112257609 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:15,749] Trial 330 finished with value: 0.9376993546472813 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 17, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:15,921] Trial 331 finished with value: 0.9521718305968297 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:16,102] Trial 332 finished with value: 0.9485541592381616 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:16,273] Trial 333 finished with value: 0.9490067118729042 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:16,434] Trial 334 finished with value: 0.9390558615062323 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:16,594] Trial 335 finished with value: 0.9410900782455001 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 52}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:16,756] Trial 336 finished with value: 0.9551119839160608 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:16,916] Trial 337 finished with value: 0.9445970574166962 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 4, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:17,097] Trial 338 finished with value: 0.9554507109622994 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 44}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:17,257] Trial 339 finished with value: 0.9517194698029666 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:17,418] Trial 340 finished with value: 0.9418816776612806 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:17,621] Trial 341 finished with value: 0.9537549015344713 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:17,826] Trial 342 finished with value: 0.9448226622909894 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:18,038] Trial 343 finished with value: 0.9492319330654381 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:18,242] Trial 344 finished with value: 0.9354377425188452 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 26, 'max_depth': 51}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:18,447] Trial 345 finished with value: 0.9572590670394348 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:18,667] Trial 346 finished with value: 0.9450481392713627 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 56}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:18,866] Trial 347 finished with value: 0.9507024573537723 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 58}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:19,084] Trial 348 finished with value: 0.9434644288641229 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:19,287] Trial 349 finished with value: 0.9553365016920365 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 56}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:19,451] Trial 350 finished with value: 0.946405669281671 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 41}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:19,622] Trial 351 finished with value: 0.954998861744115 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:19,793] Trial 352 finished with value: 0.9482147927223243 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 46}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:19,966] Trial 353 finished with value: 0.9549982862214763 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 58}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:20,138] Trial 354 finished with value: 0.9439174930745443 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:20,310] Trial 355 finished with value: 0.949570276429918 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 49}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:20,470] Trial 356 finished with value: 0.9449361681446942 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 45}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:20,632] Trial 357 finished with value: 0.9538671923959392 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 47}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:20,795] Trial 358 finished with value: 0.9466317217846829 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 5, 'max_depth': 56}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:20,968] Trial 359 finished with value: 0.9488928862844002 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 3, 'max_depth': 53}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:21,142] Trial 360 finished with value: 0.9530757848210379 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 50}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:21,315] Trial 361 finished with value: 0.9445962900531782 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 7, 'max_depth': 48}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:21,487] Trial 362 finished with value: 0.9493451831313034 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 4, 'max_depth': 57}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:21,650] Trial 363 finished with value: 0.9270702188776541 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 29, 'max_depth': 54}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:21,824] Trial 364 finished with value: 0.954772809241103 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 43}. Best is trial 231 with value: 0.9598609409411457.\n",
            "[I 2025-07-15 09:56:21,996] Trial 365 finished with value: 0.944822022821391 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 6, 'max_depth': 55}. Best is trial 231 with value: 0.9598609409411457.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: {'criterion': 'gini', 'splitter': 'best', 'max_features': 'sqrt', 'min_samples_split': 2, 'max_depth': 52}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0YTQ22b9YxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07398e7f-66da-49b4-e65a-f90cf535fc64"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "model = DecisionTreeClassifier(\n",
        "    # ハイパーパラメータ探索で特定した値を設定\n",
        "    criterion = study.best_params['criterion'],\n",
        "    splitter = study.best_params['splitter'],\n",
        "    max_features = study.best_params['max_features'],\n",
        "    min_samples_split = study.best_params['min_samples_split'],\n",
        "    max_depth = study.best_params['max_depth']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "# 正解率の出力\n",
        "print(\"Accuracy: {:.5f} %\".format(100 * accuracy_score(y_test, pred)))\n",
        "# 適合率の出力\n",
        "print(\"Precision: {:.5f} %\".format(100 * precision_score(y_test, pred,)))\n",
        "# 再現率の出力\n",
        "print(\"Recall: {:.5f} %\".format(100 * recall_score(y_test, pred)))\n",
        "# 混同行列の出力\n",
        "print(confusion_matrix(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.79376 %\n",
            "Precision: 96.21273 %\n",
            "Recall: 96.29032 %\n",
            "[[ 924   47]\n",
            " [  46 1194]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwDgHRK6yq1w"
      },
      "source": [
        "### tf-idfを使った迷惑メール検出"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP\n",
        "\n",
        "ここからは、実際にメールの文などから迷惑メールを検出する。このデータは前処理が終わっていないので、前処理をする必要がある。そこでNLPが必要というわけだ。\n",
        "\n",
        "NLP(Natural Language Processing)とは、自然言語を機械で分析して理解する技術のこと。最近では、ChatGPTなど対話型生成AIで使われていることなどから聞く機会も多いと思う。\n",
        "\n",
        "NLPは、以下の2つの分野があるよ\n",
        "\n",
        "- NLU(Natural Language Understanding)\n",
        "  - 入力を有意義な表現に結びつけること。\n",
        "- NLG(Natural Language Genration)\n",
        "  - 文章の要約、商品の紹介文、小説などの文章を生成すること。\n",
        "\n",
        "memo:\n",
        "日本語など空白で単語が区切られないタイプの言語では、エヌグラムという手法で単語を抽出する方法がある\n",
        "  \n",
        "## tf-idfとは\n",
        "\n",
        "> Term Frequency - Inverse Document Frequencyの略で自然言語をベクトルで表現する方法のひとつであり、ある文書を特徴づける重要な単語を抽出したいときに有効な手法です。\n",
        "\n",
        "引用元: https://www.takapy.work/entry/2019/01/14/141423"
      ],
      "metadata": {
        "id": "Al9Y31mwRYes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自然言語処理の手順\n",
        "\n",
        "字句分析->構文分析->意味分析->談話統合->語用論的分析"
      ],
      "metadata": {
        "id": "-fYs2BUgdDUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 勾配ブースティング木\n",
        "\n",
        "勾配ブースティングとは、ブースティングアルゴリズムのひとつのこと。ブースティングとは、集団学習のフレームワークのひとつであり、複数の弱学習器(単独で使うには精度の低い学習器のこと)を統合して全体の学習器を構成する手法(アンサンブル学習)をとる。勾配ブースティング木では、この弱学習器に決定木を活用している。"
      ],
      "metadata": {
        "id": "hZeXUL89gHWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T_bhz_wlgFnk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRwvnhoHKJIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bee7917-9189-43fb-b09a-7fd85688aa31",
        "collapsed": true
      },
      "source": [
        "!wget https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/enron1.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-22 09:26:40--  https://github.com/oreilly-japan/ml-security-jp/raw/master/ch02/enron1.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/enron1.zip [following]\n",
            "--2025-07-22 09:26:41--  https://raw.githubusercontent.com/oreilly-japan/ml-security-jp/master/ch02/enron1.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3597958 (3.4M) [application/zip]\n",
            "Saving to: ‘enron1.zip’\n",
            "\n",
            "enron1.zip          100%[===================>]   3.43M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-22 09:26:41 (56.7 MB/s) - ‘enron1.zip’ saved [3597958/3597958]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF5r5b1qLQNd"
      },
      "source": [
        "!unzip -q enron1.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1ntXsNTLmPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cd1fc7-d953-48c0-bbf2-a2d52a42fa39"
      },
      "source": [
        "!ls ./enron1/ham"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0001.1999-12-10.farmer.ham.txt\t2561.2000-10-17.farmer.ham.txt\n",
            "0002.1999-12-13.farmer.ham.txt\t2563.2000-10-17.farmer.ham.txt\n",
            "0003.1999-12-14.farmer.ham.txt\t2564.2000-10-17.farmer.ham.txt\n",
            "0004.1999-12-14.farmer.ham.txt\t2565.2000-10-18.farmer.ham.txt\n",
            "0005.1999-12-14.farmer.ham.txt\t2567.2000-10-18.farmer.ham.txt\n",
            "0007.1999-12-14.farmer.ham.txt\t2569.2000-10-18.farmer.ham.txt\n",
            "0009.1999-12-14.farmer.ham.txt\t2571.2000-10-18.farmer.ham.txt\n",
            "0010.1999-12-14.farmer.ham.txt\t2572.2000-10-18.farmer.ham.txt\n",
            "0011.1999-12-14.farmer.ham.txt\t2573.2000-10-18.farmer.ham.txt\n",
            "0012.1999-12-14.farmer.ham.txt\t2574.2000-10-18.farmer.ham.txt\n",
            "0013.1999-12-14.farmer.ham.txt\t2576.2000-10-18.farmer.ham.txt\n",
            "0014.1999-12-15.farmer.ham.txt\t2577.2000-10-18.farmer.ham.txt\n",
            "0015.1999-12-15.farmer.ham.txt\t2578.2000-10-18.farmer.ham.txt\n",
            "0016.1999-12-15.farmer.ham.txt\t2579.2000-10-18.farmer.ham.txt\n",
            "0019.1999-12-15.farmer.ham.txt\t2582.2000-10-18.farmer.ham.txt\n",
            "0020.1999-12-15.farmer.ham.txt\t2584.2000-10-18.farmer.ham.txt\n",
            "0021.1999-12-15.farmer.ham.txt\t2586.2000-10-18.farmer.ham.txt\n",
            "0022.1999-12-16.farmer.ham.txt\t2587.2000-10-18.farmer.ham.txt\n",
            "0023.1999-12-16.farmer.ham.txt\t2588.2000-10-18.farmer.ham.txt\n",
            "0024.1999-12-16.farmer.ham.txt\t2589.2000-10-19.farmer.ham.txt\n",
            "0025.1999-12-16.farmer.ham.txt\t2591.2000-10-19.farmer.ham.txt\n",
            "0027.1999-12-17.farmer.ham.txt\t2592.2000-10-19.farmer.ham.txt\n",
            "0028.1999-12-17.farmer.ham.txt\t2593.2000-10-19.farmer.ham.txt\n",
            "0029.1999-12-17.farmer.ham.txt\t2594.2000-10-19.farmer.ham.txt\n",
            "0030.1999-12-20.farmer.ham.txt\t2595.2000-10-19.farmer.ham.txt\n",
            "0031.1999-12-20.farmer.ham.txt\t2596.2000-10-19.farmer.ham.txt\n",
            "0033.1999-12-20.farmer.ham.txt\t2597.2000-10-19.farmer.ham.txt\n",
            "0034.1999-12-20.farmer.ham.txt\t2598.2000-10-19.farmer.ham.txt\n",
            "0035.1999-12-20.farmer.ham.txt\t2599.2000-10-20.farmer.ham.txt\n",
            "0036.1999-12-20.farmer.ham.txt\t2600.2000-10-20.farmer.ham.txt\n",
            "0037.1999-12-20.farmer.ham.txt\t2601.2000-10-20.farmer.ham.txt\n",
            "0038.1999-12-20.farmer.ham.txt\t2602.2000-10-20.farmer.ham.txt\n",
            "0039.1999-12-21.farmer.ham.txt\t2604.2000-10-20.farmer.ham.txt\n",
            "0042.1999-12-21.farmer.ham.txt\t2605.2000-10-20.farmer.ham.txt\n",
            "0043.1999-12-21.farmer.ham.txt\t2606.2000-10-20.farmer.ham.txt\n",
            "0044.1999-12-21.farmer.ham.txt\t2607.2000-10-20.farmer.ham.txt\n",
            "0045.1999-12-21.farmer.ham.txt\t2608.2000-10-20.farmer.ham.txt\n",
            "0047.1999-12-21.farmer.ham.txt\t2609.2000-10-20.farmer.ham.txt\n",
            "0048.1999-12-21.farmer.ham.txt\t2610.2000-10-20.farmer.ham.txt\n",
            "0049.1999-12-21.farmer.ham.txt\t2611.2000-10-20.farmer.ham.txt\n",
            "0050.1999-12-22.farmer.ham.txt\t2612.2000-10-22.farmer.ham.txt\n",
            "0051.1999-12-22.farmer.ham.txt\t2613.2000-10-23.farmer.ham.txt\n",
            "0053.1999-12-22.farmer.ham.txt\t2614.2000-10-23.farmer.ham.txt\n",
            "0055.1999-12-22.farmer.ham.txt\t2616.2000-10-23.farmer.ham.txt\n",
            "0056.1999-12-23.farmer.ham.txt\t2617.2000-10-23.farmer.ham.txt\n",
            "0057.1999-12-23.farmer.ham.txt\t2618.2000-10-23.farmer.ham.txt\n",
            "0059.1999-12-23.farmer.ham.txt\t2619.2000-10-23.farmer.ham.txt\n",
            "0060.1999-12-23.farmer.ham.txt\t2620.2000-10-23.farmer.ham.txt\n",
            "0063.1999-12-23.farmer.ham.txt\t2623.2000-10-23.farmer.ham.txt\n",
            "0064.1999-12-23.farmer.ham.txt\t2624.2000-10-23.farmer.ham.txt\n",
            "0066.1999-12-27.farmer.ham.txt\t2625.2000-10-23.farmer.ham.txt\n",
            "0067.1999-12-27.farmer.ham.txt\t2628.2000-10-24.farmer.ham.txt\n",
            "0068.1999-12-27.farmer.ham.txt\t2630.2000-10-24.farmer.ham.txt\n",
            "0070.1999-12-27.farmer.ham.txt\t2632.2000-10-24.farmer.ham.txt\n",
            "0071.1999-12-27.farmer.ham.txt\t2633.2000-10-24.farmer.ham.txt\n",
            "0074.1999-12-28.farmer.ham.txt\t2634.2000-10-24.farmer.ham.txt\n",
            "0076.1999-12-28.farmer.ham.txt\t2635.2000-10-24.farmer.ham.txt\n",
            "0077.1999-12-28.farmer.ham.txt\t2636.2000-10-24.farmer.ham.txt\n",
            "0078.1999-12-28.farmer.ham.txt\t2637.2000-10-24.farmer.ham.txt\n",
            "0079.1999-12-28.farmer.ham.txt\t2639.2000-10-24.farmer.ham.txt\n",
            "0081.1999-12-28.farmer.ham.txt\t2640.2000-10-24.farmer.ham.txt\n",
            "0083.1999-12-28.farmer.ham.txt\t2641.2000-10-24.farmer.ham.txt\n",
            "0085.1999-12-28.farmer.ham.txt\t2643.2000-10-24.farmer.ham.txt\n",
            "0086.1999-12-29.farmer.ham.txt\t2644.2000-10-24.farmer.ham.txt\n",
            "0087.1999-12-29.farmer.ham.txt\t2646.2000-10-24.farmer.ham.txt\n",
            "0089.1999-12-29.farmer.ham.txt\t2648.2000-10-24.farmer.ham.txt\n",
            "0090.1999-12-29.farmer.ham.txt\t2650.2000-10-24.farmer.ham.txt\n",
            "0091.1999-12-29.farmer.ham.txt\t2651.2000-10-25.farmer.ham.txt\n",
            "0092.1999-12-29.farmer.ham.txt\t2653.2000-10-25.farmer.ham.txt\n",
            "0095.1999-12-29.farmer.ham.txt\t2654.2000-10-25.farmer.ham.txt\n",
            "0096.1999-12-29.farmer.ham.txt\t2655.2000-10-25.farmer.ham.txt\n",
            "0097.1999-12-29.farmer.ham.txt\t2656.2000-10-25.farmer.ham.txt\n",
            "0098.1999-12-29.farmer.ham.txt\t2657.2000-10-25.farmer.ham.txt\n",
            "0099.1999-12-30.farmer.ham.txt\t2659.2000-10-25.farmer.ham.txt\n",
            "0101.1999-12-30.farmer.ham.txt\t2661.2000-10-25.farmer.ham.txt\n",
            "0106.1999-12-30.farmer.ham.txt\t2663.2000-10-25.farmer.ham.txt\n",
            "0107.1999-12-30.farmer.ham.txt\t2664.2000-10-25.farmer.ham.txt\n",
            "0109.1999-12-30.farmer.ham.txt\t2665.2000-10-25.farmer.ham.txt\n",
            "0111.1999-12-31.farmer.ham.txt\t2666.2000-10-25.farmer.ham.txt\n",
            "0112.1999-12-31.farmer.ham.txt\t2667.2000-10-26.farmer.ham.txt\n",
            "0113.2000-01-04.farmer.ham.txt\t2669.2000-10-26.farmer.ham.txt\n",
            "0114.2000-01-04.farmer.ham.txt\t2671.2000-10-26.farmer.ham.txt\n",
            "0115.2000-01-04.farmer.ham.txt\t2672.2000-10-26.farmer.ham.txt\n",
            "0117.2000-01-04.farmer.ham.txt\t2674.2000-10-26.farmer.ham.txt\n",
            "0118.2000-01-04.farmer.ham.txt\t2675.2000-10-26.farmer.ham.txt\n",
            "0119.2000-01-04.farmer.ham.txt\t2676.2000-10-26.farmer.ham.txt\n",
            "0120.2000-01-04.farmer.ham.txt\t2678.2000-10-27.farmer.ham.txt\n",
            "0121.2000-01-05.farmer.ham.txt\t2679.2000-10-27.farmer.ham.txt\n",
            "0123.2000-01-05.farmer.ham.txt\t2683.2000-10-27.farmer.ham.txt\n",
            "0124.2000-01-05.farmer.ham.txt\t2684.2000-10-27.farmer.ham.txt\n",
            "0125.2000-01-05.farmer.ham.txt\t2685.2000-10-27.farmer.ham.txt\n",
            "0126.2000-01-05.farmer.ham.txt\t2687.2000-10-27.farmer.ham.txt\n",
            "0127.2000-01-05.farmer.ham.txt\t2688.2000-10-27.farmer.ham.txt\n",
            "0128.2000-01-05.farmer.ham.txt\t2689.2000-10-27.farmer.ham.txt\n",
            "0129.2000-01-05.farmer.ham.txt\t2690.2000-10-27.farmer.ham.txt\n",
            "0132.2000-01-05.farmer.ham.txt\t2691.2000-10-27.farmer.ham.txt\n",
            "0133.2000-01-06.farmer.ham.txt\t2693.2000-10-30.farmer.ham.txt\n",
            "0136.2000-01-06.farmer.ham.txt\t2694.2000-10-30.farmer.ham.txt\n",
            "0137.2000-01-06.farmer.ham.txt\t2695.2000-10-30.farmer.ham.txt\n",
            "0138.2000-01-06.farmer.ham.txt\t2696.2000-10-30.farmer.ham.txt\n",
            "0139.2000-01-06.farmer.ham.txt\t2699.2000-10-30.farmer.ham.txt\n",
            "0140.2000-01-06.farmer.ham.txt\t2700.2000-10-30.farmer.ham.txt\n",
            "0141.2000-01-06.farmer.ham.txt\t2701.2000-10-30.farmer.ham.txt\n",
            "0142.2000-01-06.farmer.ham.txt\t2703.2000-10-30.farmer.ham.txt\n",
            "0143.2000-01-07.farmer.ham.txt\t2704.2000-10-30.farmer.ham.txt\n",
            "0144.2000-01-07.farmer.ham.txt\t2706.2000-10-30.farmer.ham.txt\n",
            "0145.2000-01-07.farmer.ham.txt\t2708.2000-10-30.farmer.ham.txt\n",
            "0146.2000-01-07.farmer.ham.txt\t2710.2000-10-30.farmer.ham.txt\n",
            "0148.2000-01-07.farmer.ham.txt\t2712.2000-10-31.farmer.ham.txt\n",
            "0151.2000-01-07.farmer.ham.txt\t2714.2000-10-31.farmer.ham.txt\n",
            "0152.2000-01-10.farmer.ham.txt\t2717.2000-10-31.farmer.ham.txt\n",
            "0154.2000-01-10.farmer.ham.txt\t2718.2000-10-31.farmer.ham.txt\n",
            "0155.2000-01-10.farmer.ham.txt\t2719.2000-10-31.farmer.ham.txt\n",
            "0156.2000-01-10.farmer.ham.txt\t2721.2000-10-31.farmer.ham.txt\n",
            "0157.2000-01-10.farmer.ham.txt\t2723.2000-10-31.farmer.ham.txt\n",
            "0158.2000-01-10.farmer.ham.txt\t2725.2000-10-31.farmer.ham.txt\n",
            "0161.2000-01-10.farmer.ham.txt\t2727.2000-10-31.farmer.ham.txt\n",
            "0162.2000-01-10.farmer.ham.txt\t2728.2000-10-31.farmer.ham.txt\n",
            "0163.2000-01-10.farmer.ham.txt\t2729.2000-10-31.farmer.ham.txt\n",
            "0164.2000-01-11.farmer.ham.txt\t2730.2000-10-31.farmer.ham.txt\n",
            "0165.2000-01-11.farmer.ham.txt\t2732.2000-11-01.farmer.ham.txt\n",
            "0166.2000-01-11.farmer.ham.txt\t2734.2000-11-01.farmer.ham.txt\n",
            "0169.2000-01-11.farmer.ham.txt\t2736.2000-11-01.farmer.ham.txt\n",
            "0171.2000-01-11.farmer.ham.txt\t2737.2000-11-01.farmer.ham.txt\n",
            "0172.2000-01-11.farmer.ham.txt\t2738.2000-11-01.farmer.ham.txt\n",
            "0175.2000-01-11.farmer.ham.txt\t2740.2000-11-01.farmer.ham.txt\n",
            "0177.2000-01-11.farmer.ham.txt\t2742.2000-11-01.farmer.ham.txt\n",
            "0178.2000-01-11.farmer.ham.txt\t2743.2000-11-01.farmer.ham.txt\n",
            "0179.2000-01-11.farmer.ham.txt\t2745.2000-11-01.farmer.ham.txt\n",
            "0180.2000-01-11.farmer.ham.txt\t2748.2000-11-01.farmer.ham.txt\n",
            "0181.2000-01-12.farmer.ham.txt\t2749.2000-11-02.farmer.ham.txt\n",
            "0182.2000-01-12.farmer.ham.txt\t2750.2000-11-02.farmer.ham.txt\n",
            "0183.2000-01-12.farmer.ham.txt\t2753.2000-11-02.farmer.ham.txt\n",
            "0185.2000-01-12.farmer.ham.txt\t2754.2000-11-02.farmer.ham.txt\n",
            "0186.2000-01-12.farmer.ham.txt\t2757.2000-11-02.farmer.ham.txt\n",
            "0187.2000-01-12.farmer.ham.txt\t2758.2000-11-02.farmer.ham.txt\n",
            "0188.2000-01-12.farmer.ham.txt\t2759.2000-11-02.farmer.ham.txt\n",
            "0190.2000-01-12.farmer.ham.txt\t2760.2000-11-02.farmer.ham.txt\n",
            "0193.2000-01-12.farmer.ham.txt\t2761.2000-11-02.farmer.ham.txt\n",
            "0194.2000-01-13.farmer.ham.txt\t2762.2000-11-02.farmer.ham.txt\n",
            "0196.2000-01-13.farmer.ham.txt\t2765.2000-11-03.farmer.ham.txt\n",
            "0198.2000-01-14.farmer.ham.txt\t2766.2000-11-03.farmer.ham.txt\n",
            "0200.2000-01-14.farmer.ham.txt\t2767.2000-11-05.farmer.ham.txt\n",
            "0201.2000-01-14.farmer.ham.txt\t2768.2000-11-06.farmer.ham.txt\n",
            "0203.2000-01-16.farmer.ham.txt\t2769.2000-11-06.farmer.ham.txt\n",
            "0205.2000-01-17.farmer.ham.txt\t2771.2000-11-06.farmer.ham.txt\n",
            "0206.2000-01-17.farmer.ham.txt\t2772.2000-11-06.farmer.ham.txt\n",
            "0207.2000-01-17.farmer.ham.txt\t2773.2000-11-06.farmer.ham.txt\n",
            "0208.2000-01-17.farmer.ham.txt\t2774.2000-11-06.farmer.ham.txt\n",
            "0210.2000-01-17.farmer.ham.txt\t2776.2000-11-07.farmer.ham.txt\n",
            "0211.2000-01-17.farmer.ham.txt\t2777.2000-11-07.farmer.ham.txt\n",
            "0212.2000-01-18.farmer.ham.txt\t2778.2000-11-07.farmer.ham.txt\n",
            "0213.2000-01-18.farmer.ham.txt\t2779.2000-11-07.farmer.ham.txt\n",
            "0215.2000-01-18.farmer.ham.txt\t2780.2000-11-07.farmer.ham.txt\n",
            "0217.2000-01-18.farmer.ham.txt\t2782.2000-11-07.farmer.ham.txt\n",
            "0218.2000-01-19.farmer.ham.txt\t2786.2000-11-07.farmer.ham.txt\n",
            "0219.2000-01-19.farmer.ham.txt\t2788.2000-11-07.farmer.ham.txt\n",
            "0220.2000-01-19.farmer.ham.txt\t2789.2000-11-07.farmer.ham.txt\n",
            "0221.2000-01-19.farmer.ham.txt\t2790.2000-11-07.farmer.ham.txt\n",
            "0222.2000-01-19.farmer.ham.txt\t2791.2000-11-07.farmer.ham.txt\n",
            "0223.2000-01-19.farmer.ham.txt\t2792.2000-11-07.farmer.ham.txt\n",
            "0224.2000-01-19.farmer.ham.txt\t2793.2000-11-08.farmer.ham.txt\n",
            "0225.2000-01-19.farmer.ham.txt\t2795.2000-11-08.farmer.ham.txt\n",
            "0226.2000-01-20.farmer.ham.txt\t2796.2000-11-08.farmer.ham.txt\n",
            "0227.2000-01-20.farmer.ham.txt\t2797.2000-11-08.farmer.ham.txt\n",
            "0229.2000-01-20.farmer.ham.txt\t2799.2000-11-08.farmer.ham.txt\n",
            "0230.2000-01-20.farmer.ham.txt\t2800.2000-11-08.farmer.ham.txt\n",
            "0231.2000-01-21.farmer.ham.txt\t2801.2000-11-09.farmer.ham.txt\n",
            "0232.2000-01-21.farmer.ham.txt\t2802.2000-11-09.farmer.ham.txt\n",
            "0234.2000-01-21.farmer.ham.txt\t2804.2000-11-09.farmer.ham.txt\n",
            "0235.2000-01-21.farmer.ham.txt\t2805.2000-11-09.farmer.ham.txt\n",
            "0237.2000-01-21.farmer.ham.txt\t2806.2000-11-09.farmer.ham.txt\n",
            "0239.2000-01-21.farmer.ham.txt\t2808.2000-11-09.farmer.ham.txt\n",
            "0240.2000-01-21.farmer.ham.txt\t2809.2000-11-09.farmer.ham.txt\n",
            "0241.2000-01-21.farmer.ham.txt\t2811.2000-11-09.farmer.ham.txt\n",
            "0242.2000-01-21.farmer.ham.txt\t2814.2000-11-09.farmer.ham.txt\n",
            "0243.2000-01-24.farmer.ham.txt\t2815.2000-11-09.farmer.ham.txt\n",
            "0244.2000-01-24.farmer.ham.txt\t2816.2000-11-10.farmer.ham.txt\n",
            "0245.2000-01-24.farmer.ham.txt\t2817.2000-11-10.farmer.ham.txt\n",
            "0246.2000-01-24.farmer.ham.txt\t2818.2000-11-10.farmer.ham.txt\n",
            "0247.2000-01-24.farmer.ham.txt\t2819.2000-11-12.farmer.ham.txt\n",
            "0249.2000-01-24.farmer.ham.txt\t2820.2000-11-13.farmer.ham.txt\n",
            "0251.2000-01-24.farmer.ham.txt\t2821.2000-11-13.farmer.ham.txt\n",
            "0252.2000-01-25.farmer.ham.txt\t2823.2000-11-13.farmer.ham.txt\n",
            "0253.2000-01-25.farmer.ham.txt\t2824.2000-11-13.farmer.ham.txt\n",
            "0254.2000-01-25.farmer.ham.txt\t2825.2000-11-13.farmer.ham.txt\n",
            "0255.2000-01-25.farmer.ham.txt\t2828.2000-11-13.farmer.ham.txt\n",
            "0257.2000-01-25.farmer.ham.txt\t2830.2000-11-13.farmer.ham.txt\n",
            "0258.2000-01-25.farmer.ham.txt\t2831.2000-11-13.farmer.ham.txt\n",
            "0259.2000-01-25.farmer.ham.txt\t2834.2000-11-13.farmer.ham.txt\n",
            "0261.2000-01-25.farmer.ham.txt\t2835.2000-11-13.farmer.ham.txt\n",
            "0262.2000-01-26.farmer.ham.txt\t2836.2000-11-13.farmer.ham.txt\n",
            "0263.2000-01-26.farmer.ham.txt\t2838.2000-11-13.farmer.ham.txt\n",
            "0265.2000-01-26.farmer.ham.txt\t2839.2000-11-14.farmer.ham.txt\n",
            "0267.2000-01-26.farmer.ham.txt\t2841.2000-11-14.farmer.ham.txt\n",
            "0268.2000-01-26.farmer.ham.txt\t2842.2000-11-14.farmer.ham.txt\n",
            "0269.2000-01-27.farmer.ham.txt\t2843.2000-11-14.farmer.ham.txt\n",
            "0270.2000-01-27.farmer.ham.txt\t2844.2000-11-14.farmer.ham.txt\n",
            "0271.2000-01-27.farmer.ham.txt\t2845.2000-11-14.farmer.ham.txt\n",
            "0272.2000-01-28.farmer.ham.txt\t2846.2000-11-14.farmer.ham.txt\n",
            "0273.2000-01-28.farmer.ham.txt\t2847.2000-11-14.farmer.ham.txt\n",
            "0274.2000-01-28.farmer.ham.txt\t2848.2000-11-14.farmer.ham.txt\n",
            "0275.2000-01-28.farmer.ham.txt\t2849.2000-11-14.farmer.ham.txt\n",
            "0276.2000-01-28.farmer.ham.txt\t2850.2000-11-15.farmer.ham.txt\n",
            "0278.2000-01-28.farmer.ham.txt\t2851.2000-11-15.farmer.ham.txt\n",
            "0279.2000-01-31.farmer.ham.txt\t2853.2000-11-15.farmer.ham.txt\n",
            "0280.2000-01-31.farmer.ham.txt\t2854.2000-11-15.farmer.ham.txt\n",
            "0281.2000-01-31.farmer.ham.txt\t2855.2000-11-15.farmer.ham.txt\n",
            "0283.2000-01-31.farmer.ham.txt\t2856.2000-11-15.farmer.ham.txt\n",
            "0284.2000-01-31.farmer.ham.txt\t2857.2000-11-15.farmer.ham.txt\n",
            "0285.2000-01-31.farmer.ham.txt\t2858.2000-11-15.farmer.ham.txt\n",
            "0286.2000-01-31.farmer.ham.txt\t2860.2000-11-15.farmer.ham.txt\n",
            "0287.2000-01-31.farmer.ham.txt\t2861.2000-11-15.farmer.ham.txt\n",
            "0288.2000-01-31.farmer.ham.txt\t2862.2000-11-15.farmer.ham.txt\n",
            "0291.2000-01-31.farmer.ham.txt\t2863.2000-11-16.farmer.ham.txt\n",
            "0292.2000-01-31.farmer.ham.txt\t2864.2000-11-16.farmer.ham.txt\n",
            "0293.2000-01-31.farmer.ham.txt\t2865.2000-11-16.farmer.ham.txt\n",
            "0294.2000-02-01.farmer.ham.txt\t2866.2000-11-16.farmer.ham.txt\n",
            "0295.2000-02-01.farmer.ham.txt\t2868.2000-11-16.farmer.ham.txt\n",
            "0296.2000-02-01.farmer.ham.txt\t2870.2000-11-16.farmer.ham.txt\n",
            "0297.2000-02-01.farmer.ham.txt\t2871.2000-11-16.farmer.ham.txt\n",
            "0299.2000-02-01.farmer.ham.txt\t2872.2000-11-16.farmer.ham.txt\n",
            "0300.2000-02-01.farmer.ham.txt\t2873.2000-11-17.farmer.ham.txt\n",
            "0301.2000-02-02.farmer.ham.txt\t2875.2000-11-17.farmer.ham.txt\n",
            "0302.2000-02-02.farmer.ham.txt\t2876.2000-11-17.farmer.ham.txt\n",
            "0304.2000-02-02.farmer.ham.txt\t2877.2000-11-17.farmer.ham.txt\n",
            "0305.2000-02-02.farmer.ham.txt\t2878.2000-11-17.farmer.ham.txt\n",
            "0306.2000-02-02.farmer.ham.txt\t2879.2000-11-17.farmer.ham.txt\n",
            "0309.2000-02-02.farmer.ham.txt\t2880.2000-11-17.farmer.ham.txt\n",
            "0310.2000-02-02.farmer.ham.txt\t2881.2000-11-17.farmer.ham.txt\n",
            "0311.2000-02-02.farmer.ham.txt\t2882.2000-11-17.farmer.ham.txt\n",
            "0313.2000-02-02.farmer.ham.txt\t2884.2000-11-17.farmer.ham.txt\n",
            "0314.2000-02-02.farmer.ham.txt\t2885.2000-11-19.farmer.ham.txt\n",
            "0315.2000-02-03.farmer.ham.txt\t2887.2000-11-20.farmer.ham.txt\n",
            "0316.2000-02-03.farmer.ham.txt\t2891.2000-11-20.farmer.ham.txt\n",
            "0317.2000-02-03.farmer.ham.txt\t2892.2000-11-20.farmer.ham.txt\n",
            "0318.2000-02-03.farmer.ham.txt\t2893.2000-11-20.farmer.ham.txt\n",
            "0319.2000-02-03.farmer.ham.txt\t2894.2000-11-20.farmer.ham.txt\n",
            "0320.2000-02-03.farmer.ham.txt\t2895.2000-11-20.farmer.ham.txt\n",
            "0321.2000-02-03.farmer.ham.txt\t2896.2000-11-21.farmer.ham.txt\n",
            "0322.2000-02-03.farmer.ham.txt\t2897.2000-11-21.farmer.ham.txt\n",
            "0326.2000-02-03.farmer.ham.txt\t2898.2000-11-21.farmer.ham.txt\n",
            "0329.2000-02-04.farmer.ham.txt\t2901.2000-11-21.farmer.ham.txt\n",
            "0330.2000-02-04.farmer.ham.txt\t2902.2000-11-21.farmer.ham.txt\n",
            "0331.2000-02-04.farmer.ham.txt\t2903.2000-11-21.farmer.ham.txt\n",
            "0333.2000-02-04.farmer.ham.txt\t2904.2000-11-21.farmer.ham.txt\n",
            "0335.2000-02-04.farmer.ham.txt\t2906.2000-11-21.farmer.ham.txt\n",
            "0336.2000-02-04.farmer.ham.txt\t2907.2000-11-21.farmer.ham.txt\n",
            "0338.2000-02-04.farmer.ham.txt\t2908.2000-11-21.farmer.ham.txt\n",
            "0340.2000-02-04.farmer.ham.txt\t2909.2000-11-21.farmer.ham.txt\n",
            "0341.2000-02-04.farmer.ham.txt\t2910.2000-11-21.farmer.ham.txt\n",
            "0343.2000-02-04.farmer.ham.txt\t2911.2000-11-21.farmer.ham.txt\n",
            "0344.2000-02-04.farmer.ham.txt\t2913.2000-11-21.farmer.ham.txt\n",
            "0345.2000-02-04.farmer.ham.txt\t2914.2000-11-21.farmer.ham.txt\n",
            "0346.2000-02-04.farmer.ham.txt\t2915.2000-11-21.farmer.ham.txt\n",
            "0348.2000-02-04.farmer.ham.txt\t2916.2000-11-21.farmer.ham.txt\n",
            "0349.2000-02-04.farmer.ham.txt\t2917.2000-11-22.farmer.ham.txt\n",
            "0350.2000-02-05.farmer.ham.txt\t2918.2000-11-22.farmer.ham.txt\n",
            "0351.2000-02-06.farmer.ham.txt\t2919.2000-11-22.farmer.ham.txt\n",
            "0353.2000-02-07.farmer.ham.txt\t2920.2000-11-22.farmer.ham.txt\n",
            "0354.2000-02-07.farmer.ham.txt\t2921.2000-11-22.farmer.ham.txt\n",
            "0355.2000-02-07.farmer.ham.txt\t2922.2000-11-22.farmer.ham.txt\n",
            "0356.2000-02-07.farmer.ham.txt\t2924.2000-11-22.farmer.ham.txt\n",
            "0358.2000-02-07.farmer.ham.txt\t2925.2000-11-22.farmer.ham.txt\n",
            "0360.2000-02-07.farmer.ham.txt\t2927.2000-11-22.farmer.ham.txt\n",
            "0361.2000-02-07.farmer.ham.txt\t2928.2000-11-24.farmer.ham.txt\n",
            "0362.2000-02-07.farmer.ham.txt\t2930.2000-11-27.farmer.ham.txt\n",
            "0363.2000-02-07.farmer.ham.txt\t2931.2000-11-27.farmer.ham.txt\n",
            "0365.2000-02-07.farmer.ham.txt\t2934.2000-11-27.farmer.ham.txt\n",
            "0366.2000-02-07.farmer.ham.txt\t2935.2000-11-27.farmer.ham.txt\n",
            "0368.2000-02-08.farmer.ham.txt\t2936.2000-11-27.farmer.ham.txt\n",
            "0369.2000-02-08.farmer.ham.txt\t2937.2000-11-27.farmer.ham.txt\n",
            "0370.2000-02-08.farmer.ham.txt\t2938.2000-11-27.farmer.ham.txt\n",
            "0371.2000-02-08.farmer.ham.txt\t2940.2000-11-27.farmer.ham.txt\n",
            "0372.2000-02-08.farmer.ham.txt\t2941.2000-11-27.farmer.ham.txt\n",
            "0374.2000-02-08.farmer.ham.txt\t2943.2000-11-27.farmer.ham.txt\n",
            "0375.2000-02-08.farmer.ham.txt\t2945.2000-11-27.farmer.ham.txt\n",
            "0376.2000-02-09.farmer.ham.txt\t2946.2000-11-27.farmer.ham.txt\n",
            "0379.2000-02-09.farmer.ham.txt\t2947.2000-11-27.farmer.ham.txt\n",
            "0380.2000-02-09.farmer.ham.txt\t2949.2000-11-27.farmer.ham.txt\n",
            "0382.2000-02-09.farmer.ham.txt\t2950.2000-11-27.farmer.ham.txt\n",
            "0383.2000-02-09.farmer.ham.txt\t2951.2000-11-27.farmer.ham.txt\n",
            "0384.2000-02-09.farmer.ham.txt\t2952.2000-11-27.farmer.ham.txt\n",
            "0386.2000-02-09.farmer.ham.txt\t2954.2000-11-27.farmer.ham.txt\n",
            "0388.2000-02-09.farmer.ham.txt\t2958.2000-11-27.farmer.ham.txt\n",
            "0390.2000-02-09.farmer.ham.txt\t2959.2000-11-28.farmer.ham.txt\n",
            "0393.2000-02-09.farmer.ham.txt\t2961.2000-11-28.farmer.ham.txt\n",
            "0394.2000-02-10.farmer.ham.txt\t2962.2000-11-28.farmer.ham.txt\n",
            "0395.2000-02-10.farmer.ham.txt\t2963.2000-11-28.farmer.ham.txt\n",
            "0397.2000-02-10.farmer.ham.txt\t2964.2000-11-28.farmer.ham.txt\n",
            "0399.2000-02-10.farmer.ham.txt\t2965.2000-11-29.farmer.ham.txt\n",
            "0400.2000-02-10.farmer.ham.txt\t2966.2000-11-29.farmer.ham.txt\n",
            "0402.2000-02-11.farmer.ham.txt\t2968.2000-11-29.farmer.ham.txt\n",
            "0403.2000-02-11.farmer.ham.txt\t2969.2000-11-29.farmer.ham.txt\n",
            "0404.2000-02-14.farmer.ham.txt\t2970.2000-11-29.farmer.ham.txt\n",
            "0405.2000-02-14.farmer.ham.txt\t2972.2000-11-29.farmer.ham.txt\n",
            "0406.2000-02-14.farmer.ham.txt\t2973.2000-11-29.farmer.ham.txt\n",
            "0408.2000-02-14.farmer.ham.txt\t2974.2000-11-29.farmer.ham.txt\n",
            "0409.2000-02-14.farmer.ham.txt\t2975.2000-11-29.farmer.ham.txt\n",
            "0410.2000-02-14.farmer.ham.txt\t2976.2000-11-30.farmer.ham.txt\n",
            "0411.2000-02-14.farmer.ham.txt\t2977.2000-11-30.farmer.ham.txt\n",
            "0412.2000-02-14.farmer.ham.txt\t2979.2000-11-30.farmer.ham.txt\n",
            "0413.2000-02-14.farmer.ham.txt\t2980.2000-11-30.farmer.ham.txt\n",
            "0414.2000-02-14.farmer.ham.txt\t2982.2000-11-30.farmer.ham.txt\n",
            "0415.2000-02-15.farmer.ham.txt\t2983.2000-11-30.farmer.ham.txt\n",
            "0416.2000-02-15.farmer.ham.txt\t2985.2000-11-30.farmer.ham.txt\n",
            "0418.2000-02-15.farmer.ham.txt\t2986.2000-11-30.farmer.ham.txt\n",
            "0419.2000-02-15.farmer.ham.txt\t2989.2000-12-01.farmer.ham.txt\n",
            "0420.2000-02-15.farmer.ham.txt\t2990.2000-12-01.farmer.ham.txt\n",
            "0421.2000-02-16.farmer.ham.txt\t2991.2000-12-01.farmer.ham.txt\n",
            "0422.2000-02-16.farmer.ham.txt\t2992.2000-12-01.farmer.ham.txt\n",
            "0423.2000-02-16.farmer.ham.txt\t2993.2000-12-01.farmer.ham.txt\n",
            "0425.2000-02-16.farmer.ham.txt\t2994.2000-12-01.farmer.ham.txt\n",
            "0426.2000-02-16.farmer.ham.txt\t2996.2000-12-03.farmer.ham.txt\n",
            "0427.2000-02-16.farmer.ham.txt\t2997.2000-12-04.farmer.ham.txt\n",
            "0428.2000-02-16.farmer.ham.txt\t2998.2000-12-04.farmer.ham.txt\n",
            "0429.2000-02-17.farmer.ham.txt\t2999.2000-12-04.farmer.ham.txt\n",
            "0430.2000-02-17.farmer.ham.txt\t3000.2000-12-04.farmer.ham.txt\n",
            "0433.2000-02-17.farmer.ham.txt\t3002.2000-12-04.farmer.ham.txt\n",
            "0435.2000-02-17.farmer.ham.txt\t3003.2000-12-04.farmer.ham.txt\n",
            "0436.2000-02-17.farmer.ham.txt\t3004.2000-12-04.farmer.ham.txt\n",
            "0437.2000-02-17.farmer.ham.txt\t3006.2000-12-04.farmer.ham.txt\n",
            "0440.2000-02-17.farmer.ham.txt\t3007.2000-12-04.farmer.ham.txt\n",
            "0441.2000-02-18.farmer.ham.txt\t3008.2000-12-05.farmer.ham.txt\n",
            "0442.2000-02-18.farmer.ham.txt\t3011.2000-12-05.farmer.ham.txt\n",
            "0443.2000-02-18.farmer.ham.txt\t3014.2000-12-05.farmer.ham.txt\n",
            "0444.2000-02-18.farmer.ham.txt\t3015.2000-12-05.farmer.ham.txt\n",
            "0446.2000-02-18.farmer.ham.txt\t3016.2000-12-05.farmer.ham.txt\n",
            "0447.2000-02-21.farmer.ham.txt\t3017.2000-12-05.farmer.ham.txt\n",
            "0448.2000-02-22.farmer.ham.txt\t3019.2000-12-05.farmer.ham.txt\n",
            "0450.2000-02-22.farmer.ham.txt\t3021.2000-12-05.farmer.ham.txt\n",
            "0452.2000-02-22.farmer.ham.txt\t3022.2000-12-05.farmer.ham.txt\n",
            "0453.2000-02-22.farmer.ham.txt\t3024.2000-12-05.farmer.ham.txt\n",
            "0456.2000-02-22.farmer.ham.txt\t3025.2000-12-05.farmer.ham.txt\n",
            "0457.2000-02-22.farmer.ham.txt\t3027.2000-12-05.farmer.ham.txt\n",
            "0458.2000-02-22.farmer.ham.txt\t3028.2000-12-05.farmer.ham.txt\n",
            "0459.2000-02-22.farmer.ham.txt\t3030.2000-12-05.farmer.ham.txt\n",
            "0460.2000-02-22.farmer.ham.txt\t3032.2000-12-06.farmer.ham.txt\n",
            "0461.2000-02-22.farmer.ham.txt\t3034.2000-12-06.farmer.ham.txt\n",
            "0464.2000-02-22.farmer.ham.txt\t3036.2000-12-06.farmer.ham.txt\n",
            "0465.2000-02-22.farmer.ham.txt\t3037.2000-12-06.farmer.ham.txt\n",
            "0466.2000-02-23.farmer.ham.txt\t3038.2000-12-06.farmer.ham.txt\n",
            "0467.2000-02-23.farmer.ham.txt\t3039.2000-12-07.farmer.ham.txt\n",
            "0468.2000-02-23.farmer.ham.txt\t3041.2000-12-07.farmer.ham.txt\n",
            "0469.2000-02-23.farmer.ham.txt\t3043.2000-12-07.farmer.ham.txt\n",
            "0470.2000-02-23.farmer.ham.txt\t3044.2000-12-07.farmer.ham.txt\n",
            "0471.2000-02-23.farmer.ham.txt\t3045.2000-12-07.farmer.ham.txt\n",
            "0472.2000-02-23.farmer.ham.txt\t3046.2000-12-07.farmer.ham.txt\n",
            "0474.2000-02-23.farmer.ham.txt\t3047.2000-12-07.farmer.ham.txt\n",
            "0475.2000-02-24.farmer.ham.txt\t3048.2000-12-07.farmer.ham.txt\n",
            "0476.2000-02-24.farmer.ham.txt\t3050.2000-12-08.farmer.ham.txt\n",
            "0478.2000-02-24.farmer.ham.txt\t3051.2000-12-08.farmer.ham.txt\n",
            "0479.2000-02-24.farmer.ham.txt\t3052.2000-12-08.farmer.ham.txt\n",
            "0481.2000-02-24.farmer.ham.txt\t3053.2000-12-08.farmer.ham.txt\n",
            "0482.2000-02-24.farmer.ham.txt\t3054.2000-12-11.farmer.ham.txt\n",
            "0483.2000-02-24.farmer.ham.txt\t3056.2000-12-11.farmer.ham.txt\n",
            "0486.2000-02-24.farmer.ham.txt\t3057.2000-12-11.farmer.ham.txt\n",
            "0487.2000-02-24.farmer.ham.txt\t3058.2000-12-11.farmer.ham.txt\n",
            "0488.2000-02-24.farmer.ham.txt\t3059.2000-12-11.farmer.ham.txt\n",
            "0489.2000-02-24.farmer.ham.txt\t3061.2000-12-11.farmer.ham.txt\n",
            "0490.2000-02-25.farmer.ham.txt\t3062.2000-12-11.farmer.ham.txt\n",
            "0491.2000-02-25.farmer.ham.txt\t3063.2000-12-11.farmer.ham.txt\n",
            "0493.2000-02-25.farmer.ham.txt\t3064.2000-12-11.farmer.ham.txt\n",
            "0494.2000-02-25.farmer.ham.txt\t3066.2000-12-11.farmer.ham.txt\n",
            "0495.2000-02-25.farmer.ham.txt\t3067.2000-12-12.farmer.ham.txt\n",
            "0497.2000-02-25.farmer.ham.txt\t3068.2000-12-12.farmer.ham.txt\n",
            "0498.2000-02-25.farmer.ham.txt\t3070.2000-12-12.farmer.ham.txt\n",
            "0499.2000-02-25.farmer.ham.txt\t3071.2000-12-12.farmer.ham.txt\n",
            "0500.2000-02-28.farmer.ham.txt\t3073.2000-12-12.farmer.ham.txt\n",
            "0502.2000-02-28.farmer.ham.txt\t3075.2000-12-12.farmer.ham.txt\n",
            "0503.2000-02-28.farmer.ham.txt\t3076.2000-12-12.farmer.ham.txt\n",
            "0504.2000-02-28.farmer.ham.txt\t3077.2000-12-12.farmer.ham.txt\n",
            "0506.2000-02-28.farmer.ham.txt\t3078.2000-12-12.farmer.ham.txt\n",
            "0507.2000-02-28.farmer.ham.txt\t3080.2000-12-12.farmer.ham.txt\n",
            "0508.2000-02-28.farmer.ham.txt\t3081.2000-12-12.farmer.ham.txt\n",
            "0509.2000-02-29.farmer.ham.txt\t3082.2000-12-12.farmer.ham.txt\n",
            "0510.2000-02-29.farmer.ham.txt\t3084.2000-12-13.farmer.ham.txt\n",
            "0513.2000-02-29.farmer.ham.txt\t3085.2000-12-13.farmer.ham.txt\n",
            "0514.2000-02-29.farmer.ham.txt\t3086.2000-12-13.farmer.ham.txt\n",
            "0515.2000-02-29.farmer.ham.txt\t3088.2000-12-13.farmer.ham.txt\n",
            "0516.2000-02-29.farmer.ham.txt\t3089.2000-12-13.farmer.ham.txt\n",
            "0517.2000-02-29.farmer.ham.txt\t3091.2000-12-13.farmer.ham.txt\n",
            "0518.2000-02-29.farmer.ham.txt\t3092.2000-12-13.farmer.ham.txt\n",
            "0519.2000-02-29.farmer.ham.txt\t3093.2000-12-13.farmer.ham.txt\n",
            "0521.2000-03-01.farmer.ham.txt\t3094.2000-12-13.farmer.ham.txt\n",
            "0522.2000-03-01.farmer.ham.txt\t3095.2000-12-13.farmer.ham.txt\n",
            "0523.2000-03-01.farmer.ham.txt\t3096.2000-12-14.farmer.ham.txt\n",
            "0524.2000-03-01.farmer.ham.txt\t3097.2000-12-14.farmer.ham.txt\n",
            "0525.2000-03-01.farmer.ham.txt\t3098.2000-12-14.farmer.ham.txt\n",
            "0526.2000-03-01.farmer.ham.txt\t3099.2000-12-14.farmer.ham.txt\n",
            "0527.2000-03-01.farmer.ham.txt\t3100.2000-12-14.farmer.ham.txt\n",
            "0530.2000-03-02.farmer.ham.txt\t3101.2000-12-14.farmer.ham.txt\n",
            "0531.2000-03-02.farmer.ham.txt\t3102.2000-12-14.farmer.ham.txt\n",
            "0532.2000-03-02.farmer.ham.txt\t3104.2000-12-14.farmer.ham.txt\n",
            "0534.2000-03-02.farmer.ham.txt\t3106.2000-12-14.farmer.ham.txt\n",
            "0535.2000-03-02.farmer.ham.txt\t3108.2000-12-15.farmer.ham.txt\n",
            "0536.2000-03-03.farmer.ham.txt\t3109.2000-12-15.farmer.ham.txt\n",
            "0537.2000-03-03.farmer.ham.txt\t3111.2000-12-15.farmer.ham.txt\n",
            "0539.2000-03-03.farmer.ham.txt\t3114.2000-12-15.farmer.ham.txt\n",
            "0540.2000-03-03.farmer.ham.txt\t3115.2000-12-15.farmer.ham.txt\n",
            "0541.2000-03-03.farmer.ham.txt\t3117.2000-12-15.farmer.ham.txt\n",
            "0543.2000-03-03.farmer.ham.txt\t3118.2000-12-15.farmer.ham.txt\n",
            "0545.2000-03-03.farmer.ham.txt\t3119.2000-12-18.farmer.ham.txt\n",
            "0546.2000-03-03.farmer.ham.txt\t3120.2000-12-18.farmer.ham.txt\n",
            "0548.2000-03-03.farmer.ham.txt\t3121.2000-12-18.farmer.ham.txt\n",
            "0549.2000-03-03.farmer.ham.txt\t3122.2000-12-18.farmer.ham.txt\n",
            "0550.2000-03-03.farmer.ham.txt\t3125.2000-12-19.farmer.ham.txt\n",
            "0551.2000-03-03.farmer.ham.txt\t3126.2000-12-19.farmer.ham.txt\n",
            "0552.2000-03-06.farmer.ham.txt\t3127.2000-12-19.farmer.ham.txt\n",
            "0553.2000-03-06.farmer.ham.txt\t3128.2000-12-19.farmer.ham.txt\n",
            "0554.2000-03-06.farmer.ham.txt\t3129.2000-12-19.farmer.ham.txt\n",
            "0556.2000-03-06.farmer.ham.txt\t3132.2000-12-19.farmer.ham.txt\n",
            "0558.2000-03-06.farmer.ham.txt\t3133.2000-12-19.farmer.ham.txt\n",
            "0560.2000-03-06.farmer.ham.txt\t3134.2000-12-19.farmer.ham.txt\n",
            "0562.2000-03-06.farmer.ham.txt\t3135.2000-12-19.farmer.ham.txt\n",
            "0563.2000-03-06.farmer.ham.txt\t3136.2000-12-19.farmer.ham.txt\n",
            "0564.2000-03-07.farmer.ham.txt\t3137.2000-12-19.farmer.ham.txt\n",
            "0565.2000-03-07.farmer.ham.txt\t3138.2000-12-19.farmer.ham.txt\n",
            "0566.2000-03-07.farmer.ham.txt\t3139.2000-12-19.farmer.ham.txt\n",
            "0568.2000-03-07.farmer.ham.txt\t3140.2000-12-19.farmer.ham.txt\n",
            "0570.2000-03-07.farmer.ham.txt\t3141.2000-12-19.farmer.ham.txt\n",
            "0572.2000-03-07.farmer.ham.txt\t3142.2000-12-20.farmer.ham.txt\n",
            "0573.2000-03-07.farmer.ham.txt\t3143.2000-12-20.farmer.ham.txt\n",
            "0576.2000-03-07.farmer.ham.txt\t3145.2000-12-20.farmer.ham.txt\n",
            "0579.2000-03-08.farmer.ham.txt\t3146.2000-12-20.farmer.ham.txt\n",
            "0581.2000-03-08.farmer.ham.txt\t3147.2000-12-20.farmer.ham.txt\n",
            "0583.2000-03-08.farmer.ham.txt\t3148.2000-12-20.farmer.ham.txt\n",
            "0584.2000-03-08.farmer.ham.txt\t3149.2000-12-20.farmer.ham.txt\n",
            "0586.2000-03-08.farmer.ham.txt\t3150.2000-12-20.farmer.ham.txt\n",
            "0587.2000-03-10.farmer.ham.txt\t3151.2000-12-20.farmer.ham.txt\n",
            "0590.2000-03-10.farmer.ham.txt\t3152.2000-12-20.farmer.ham.txt\n",
            "0591.2000-03-10.farmer.ham.txt\t3154.2000-12-20.farmer.ham.txt\n",
            "0592.2000-03-10.farmer.ham.txt\t3155.2000-12-20.farmer.ham.txt\n",
            "0593.2000-03-10.farmer.ham.txt\t3156.2000-12-20.farmer.ham.txt\n",
            "0594.2000-03-11.farmer.ham.txt\t3157.2000-12-20.farmer.ham.txt\n",
            "0597.2000-03-11.farmer.ham.txt\t3158.2000-12-21.farmer.ham.txt\n",
            "0599.2000-03-11.farmer.ham.txt\t3160.2000-12-21.farmer.ham.txt\n",
            "0600.2000-03-13.farmer.ham.txt\t3162.2000-12-21.farmer.ham.txt\n",
            "0601.2000-03-13.farmer.ham.txt\t3163.2000-12-21.farmer.ham.txt\n",
            "0602.2000-03-13.farmer.ham.txt\t3168.2000-12-21.farmer.ham.txt\n",
            "0603.2000-03-13.farmer.ham.txt\t3169.2000-12-21.farmer.ham.txt\n",
            "0604.2000-03-13.farmer.ham.txt\t3171.2000-12-21.farmer.ham.txt\n",
            "0605.2000-03-13.farmer.ham.txt\t3174.2000-12-21.farmer.ham.txt\n",
            "0606.2000-03-13.farmer.ham.txt\t3177.2000-12-21.farmer.ham.txt\n",
            "0607.2000-03-13.farmer.ham.txt\t3179.2000-12-22.farmer.ham.txt\n",
            "0608.2000-03-13.farmer.ham.txt\t3182.2000-12-22.farmer.ham.txt\n",
            "0609.2000-03-14.farmer.ham.txt\t3185.2000-12-22.farmer.ham.txt\n",
            "0610.2000-03-14.farmer.ham.txt\t3186.2000-12-26.farmer.ham.txt\n",
            "0611.2000-03-14.farmer.ham.txt\t3187.2000-12-26.farmer.ham.txt\n",
            "0613.2000-03-14.farmer.ham.txt\t3188.2000-12-26.farmer.ham.txt\n",
            "0614.2000-03-15.farmer.ham.txt\t3189.2000-12-26.farmer.ham.txt\n",
            "0616.2000-03-15.farmer.ham.txt\t3191.2000-12-26.farmer.ham.txt\n",
            "0617.2000-03-15.farmer.ham.txt\t3192.2000-12-26.farmer.ham.txt\n",
            "0618.2000-03-15.farmer.ham.txt\t3194.2000-12-27.farmer.ham.txt\n",
            "0619.2000-03-17.farmer.ham.txt\t3196.2000-12-27.farmer.ham.txt\n",
            "0620.2000-03-17.farmer.ham.txt\t3197.2000-12-27.farmer.ham.txt\n",
            "0623.2000-03-18.farmer.ham.txt\t3198.2000-12-27.farmer.ham.txt\n",
            "0624.2000-03-19.farmer.ham.txt\t3199.2000-12-27.farmer.ham.txt\n",
            "0627.2000-03-20.farmer.ham.txt\t3200.2000-12-27.farmer.ham.txt\n",
            "0628.2000-03-20.farmer.ham.txt\t3202.2000-12-27.farmer.ham.txt\n",
            "0629.2000-03-20.farmer.ham.txt\t3203.2000-12-27.farmer.ham.txt\n",
            "0631.2000-03-20.farmer.ham.txt\t3204.2000-12-28.farmer.ham.txt\n",
            "0632.2000-03-20.farmer.ham.txt\t3205.2000-12-28.farmer.ham.txt\n",
            "0633.2000-03-20.farmer.ham.txt\t3206.2000-12-28.farmer.ham.txt\n",
            "0635.2000-03-20.farmer.ham.txt\t3208.2000-12-28.farmer.ham.txt\n",
            "0636.2000-03-20.farmer.ham.txt\t3209.2000-12-28.farmer.ham.txt\n",
            "0637.2000-03-20.farmer.ham.txt\t3210.2000-12-28.farmer.ham.txt\n",
            "0638.2000-03-20.farmer.ham.txt\t3211.2000-12-28.farmer.ham.txt\n",
            "0639.2000-03-20.farmer.ham.txt\t3212.2000-12-28.farmer.ham.txt\n",
            "0641.2000-03-20.farmer.ham.txt\t3213.2000-12-28.farmer.ham.txt\n",
            "0642.2000-03-20.farmer.ham.txt\t3215.2000-12-28.farmer.ham.txt\n",
            "0643.2000-03-20.farmer.ham.txt\t3216.2000-12-28.farmer.ham.txt\n",
            "0645.2000-03-20.farmer.ham.txt\t3219.2000-12-28.farmer.ham.txt\n",
            "0646.2000-03-21.farmer.ham.txt\t3220.2000-12-28.farmer.ham.txt\n",
            "0648.2000-03-21.farmer.ham.txt\t3223.2000-12-29.farmer.ham.txt\n",
            "0649.2000-03-21.farmer.ham.txt\t3224.2000-12-29.farmer.ham.txt\n",
            "0650.2000-03-21.farmer.ham.txt\t3225.2000-12-29.farmer.ham.txt\n",
            "0652.2000-03-21.farmer.ham.txt\t3226.2001-01-01.farmer.ham.txt\n",
            "0653.2000-03-21.farmer.ham.txt\t3227.2001-01-01.farmer.ham.txt\n",
            "0654.2000-03-21.farmer.ham.txt\t3228.2001-01-01.farmer.ham.txt\n",
            "0655.2000-03-21.farmer.ham.txt\t3229.2001-01-02.farmer.ham.txt\n",
            "0656.2000-03-21.farmer.ham.txt\t3231.2001-01-02.farmer.ham.txt\n",
            "0659.2000-03-21.farmer.ham.txt\t3232.2001-01-02.farmer.ham.txt\n",
            "0662.2000-03-21.farmer.ham.txt\t3233.2001-01-02.farmer.ham.txt\n",
            "0664.2000-03-21.farmer.ham.txt\t3234.2001-01-02.farmer.ham.txt\n",
            "0665.2000-03-21.farmer.ham.txt\t3236.2001-01-02.farmer.ham.txt\n",
            "0666.2000-03-21.farmer.ham.txt\t3237.2001-01-02.farmer.ham.txt\n",
            "0669.2000-03-21.farmer.ham.txt\t3240.2001-01-02.farmer.ham.txt\n",
            "0672.2000-03-21.farmer.ham.txt\t3242.2001-01-02.farmer.ham.txt\n",
            "0675.2000-03-21.farmer.ham.txt\t3243.2001-01-03.farmer.ham.txt\n",
            "0676.2000-03-22.farmer.ham.txt\t3244.2001-01-03.farmer.ham.txt\n",
            "0677.2000-03-22.farmer.ham.txt\t3246.2001-01-03.farmer.ham.txt\n",
            "0678.2000-03-22.farmer.ham.txt\t3249.2001-01-03.farmer.ham.txt\n",
            "0679.2000-03-22.farmer.ham.txt\t3250.2001-01-03.farmer.ham.txt\n",
            "0680.2000-03-22.farmer.ham.txt\t3251.2001-01-03.farmer.ham.txt\n",
            "0681.2000-03-22.farmer.ham.txt\t3252.2001-01-03.farmer.ham.txt\n",
            "0683.2000-03-22.farmer.ham.txt\t3253.2001-01-04.farmer.ham.txt\n",
            "0684.2000-03-22.farmer.ham.txt\t3254.2001-01-04.farmer.ham.txt\n",
            "0685.2000-03-22.farmer.ham.txt\t3256.2001-01-04.farmer.ham.txt\n",
            "0688.2000-03-22.farmer.ham.txt\t3258.2001-01-04.farmer.ham.txt\n",
            "0689.2000-03-22.farmer.ham.txt\t3259.2001-01-05.farmer.ham.txt\n",
            "0690.2000-03-22.farmer.ham.txt\t3260.2001-01-05.farmer.ham.txt\n",
            "0691.2000-03-22.farmer.ham.txt\t3261.2001-01-05.farmer.ham.txt\n",
            "0694.2000-03-22.farmer.ham.txt\t3263.2001-01-05.farmer.ham.txt\n",
            "0696.2000-03-22.farmer.ham.txt\t3264.2001-01-05.farmer.ham.txt\n",
            "0698.2000-03-22.farmer.ham.txt\t3267.2001-01-05.farmer.ham.txt\n",
            "0700.2000-03-23.farmer.ham.txt\t3269.2001-01-05.farmer.ham.txt\n",
            "0701.2000-03-23.farmer.ham.txt\t3270.2001-01-05.farmer.ham.txt\n",
            "0702.2000-03-23.farmer.ham.txt\t3271.2001-01-06.farmer.ham.txt\n",
            "0703.2000-03-23.farmer.ham.txt\t3272.2001-01-08.farmer.ham.txt\n",
            "0704.2000-03-23.farmer.ham.txt\t3273.2001-01-08.farmer.ham.txt\n",
            "0706.2000-03-23.farmer.ham.txt\t3274.2001-01-08.farmer.ham.txt\n",
            "0708.2000-03-23.farmer.ham.txt\t3276.2001-01-08.farmer.ham.txt\n",
            "0711.2000-03-23.farmer.ham.txt\t3277.2001-01-08.farmer.ham.txt\n",
            "0713.2000-03-23.farmer.ham.txt\t3279.2001-01-08.farmer.ham.txt\n",
            "0714.2000-03-24.farmer.ham.txt\t3280.2001-01-08.farmer.ham.txt\n",
            "0715.2000-03-24.farmer.ham.txt\t3282.2001-01-08.farmer.ham.txt\n",
            "0716.2000-03-24.farmer.ham.txt\t3283.2001-01-09.farmer.ham.txt\n",
            "0719.2000-03-24.farmer.ham.txt\t3284.2001-01-09.farmer.ham.txt\n",
            "0720.2000-03-24.farmer.ham.txt\t3285.2001-01-09.farmer.ham.txt\n",
            "0722.2000-03-24.farmer.ham.txt\t3286.2001-01-09.farmer.ham.txt\n",
            "0724.2000-03-24.farmer.ham.txt\t3287.2001-01-09.farmer.ham.txt\n",
            "0725.2000-03-24.farmer.ham.txt\t3289.2001-01-09.farmer.ham.txt\n",
            "0727.2000-03-24.farmer.ham.txt\t3290.2001-01-09.farmer.ham.txt\n",
            "0728.2000-03-25.farmer.ham.txt\t3292.2001-01-09.farmer.ham.txt\n",
            "0729.2000-03-26.farmer.ham.txt\t3293.2001-01-10.farmer.ham.txt\n",
            "0730.2000-03-27.farmer.ham.txt\t3294.2001-01-10.farmer.ham.txt\n",
            "0731.2000-03-27.farmer.ham.txt\t3295.2001-01-10.farmer.ham.txt\n",
            "0732.2000-03-27.farmer.ham.txt\t3296.2001-01-10.farmer.ham.txt\n",
            "0735.2000-03-27.farmer.ham.txt\t3297.2001-01-10.farmer.ham.txt\n",
            "0736.2000-03-27.farmer.ham.txt\t3298.2001-01-10.farmer.ham.txt\n",
            "0738.2000-03-27.farmer.ham.txt\t3300.2001-01-10.farmer.ham.txt\n",
            "0739.2000-03-27.farmer.ham.txt\t3301.2001-01-10.farmer.ham.txt\n",
            "0740.2000-03-27.farmer.ham.txt\t3303.2001-01-10.farmer.ham.txt\n",
            "0741.2000-03-27.farmer.ham.txt\t3305.2001-01-10.farmer.ham.txt\n",
            "0742.2000-03-27.farmer.ham.txt\t3306.2001-01-10.farmer.ham.txt\n",
            "0743.2000-03-27.farmer.ham.txt\t3307.2001-01-10.farmer.ham.txt\n",
            "0744.2000-03-27.farmer.ham.txt\t3308.2001-01-10.farmer.ham.txt\n",
            "0745.2000-03-27.farmer.ham.txt\t3309.2001-01-10.farmer.ham.txt\n",
            "0748.2000-03-27.farmer.ham.txt\t3310.2001-01-10.farmer.ham.txt\n",
            "0749.2000-03-28.farmer.ham.txt\t3311.2001-01-10.farmer.ham.txt\n",
            "0752.2000-03-28.farmer.ham.txt\t3314.2001-01-10.farmer.ham.txt\n",
            "0753.2000-03-28.farmer.ham.txt\t3316.2001-01-11.farmer.ham.txt\n",
            "0755.2000-03-28.farmer.ham.txt\t3317.2001-01-11.farmer.ham.txt\n",
            "0756.2000-03-28.farmer.ham.txt\t3318.2001-01-11.farmer.ham.txt\n",
            "0757.2000-03-28.farmer.ham.txt\t3320.2001-01-11.farmer.ham.txt\n",
            "0759.2000-03-28.farmer.ham.txt\t3323.2001-01-11.farmer.ham.txt\n",
            "0761.2000-03-28.farmer.ham.txt\t3324.2001-01-11.farmer.ham.txt\n",
            "0765.2000-03-28.farmer.ham.txt\t3325.2001-01-11.farmer.ham.txt\n",
            "0766.2000-03-28.farmer.ham.txt\t3326.2001-01-11.farmer.ham.txt\n",
            "0768.2000-03-28.farmer.ham.txt\t3327.2001-01-11.farmer.ham.txt\n",
            "0769.2000-03-28.farmer.ham.txt\t3329.2001-01-12.farmer.ham.txt\n",
            "0770.2000-03-28.farmer.ham.txt\t3331.2001-01-12.farmer.ham.txt\n",
            "0771.2000-03-28.farmer.ham.txt\t3333.2001-01-12.farmer.ham.txt\n",
            "0772.2000-03-28.farmer.ham.txt\t3334.2001-01-12.farmer.ham.txt\n",
            "0773.2000-03-28.farmer.ham.txt\t3335.2001-01-12.farmer.ham.txt\n",
            "0774.2000-03-28.farmer.ham.txt\t3336.2001-01-12.farmer.ham.txt\n",
            "0776.2000-03-28.farmer.ham.txt\t3337.2001-01-12.farmer.ham.txt\n",
            "0777.2000-03-28.farmer.ham.txt\t3339.2001-01-12.farmer.ham.txt\n",
            "0778.2000-03-28.farmer.ham.txt\t3340.2001-01-12.farmer.ham.txt\n",
            "0780.2000-03-28.farmer.ham.txt\t3341.2001-01-12.farmer.ham.txt\n",
            "0781.2000-03-29.farmer.ham.txt\t3342.2001-01-12.farmer.ham.txt\n",
            "0782.2000-03-29.farmer.ham.txt\t3344.2001-01-12.farmer.ham.txt\n",
            "0783.2000-03-29.farmer.ham.txt\t3345.2001-01-13.farmer.ham.txt\n",
            "0785.2000-03-29.farmer.ham.txt\t3347.2001-01-15.farmer.ham.txt\n",
            "0787.2000-03-29.farmer.ham.txt\t3348.2001-01-15.farmer.ham.txt\n",
            "0789.2000-03-29.farmer.ham.txt\t3349.2001-01-15.farmer.ham.txt\n",
            "0790.2000-03-29.farmer.ham.txt\t3350.2001-01-16.farmer.ham.txt\n",
            "0792.2000-03-29.farmer.ham.txt\t3351.2001-01-16.farmer.ham.txt\n",
            "0793.2000-03-29.farmer.ham.txt\t3354.2001-01-16.farmer.ham.txt\n",
            "0795.2000-03-30.farmer.ham.txt\t3355.2001-01-16.farmer.ham.txt\n",
            "0796.2000-03-30.farmer.ham.txt\t3356.2001-01-16.farmer.ham.txt\n",
            "0798.2000-03-31.farmer.ham.txt\t3359.2001-01-17.farmer.ham.txt\n",
            "0800.2000-03-31.farmer.ham.txt\t3360.2001-01-17.farmer.ham.txt\n",
            "0801.2000-03-31.farmer.ham.txt\t3362.2001-01-17.farmer.ham.txt\n",
            "0802.2000-03-31.farmer.ham.txt\t3363.2001-01-17.farmer.ham.txt\n",
            "0804.2000-03-31.farmer.ham.txt\t3365.2001-01-17.farmer.ham.txt\n",
            "0806.2000-03-31.farmer.ham.txt\t3366.2001-01-17.farmer.ham.txt\n",
            "0807.2000-03-31.farmer.ham.txt\t3368.2001-01-18.farmer.ham.txt\n",
            "0808.2000-03-31.farmer.ham.txt\t3369.2001-01-18.farmer.ham.txt\n",
            "0809.2000-03-31.farmer.ham.txt\t3370.2001-01-18.farmer.ham.txt\n",
            "0812.2000-04-03.farmer.ham.txt\t3372.2001-01-18.farmer.ham.txt\n",
            "0813.2000-04-03.farmer.ham.txt\t3373.2001-01-18.farmer.ham.txt\n",
            "0815.2000-04-03.farmer.ham.txt\t3374.2001-01-18.farmer.ham.txt\n",
            "0816.2000-04-03.farmer.ham.txt\t3375.2001-01-19.farmer.ham.txt\n",
            "0817.2000-04-03.farmer.ham.txt\t3376.2001-01-19.farmer.ham.txt\n",
            "0818.2000-04-03.farmer.ham.txt\t3378.2001-01-19.farmer.ham.txt\n",
            "0819.2000-04-03.farmer.ham.txt\t3379.2001-01-19.farmer.ham.txt\n",
            "0821.2000-04-03.farmer.ham.txt\t3380.2001-01-19.farmer.ham.txt\n",
            "0822.2000-04-03.farmer.ham.txt\t3381.2001-01-19.farmer.ham.txt\n",
            "0823.2000-04-03.farmer.ham.txt\t3382.2001-01-20.farmer.ham.txt\n",
            "0824.2000-04-03.farmer.ham.txt\t3385.2001-01-21.farmer.ham.txt\n",
            "0825.2000-04-03.farmer.ham.txt\t3386.2001-01-22.farmer.ham.txt\n",
            "0826.2000-04-03.farmer.ham.txt\t3387.2001-01-22.farmer.ham.txt\n",
            "0827.2000-04-04.farmer.ham.txt\t3389.2001-01-22.farmer.ham.txt\n",
            "0828.2000-04-04.farmer.ham.txt\t3390.2001-01-22.farmer.ham.txt\n",
            "0829.2000-04-04.farmer.ham.txt\t3391.2001-01-22.farmer.ham.txt\n",
            "0831.2000-04-04.farmer.ham.txt\t3392.2001-01-22.farmer.ham.txt\n",
            "0832.2000-04-04.farmer.ham.txt\t3393.2001-01-22.farmer.ham.txt\n",
            "0833.2000-04-04.farmer.ham.txt\t3394.2001-01-22.farmer.ham.txt\n",
            "0834.2000-04-04.farmer.ham.txt\t3396.2001-01-22.farmer.ham.txt\n",
            "0837.2000-04-04.farmer.ham.txt\t3399.2001-01-23.farmer.ham.txt\n",
            "0839.2000-04-04.farmer.ham.txt\t3401.2001-01-23.farmer.ham.txt\n",
            "0841.2000-04-04.farmer.ham.txt\t3402.2001-01-23.farmer.ham.txt\n",
            "0843.2000-04-04.farmer.ham.txt\t3403.2001-01-23.farmer.ham.txt\n",
            "0845.2000-04-04.farmer.ham.txt\t3404.2001-01-23.farmer.ham.txt\n",
            "0846.2000-04-04.farmer.ham.txt\t3405.2001-01-23.farmer.ham.txt\n",
            "0848.2000-04-05.farmer.ham.txt\t3407.2001-01-23.farmer.ham.txt\n",
            "0850.2000-04-05.farmer.ham.txt\t3409.2001-01-23.farmer.ham.txt\n",
            "0851.2000-04-05.farmer.ham.txt\t3410.2001-01-24.farmer.ham.txt\n",
            "0852.2000-04-05.farmer.ham.txt\t3411.2001-01-24.farmer.ham.txt\n",
            "0853.2000-04-05.farmer.ham.txt\t3412.2001-01-24.farmer.ham.txt\n",
            "0855.2000-04-05.farmer.ham.txt\t3413.2001-01-24.farmer.ham.txt\n",
            "0856.2000-04-05.farmer.ham.txt\t3414.2001-01-24.farmer.ham.txt\n",
            "0857.2000-04-05.farmer.ham.txt\t3415.2001-01-24.farmer.ham.txt\n",
            "0859.2000-04-05.farmer.ham.txt\t3416.2001-01-24.farmer.ham.txt\n",
            "0860.2000-04-05.farmer.ham.txt\t3417.2001-01-24.farmer.ham.txt\n",
            "0863.2000-04-05.farmer.ham.txt\t3418.2001-01-25.farmer.ham.txt\n",
            "0864.2000-04-05.farmer.ham.txt\t3420.2001-01-25.farmer.ham.txt\n",
            "0866.2000-04-05.farmer.ham.txt\t3423.2001-01-25.farmer.ham.txt\n",
            "0868.2000-04-06.farmer.ham.txt\t3424.2001-01-25.farmer.ham.txt\n",
            "0869.2000-04-06.farmer.ham.txt\t3425.2001-01-25.farmer.ham.txt\n",
            "0870.2000-04-06.farmer.ham.txt\t3426.2001-01-25.farmer.ham.txt\n",
            "0872.2000-04-06.farmer.ham.txt\t3427.2001-01-25.farmer.ham.txt\n",
            "0873.2000-04-06.farmer.ham.txt\t3429.2001-01-25.farmer.ham.txt\n",
            "0875.2000-04-06.farmer.ham.txt\t3430.2001-01-25.farmer.ham.txt\n",
            "0876.2000-04-06.farmer.ham.txt\t3431.2001-01-25.farmer.ham.txt\n",
            "0877.2000-04-06.farmer.ham.txt\t3432.2001-01-25.farmer.ham.txt\n",
            "0878.2000-04-06.farmer.ham.txt\t3434.2001-01-25.farmer.ham.txt\n",
            "0879.2000-04-06.farmer.ham.txt\t3435.2001-01-25.farmer.ham.txt\n",
            "0880.2000-04-06.farmer.ham.txt\t3436.2001-01-25.farmer.ham.txt\n",
            "0882.2000-04-06.farmer.ham.txt\t3437.2001-01-25.farmer.ham.txt\n",
            "0884.2000-04-06.farmer.ham.txt\t3438.2001-01-25.farmer.ham.txt\n",
            "0885.2000-04-07.farmer.ham.txt\t3439.2001-01-26.farmer.ham.txt\n",
            "0886.2000-04-07.farmer.ham.txt\t3440.2001-01-26.farmer.ham.txt\n",
            "0888.2000-04-07.farmer.ham.txt\t3444.2001-01-26.farmer.ham.txt\n",
            "0890.2000-04-07.farmer.ham.txt\t3445.2001-01-26.farmer.ham.txt\n",
            "0892.2000-04-07.farmer.ham.txt\t3446.2001-01-26.farmer.ham.txt\n",
            "0894.2000-04-10.farmer.ham.txt\t3447.2001-01-26.farmer.ham.txt\n",
            "0896.2000-04-10.farmer.ham.txt\t3450.2001-01-26.farmer.ham.txt\n",
            "0898.2000-04-10.farmer.ham.txt\t3451.2001-01-26.farmer.ham.txt\n",
            "0900.2000-04-10.farmer.ham.txt\t3454.2001-01-26.farmer.ham.txt\n",
            "0901.2000-04-10.farmer.ham.txt\t3456.2001-01-26.farmer.ham.txt\n",
            "0902.2000-04-10.farmer.ham.txt\t3457.2001-01-28.farmer.ham.txt\n",
            "0904.2000-04-11.farmer.ham.txt\t3458.2001-01-29.farmer.ham.txt\n",
            "0906.2000-04-11.farmer.ham.txt\t3459.2001-01-29.farmer.ham.txt\n",
            "0907.2000-04-11.farmer.ham.txt\t3461.2001-01-29.farmer.ham.txt\n",
            "0908.2000-04-11.farmer.ham.txt\t3462.2001-01-29.farmer.ham.txt\n",
            "0909.2000-04-11.farmer.ham.txt\t3463.2001-01-29.farmer.ham.txt\n",
            "0911.2000-04-11.farmer.ham.txt\t3464.2001-01-29.farmer.ham.txt\n",
            "0912.2000-04-11.farmer.ham.txt\t3466.2001-01-29.farmer.ham.txt\n",
            "0915.2000-04-11.farmer.ham.txt\t3467.2001-01-29.farmer.ham.txt\n",
            "0916.2000-04-12.farmer.ham.txt\t3469.2001-01-29.farmer.ham.txt\n",
            "0917.2000-04-12.farmer.ham.txt\t3470.2001-01-29.farmer.ham.txt\n",
            "0918.2000-04-12.farmer.ham.txt\t3472.2001-01-29.farmer.ham.txt\n",
            "0919.2000-04-12.farmer.ham.txt\t3473.2001-01-30.farmer.ham.txt\n",
            "0921.2000-04-12.farmer.ham.txt\t3474.2001-01-30.farmer.ham.txt\n",
            "0922.2000-04-12.farmer.ham.txt\t3477.2001-01-30.farmer.ham.txt\n",
            "0923.2000-04-13.farmer.ham.txt\t3478.2001-01-30.farmer.ham.txt\n",
            "0925.2000-04-13.farmer.ham.txt\t3479.2001-01-30.farmer.ham.txt\n",
            "0926.2000-04-13.farmer.ham.txt\t3480.2001-01-30.farmer.ham.txt\n",
            "0927.2000-04-13.farmer.ham.txt\t3481.2001-01-30.farmer.ham.txt\n",
            "0929.2000-04-13.farmer.ham.txt\t3482.2001-01-30.farmer.ham.txt\n",
            "0930.2000-04-13.farmer.ham.txt\t3484.2001-01-31.farmer.ham.txt\n",
            "0932.2000-04-13.farmer.ham.txt\t3485.2001-01-31.farmer.ham.txt\n",
            "0933.2000-04-13.farmer.ham.txt\t3487.2001-01-31.farmer.ham.txt\n",
            "0935.2000-04-14.farmer.ham.txt\t3488.2001-01-31.farmer.ham.txt\n",
            "0936.2000-04-14.farmer.ham.txt\t3489.2001-01-31.farmer.ham.txt\n",
            "0937.2000-04-14.farmer.ham.txt\t3490.2001-01-31.farmer.ham.txt\n",
            "0939.2000-04-14.farmer.ham.txt\t3491.2001-01-31.farmer.ham.txt\n",
            "0940.2000-04-14.farmer.ham.txt\t3492.2001-01-31.farmer.ham.txt\n",
            "0942.2000-04-14.farmer.ham.txt\t3493.2001-02-01.farmer.ham.txt\n",
            "0943.2000-04-14.farmer.ham.txt\t3494.2001-02-01.farmer.ham.txt\n",
            "0944.2000-04-14.farmer.ham.txt\t3495.2001-02-01.farmer.ham.txt\n",
            "0945.2000-04-17.farmer.ham.txt\t3496.2001-02-01.farmer.ham.txt\n",
            "0946.2000-04-17.farmer.ham.txt\t3498.2001-02-01.farmer.ham.txt\n",
            "0947.2000-04-17.farmer.ham.txt\t3500.2001-02-01.farmer.ham.txt\n",
            "0948.2000-04-17.farmer.ham.txt\t3501.2001-02-01.farmer.ham.txt\n",
            "0949.2000-04-17.farmer.ham.txt\t3503.2001-02-01.farmer.ham.txt\n",
            "0951.2000-04-17.farmer.ham.txt\t3506.2001-02-01.farmer.ham.txt\n",
            "0955.2000-04-18.farmer.ham.txt\t3507.2001-02-01.farmer.ham.txt\n",
            "0956.2000-04-19.farmer.ham.txt\t3508.2001-02-01.farmer.ham.txt\n",
            "0958.2000-04-19.farmer.ham.txt\t3509.2001-02-01.farmer.ham.txt\n",
            "0959.2000-04-19.farmer.ham.txt\t3510.2001-02-01.farmer.ham.txt\n",
            "0960.2000-04-19.farmer.ham.txt\t3511.2001-02-01.farmer.ham.txt\n",
            "0961.2000-04-19.farmer.ham.txt\t3514.2001-02-02.farmer.ham.txt\n",
            "0964.2000-04-19.farmer.ham.txt\t3516.2001-02-02.farmer.ham.txt\n",
            "0965.2000-04-19.farmer.ham.txt\t3518.2001-02-02.farmer.ham.txt\n",
            "0966.2000-04-19.farmer.ham.txt\t3519.2001-02-02.farmer.ham.txt\n",
            "0968.2000-04-19.farmer.ham.txt\t3520.2001-02-05.farmer.ham.txt\n",
            "0970.2000-04-19.farmer.ham.txt\t3521.2001-02-05.farmer.ham.txt\n",
            "0972.2000-04-19.farmer.ham.txt\t3522.2001-02-05.farmer.ham.txt\n",
            "0973.2000-04-20.farmer.ham.txt\t3524.2001-02-05.farmer.ham.txt\n",
            "0974.2000-04-20.farmer.ham.txt\t3525.2001-02-05.farmer.ham.txt\n",
            "0975.2000-04-20.farmer.ham.txt\t3527.2001-02-05.farmer.ham.txt\n",
            "0976.2000-04-20.farmer.ham.txt\t3528.2001-02-05.farmer.ham.txt\n",
            "0978.2000-04-20.farmer.ham.txt\t3529.2001-02-05.farmer.ham.txt\n",
            "0979.2000-04-24.farmer.ham.txt\t3532.2001-02-06.farmer.ham.txt\n",
            "0980.2000-04-24.farmer.ham.txt\t3534.2001-02-06.farmer.ham.txt\n",
            "0981.2000-04-24.farmer.ham.txt\t3535.2001-02-06.farmer.ham.txt\n",
            "0982.2000-04-24.farmer.ham.txt\t3537.2001-02-06.farmer.ham.txt\n",
            "0983.2000-04-24.farmer.ham.txt\t3538.2001-02-06.farmer.ham.txt\n",
            "0985.2000-04-24.farmer.ham.txt\t3539.2001-02-06.farmer.ham.txt\n",
            "0986.2000-04-24.farmer.ham.txt\t3541.2001-02-06.farmer.ham.txt\n",
            "0987.2000-04-24.farmer.ham.txt\t3543.2001-02-06.farmer.ham.txt\n",
            "0988.2000-04-24.farmer.ham.txt\t3544.2001-02-07.farmer.ham.txt\n",
            "0989.2000-04-24.farmer.ham.txt\t3545.2001-02-07.farmer.ham.txt\n",
            "0990.2000-04-25.farmer.ham.txt\t3546.2001-02-07.farmer.ham.txt\n",
            "0991.2000-04-25.farmer.ham.txt\t3548.2001-02-07.farmer.ham.txt\n",
            "0993.2000-04-25.farmer.ham.txt\t3549.2001-02-07.farmer.ham.txt\n",
            "0994.2000-04-25.farmer.ham.txt\t3550.2001-02-07.farmer.ham.txt\n",
            "0996.2000-04-25.farmer.ham.txt\t3551.2001-02-08.farmer.ham.txt\n",
            "0998.2000-04-25.farmer.ham.txt\t3552.2001-02-08.farmer.ham.txt\n",
            "0999.2000-04-25.farmer.ham.txt\t3553.2001-02-08.farmer.ham.txt\n",
            "1000.2000-04-26.farmer.ham.txt\t3557.2001-02-09.farmer.ham.txt\n",
            "1001.2000-04-26.farmer.ham.txt\t3558.2001-02-09.farmer.ham.txt\n",
            "1002.2000-04-26.farmer.ham.txt\t3559.2001-02-09.farmer.ham.txt\n",
            "1003.2000-04-26.farmer.ham.txt\t3560.2001-02-09.farmer.ham.txt\n",
            "1004.2000-04-26.farmer.ham.txt\t3561.2001-02-09.farmer.ham.txt\n",
            "1006.2000-04-27.farmer.ham.txt\t3563.2001-02-10.farmer.ham.txt\n",
            "1007.2000-04-27.farmer.ham.txt\t3565.2001-02-12.farmer.ham.txt\n",
            "1009.2000-04-27.farmer.ham.txt\t3566.2001-02-12.farmer.ham.txt\n",
            "1010.2000-04-28.farmer.ham.txt\t3567.2001-02-12.farmer.ham.txt\n",
            "1012.2000-04-28.farmer.ham.txt\t3569.2001-02-12.farmer.ham.txt\n",
            "1013.2000-04-28.farmer.ham.txt\t3571.2001-02-12.farmer.ham.txt\n",
            "1015.2000-05-01.farmer.ham.txt\t3572.2001-02-12.farmer.ham.txt\n",
            "1016.2000-05-01.farmer.ham.txt\t3575.2001-02-13.farmer.ham.txt\n",
            "1017.2000-05-01.farmer.ham.txt\t3576.2001-02-13.farmer.ham.txt\n",
            "1020.2000-05-01.farmer.ham.txt\t3577.2001-02-13.farmer.ham.txt\n",
            "1021.2000-05-01.farmer.ham.txt\t3578.2001-02-14.farmer.ham.txt\n",
            "1022.2000-05-01.farmer.ham.txt\t3580.2001-02-14.farmer.ham.txt\n",
            "1024.2000-05-01.farmer.ham.txt\t3581.2001-02-14.farmer.ham.txt\n",
            "1025.2000-05-01.farmer.ham.txt\t3583.2001-02-15.farmer.ham.txt\n",
            "1026.2000-05-02.farmer.ham.txt\t3585.2001-02-15.farmer.ham.txt\n",
            "1028.2000-05-02.farmer.ham.txt\t3586.2001-02-15.farmer.ham.txt\n",
            "1029.2000-05-02.farmer.ham.txt\t3587.2001-02-15.farmer.ham.txt\n",
            "1030.2000-05-02.farmer.ham.txt\t3588.2001-02-16.farmer.ham.txt\n",
            "1031.2000-05-03.farmer.ham.txt\t3589.2001-02-16.farmer.ham.txt\n",
            "1032.2000-05-03.farmer.ham.txt\t3592.2001-02-16.farmer.ham.txt\n",
            "1034.2000-05-03.farmer.ham.txt\t3593.2001-02-16.farmer.ham.txt\n",
            "1035.2000-05-03.farmer.ham.txt\t3594.2001-02-16.farmer.ham.txt\n",
            "1036.2000-05-04.farmer.ham.txt\t3595.2001-02-16.farmer.ham.txt\n",
            "1039.2000-05-04.farmer.ham.txt\t3596.2001-02-16.farmer.ham.txt\n",
            "1041.2000-05-04.farmer.ham.txt\t3599.2001-02-16.farmer.ham.txt\n",
            "1042.2000-05-05.farmer.ham.txt\t3600.2001-02-18.farmer.ham.txt\n",
            "1043.2000-05-05.farmer.ham.txt\t3601.2001-02-18.farmer.ham.txt\n",
            "1045.2000-05-05.farmer.ham.txt\t3602.2001-02-19.farmer.ham.txt\n",
            "1047.2000-05-08.farmer.ham.txt\t3603.2001-02-20.farmer.ham.txt\n",
            "1049.2000-05-08.farmer.ham.txt\t3605.2001-02-20.farmer.ham.txt\n",
            "1050.2000-05-08.farmer.ham.txt\t3606.2001-02-20.farmer.ham.txt\n",
            "1051.2000-05-08.farmer.ham.txt\t3608.2001-02-20.farmer.ham.txt\n",
            "1052.2000-05-08.farmer.ham.txt\t3609.2001-02-20.farmer.ham.txt\n",
            "1054.2000-05-08.farmer.ham.txt\t3611.2001-02-20.farmer.ham.txt\n",
            "1055.2000-05-09.farmer.ham.txt\t3612.2001-02-21.farmer.ham.txt\n",
            "1056.2000-05-09.farmer.ham.txt\t3613.2001-02-21.farmer.ham.txt\n",
            "1058.2000-05-09.farmer.ham.txt\t3616.2001-02-21.farmer.ham.txt\n",
            "1059.2000-05-09.farmer.ham.txt\t3617.2001-02-21.farmer.ham.txt\n",
            "1060.2000-05-10.farmer.ham.txt\t3619.2001-02-21.farmer.ham.txt\n",
            "1061.2000-05-10.farmer.ham.txt\t3622.2001-02-21.farmer.ham.txt\n",
            "1062.2000-05-11.farmer.ham.txt\t3623.2001-02-21.farmer.ham.txt\n",
            "1063.2000-05-11.farmer.ham.txt\t3625.2001-02-21.farmer.ham.txt\n",
            "1064.2000-05-11.farmer.ham.txt\t3626.2001-02-21.farmer.ham.txt\n",
            "1065.2000-05-11.farmer.ham.txt\t3627.2001-02-21.farmer.ham.txt\n",
            "1067.2000-05-11.farmer.ham.txt\t3628.2001-02-21.farmer.ham.txt\n",
            "1068.2000-05-11.farmer.ham.txt\t3629.2001-02-21.farmer.ham.txt\n",
            "1069.2000-05-12.farmer.ham.txt\t3630.2001-02-21.farmer.ham.txt\n",
            "1070.2000-05-12.farmer.ham.txt\t3631.2001-02-22.farmer.ham.txt\n",
            "1071.2000-05-12.farmer.ham.txt\t3632.2001-02-22.farmer.ham.txt\n",
            "1072.2000-05-12.farmer.ham.txt\t3633.2001-02-22.farmer.ham.txt\n",
            "1073.2000-05-14.farmer.ham.txt\t3634.2001-02-22.farmer.ham.txt\n",
            "1074.2000-05-15.farmer.ham.txt\t3635.2001-02-22.farmer.ham.txt\n",
            "1075.2000-05-15.farmer.ham.txt\t3636.2001-02-22.farmer.ham.txt\n",
            "1077.2000-05-16.farmer.ham.txt\t3638.2001-02-22.farmer.ham.txt\n",
            "1079.2000-05-16.farmer.ham.txt\t3639.2001-02-22.farmer.ham.txt\n",
            "1080.2000-05-17.farmer.ham.txt\t3640.2001-02-22.farmer.ham.txt\n",
            "1081.2000-05-17.farmer.ham.txt\t3641.2001-02-22.farmer.ham.txt\n",
            "1083.2000-05-17.farmer.ham.txt\t3642.2001-02-22.farmer.ham.txt\n",
            "1084.2000-05-17.farmer.ham.txt\t3643.2001-02-22.farmer.ham.txt\n",
            "1086.2000-05-18.farmer.ham.txt\t3645.2001-02-23.farmer.ham.txt\n",
            "1087.2000-05-18.farmer.ham.txt\t3646.2001-02-23.farmer.ham.txt\n",
            "1088.2000-05-18.farmer.ham.txt\t3647.2001-02-23.farmer.ham.txt\n",
            "1089.2000-05-18.farmer.ham.txt\t3648.2001-02-23.farmer.ham.txt\n",
            "1090.2000-05-18.farmer.ham.txt\t3650.2001-02-23.farmer.ham.txt\n",
            "1091.2000-05-19.farmer.ham.txt\t3652.2001-02-23.farmer.ham.txt\n",
            "1094.2000-05-19.farmer.ham.txt\t3653.2001-02-23.farmer.ham.txt\n",
            "1097.2000-05-19.farmer.ham.txt\t3654.2001-02-23.farmer.ham.txt\n",
            "1098.2000-05-19.farmer.ham.txt\t3655.2001-02-23.farmer.ham.txt\n",
            "1100.2000-05-19.farmer.ham.txt\t3657.2001-02-23.farmer.ham.txt\n",
            "1101.2000-05-19.farmer.ham.txt\t3658.2001-02-23.farmer.ham.txt\n",
            "1102.2000-05-19.farmer.ham.txt\t3659.2001-02-23.farmer.ham.txt\n",
            "1103.2000-05-22.farmer.ham.txt\t3662.2001-02-23.farmer.ham.txt\n",
            "1105.2000-05-22.farmer.ham.txt\t3663.2001-02-23.farmer.ham.txt\n",
            "1106.2000-05-22.farmer.ham.txt\t3664.2001-02-23.farmer.ham.txt\n",
            "1108.2000-05-22.farmer.ham.txt\t3665.2001-02-25.farmer.ham.txt\n",
            "1109.2000-05-22.farmer.ham.txt\t3667.2001-02-26.farmer.ham.txt\n",
            "1110.2000-05-22.farmer.ham.txt\t3669.2001-02-26.farmer.ham.txt\n",
            "1111.2000-05-22.farmer.ham.txt\t3670.2001-02-26.farmer.ham.txt\n",
            "1113.2000-05-22.farmer.ham.txt\t3671.2001-02-26.farmer.ham.txt\n",
            "1114.2000-05-23.farmer.ham.txt\t3673.2001-02-26.farmer.ham.txt\n",
            "1116.2000-05-23.farmer.ham.txt\t3675.2001-02-26.farmer.ham.txt\n",
            "1117.2000-05-23.farmer.ham.txt\t3676.2001-02-26.farmer.ham.txt\n",
            "1118.2000-05-23.farmer.ham.txt\t3678.2001-02-26.farmer.ham.txt\n",
            "1120.2000-05-23.farmer.ham.txt\t3679.2001-02-27.farmer.ham.txt\n",
            "1121.2000-05-23.farmer.ham.txt\t3680.2001-02-27.farmer.ham.txt\n",
            "1122.2000-05-23.farmer.ham.txt\t3682.2001-02-27.farmer.ham.txt\n",
            "1124.2000-05-23.farmer.ham.txt\t3683.2001-02-27.farmer.ham.txt\n",
            "1125.2000-05-23.farmer.ham.txt\t3684.2001-02-27.farmer.ham.txt\n",
            "1126.2000-05-24.farmer.ham.txt\t3685.2001-02-27.farmer.ham.txt\n",
            "1127.2000-05-24.farmer.ham.txt\t3686.2001-02-27.farmer.ham.txt\n",
            "1128.2000-05-24.farmer.ham.txt\t3689.2001-02-27.farmer.ham.txt\n",
            "1129.2000-05-24.farmer.ham.txt\t3690.2001-02-28.farmer.ham.txt\n",
            "1131.2000-05-24.farmer.ham.txt\t3691.2001-02-28.farmer.ham.txt\n",
            "1132.2000-05-24.farmer.ham.txt\t3692.2001-03-01.farmer.ham.txt\n",
            "1133.2000-05-24.farmer.ham.txt\t3693.2001-03-01.farmer.ham.txt\n",
            "1134.2000-05-24.farmer.ham.txt\t3694.2001-03-01.farmer.ham.txt\n",
            "1135.2000-05-24.farmer.ham.txt\t3696.2001-03-01.farmer.ham.txt\n",
            "1136.2000-05-24.farmer.ham.txt\t3697.2001-03-02.farmer.ham.txt\n",
            "1137.2000-05-24.farmer.ham.txt\t3698.2001-03-02.farmer.ham.txt\n",
            "1138.2000-05-24.farmer.ham.txt\t3699.2001-03-02.farmer.ham.txt\n",
            "1139.2000-05-25.farmer.ham.txt\t3700.2001-03-02.farmer.ham.txt\n",
            "1140.2000-05-25.farmer.ham.txt\t3701.2001-03-02.farmer.ham.txt\n",
            "1143.2000-05-25.farmer.ham.txt\t3702.2001-03-02.farmer.ham.txt\n",
            "1144.2000-05-25.farmer.ham.txt\t3703.2001-03-04.farmer.ham.txt\n",
            "1145.2000-05-25.farmer.ham.txt\t3704.2001-03-05.farmer.ham.txt\n",
            "1146.2000-05-25.farmer.ham.txt\t3705.2001-03-05.farmer.ham.txt\n",
            "1147.2000-05-25.farmer.ham.txt\t3706.2001-03-05.farmer.ham.txt\n",
            "1150.2000-05-26.farmer.ham.txt\t3707.2001-03-05.farmer.ham.txt\n",
            "1151.2000-05-26.farmer.ham.txt\t3710.2001-03-05.farmer.ham.txt\n",
            "1152.2000-05-26.farmer.ham.txt\t3712.2001-03-06.farmer.ham.txt\n",
            "1153.2000-05-26.farmer.ham.txt\t3713.2001-03-06.farmer.ham.txt\n",
            "1155.2000-05-26.farmer.ham.txt\t3715.2001-03-06.farmer.ham.txt\n",
            "1157.2000-05-26.farmer.ham.txt\t3716.2001-03-06.farmer.ham.txt\n",
            "1158.2000-05-26.farmer.ham.txt\t3718.2001-03-06.farmer.ham.txt\n",
            "1159.2000-05-30.farmer.ham.txt\t3719.2001-03-06.farmer.ham.txt\n",
            "1160.2000-05-30.farmer.ham.txt\t3720.2001-03-06.farmer.ham.txt\n",
            "1161.2000-05-30.farmer.ham.txt\t3721.2001-03-06.farmer.ham.txt\n",
            "1162.2000-05-30.farmer.ham.txt\t3722.2001-03-06.farmer.ham.txt\n",
            "1163.2000-05-30.farmer.ham.txt\t3724.2001-03-07.farmer.ham.txt\n",
            "1164.2000-05-30.farmer.ham.txt\t3725.2001-03-07.farmer.ham.txt\n",
            "1167.2000-05-30.farmer.ham.txt\t3727.2001-03-07.farmer.ham.txt\n",
            "1168.2000-05-30.farmer.ham.txt\t3729.2001-03-07.farmer.ham.txt\n",
            "1169.2000-05-30.farmer.ham.txt\t3730.2001-03-07.farmer.ham.txt\n",
            "1170.2000-05-30.farmer.ham.txt\t3731.2001-03-07.farmer.ham.txt\n",
            "1171.2000-05-30.farmer.ham.txt\t3733.2001-03-08.farmer.ham.txt\n",
            "1172.2000-05-30.farmer.ham.txt\t3734.2001-03-08.farmer.ham.txt\n",
            "1173.2000-05-31.farmer.ham.txt\t3736.2001-03-08.farmer.ham.txt\n",
            "1174.2000-05-31.farmer.ham.txt\t3738.2001-03-08.farmer.ham.txt\n",
            "1175.2000-05-31.farmer.ham.txt\t3739.2001-03-08.farmer.ham.txt\n",
            "1176.2000-05-31.farmer.ham.txt\t3740.2001-03-08.farmer.ham.txt\n",
            "1178.2000-05-31.farmer.ham.txt\t3741.2001-03-08.farmer.ham.txt\n",
            "1179.2000-05-31.farmer.ham.txt\t3742.2001-03-09.farmer.ham.txt\n",
            "1181.2000-05-31.farmer.ham.txt\t3743.2001-03-09.farmer.ham.txt\n",
            "1184.2000-05-31.farmer.ham.txt\t3744.2001-03-09.farmer.ham.txt\n",
            "1186.2000-05-31.farmer.ham.txt\t3745.2001-03-09.farmer.ham.txt\n",
            "1187.2000-05-31.farmer.ham.txt\t3747.2001-03-09.farmer.ham.txt\n",
            "1188.2000-05-31.farmer.ham.txt\t3749.2001-03-09.farmer.ham.txt\n",
            "1189.2000-05-31.farmer.ham.txt\t3750.2001-03-09.farmer.ham.txt\n",
            "1191.2000-05-31.farmer.ham.txt\t3751.2001-03-12.farmer.ham.txt\n",
            "1193.2000-06-01.farmer.ham.txt\t3752.2001-03-12.farmer.ham.txt\n",
            "1194.2000-06-01.farmer.ham.txt\t3753.2001-03-12.farmer.ham.txt\n",
            "1197.2000-06-01.farmer.ham.txt\t3754.2001-03-12.farmer.ham.txt\n",
            "1198.2000-06-01.farmer.ham.txt\t3755.2001-03-12.farmer.ham.txt\n",
            "1201.2000-06-01.farmer.ham.txt\t3757.2001-03-12.farmer.ham.txt\n",
            "1202.2000-06-01.farmer.ham.txt\t3758.2001-03-12.farmer.ham.txt\n",
            "1203.2000-06-01.farmer.ham.txt\t3759.2001-03-12.farmer.ham.txt\n",
            "1206.2000-06-01.farmer.ham.txt\t3760.2001-03-12.farmer.ham.txt\n",
            "1207.2000-06-01.farmer.ham.txt\t3761.2001-03-12.farmer.ham.txt\n",
            "1209.2000-06-01.farmer.ham.txt\t3762.2001-03-12.farmer.ham.txt\n",
            "1210.2000-06-01.farmer.ham.txt\t3763.2001-03-12.farmer.ham.txt\n",
            "1211.2000-06-01.farmer.ham.txt\t3764.2001-03-12.farmer.ham.txt\n",
            "1213.2000-06-02.farmer.ham.txt\t3765.2001-03-13.farmer.ham.txt\n",
            "1214.2000-06-02.farmer.ham.txt\t3767.2001-03-13.farmer.ham.txt\n",
            "1215.2000-06-02.farmer.ham.txt\t3769.2001-03-13.farmer.ham.txt\n",
            "1217.2000-06-02.farmer.ham.txt\t3771.2001-03-13.farmer.ham.txt\n",
            "1220.2000-06-02.farmer.ham.txt\t3772.2001-03-13.farmer.ham.txt\n",
            "1221.2000-06-02.farmer.ham.txt\t3775.2001-03-13.farmer.ham.txt\n",
            "1222.2000-06-02.farmer.ham.txt\t3776.2001-03-13.farmer.ham.txt\n",
            "1223.2000-06-02.farmer.ham.txt\t3777.2001-03-13.farmer.ham.txt\n",
            "1225.2000-06-03.farmer.ham.txt\t3778.2001-03-13.farmer.ham.txt\n",
            "1226.2000-06-04.farmer.ham.txt\t3780.2001-03-14.farmer.ham.txt\n",
            "1227.2000-06-04.farmer.ham.txt\t3782.2001-03-14.farmer.ham.txt\n",
            "1229.2000-06-05.farmer.ham.txt\t3784.2001-03-14.farmer.ham.txt\n",
            "1232.2000-06-05.farmer.ham.txt\t3785.2001-03-14.farmer.ham.txt\n",
            "1233.2000-06-05.farmer.ham.txt\t3786.2001-03-14.farmer.ham.txt\n",
            "1234.2000-06-05.farmer.ham.txt\t3788.2001-03-14.farmer.ham.txt\n",
            "1235.2000-06-05.farmer.ham.txt\t3790.2001-03-14.farmer.ham.txt\n",
            "1237.2000-06-05.farmer.ham.txt\t3791.2001-03-14.farmer.ham.txt\n",
            "1238.2000-06-05.farmer.ham.txt\t3793.2001-03-14.farmer.ham.txt\n",
            "1239.2000-06-05.farmer.ham.txt\t3794.2001-03-14.farmer.ham.txt\n",
            "1240.2000-06-05.farmer.ham.txt\t3795.2001-03-14.farmer.ham.txt\n",
            "1242.2000-06-05.farmer.ham.txt\t3796.2001-03-14.farmer.ham.txt\n",
            "1244.2000-06-05.farmer.ham.txt\t3798.2001-03-14.farmer.ham.txt\n",
            "1245.2000-06-05.farmer.ham.txt\t3800.2001-03-15.farmer.ham.txt\n",
            "1246.2000-06-05.farmer.ham.txt\t3801.2001-03-15.farmer.ham.txt\n",
            "1248.2000-06-05.farmer.ham.txt\t3804.2001-03-15.farmer.ham.txt\n",
            "1249.2000-06-06.farmer.ham.txt\t3805.2001-03-15.farmer.ham.txt\n",
            "1250.2000-06-06.farmer.ham.txt\t3806.2001-03-15.farmer.ham.txt\n",
            "1251.2000-06-06.farmer.ham.txt\t3807.2001-03-15.farmer.ham.txt\n",
            "1252.2000-06-06.farmer.ham.txt\t3808.2001-03-15.farmer.ham.txt\n",
            "1253.2000-06-06.farmer.ham.txt\t3809.2001-03-15.farmer.ham.txt\n",
            "1254.2000-06-06.farmer.ham.txt\t3810.2001-03-15.farmer.ham.txt\n",
            "1255.2000-06-06.farmer.ham.txt\t3815.2001-03-15.farmer.ham.txt\n",
            "1256.2000-06-06.farmer.ham.txt\t3816.2001-03-15.farmer.ham.txt\n",
            "1257.2000-06-06.farmer.ham.txt\t3817.2001-03-15.farmer.ham.txt\n",
            "1259.2000-06-06.farmer.ham.txt\t3819.2001-03-15.farmer.ham.txt\n",
            "1261.2000-06-06.farmer.ham.txt\t3820.2001-03-15.farmer.ham.txt\n",
            "1262.2000-06-07.farmer.ham.txt\t3823.2001-03-16.farmer.ham.txt\n",
            "1263.2000-06-07.farmer.ham.txt\t3824.2001-03-16.farmer.ham.txt\n",
            "1264.2000-06-07.farmer.ham.txt\t3825.2001-03-16.farmer.ham.txt\n",
            "1265.2000-06-07.farmer.ham.txt\t3826.2001-03-16.farmer.ham.txt\n",
            "1266.2000-06-07.farmer.ham.txt\t3829.2001-03-16.farmer.ham.txt\n",
            "1267.2000-06-07.farmer.ham.txt\t3831.2001-03-16.farmer.ham.txt\n",
            "1269.2000-06-07.farmer.ham.txt\t3832.2001-03-16.farmer.ham.txt\n",
            "1270.2000-06-07.farmer.ham.txt\t3833.2001-03-16.farmer.ham.txt\n",
            "1271.2000-06-07.farmer.ham.txt\t3834.2001-03-16.farmer.ham.txt\n",
            "1272.2000-06-07.farmer.ham.txt\t3835.2001-03-16.farmer.ham.txt\n",
            "1273.2000-06-07.farmer.ham.txt\t3836.2001-03-16.farmer.ham.txt\n",
            "1274.2000-06-07.farmer.ham.txt\t3837.2001-03-16.farmer.ham.txt\n",
            "1275.2000-06-07.farmer.ham.txt\t3838.2001-03-16.farmer.ham.txt\n",
            "1276.2000-06-07.farmer.ham.txt\t3839.2001-03-16.farmer.ham.txt\n",
            "1277.2000-06-07.farmer.ham.txt\t3840.2001-03-19.farmer.ham.txt\n",
            "1279.2000-06-07.farmer.ham.txt\t3841.2001-03-19.farmer.ham.txt\n",
            "1281.2000-06-08.farmer.ham.txt\t3842.2001-03-19.farmer.ham.txt\n",
            "1283.2000-06-08.farmer.ham.txt\t3843.2001-03-19.farmer.ham.txt\n",
            "1285.2000-06-08.farmer.ham.txt\t3846.2001-03-19.farmer.ham.txt\n",
            "1286.2000-06-08.farmer.ham.txt\t3847.2001-03-19.farmer.ham.txt\n",
            "1287.2000-06-08.farmer.ham.txt\t3848.2001-03-20.farmer.ham.txt\n",
            "1288.2000-06-08.farmer.ham.txt\t3850.2001-03-20.farmer.ham.txt\n",
            "1289.2000-06-08.farmer.ham.txt\t3851.2001-03-20.farmer.ham.txt\n",
            "1290.2000-06-08.farmer.ham.txt\t3852.2001-03-20.farmer.ham.txt\n",
            "1291.2000-06-08.farmer.ham.txt\t3853.2001-03-20.farmer.ham.txt\n",
            "1292.2000-06-08.farmer.ham.txt\t3855.2001-03-20.farmer.ham.txt\n",
            "1294.2000-06-08.farmer.ham.txt\t3857.2001-03-20.farmer.ham.txt\n",
            "1296.2000-06-08.farmer.ham.txt\t3859.2001-03-20.farmer.ham.txt\n",
            "1297.2000-06-09.farmer.ham.txt\t3860.2001-03-20.farmer.ham.txt\n",
            "1298.2000-06-09.farmer.ham.txt\t3861.2001-03-20.farmer.ham.txt\n",
            "1299.2000-06-09.farmer.ham.txt\t3863.2001-03-20.farmer.ham.txt\n",
            "1302.2000-06-09.farmer.ham.txt\t3864.2001-03-20.farmer.ham.txt\n",
            "1303.2000-06-09.farmer.ham.txt\t3865.2001-03-20.farmer.ham.txt\n",
            "1304.2000-06-09.farmer.ham.txt\t3866.2001-03-20.farmer.ham.txt\n",
            "1305.2000-06-09.farmer.ham.txt\t3868.2001-03-20.farmer.ham.txt\n",
            "1310.2000-06-09.farmer.ham.txt\t3869.2001-03-20.farmer.ham.txt\n",
            "1311.2000-06-09.farmer.ham.txt\t3873.2001-03-20.farmer.ham.txt\n",
            "1312.2000-06-09.farmer.ham.txt\t3876.2001-03-20.farmer.ham.txt\n",
            "1314.2000-06-09.farmer.ham.txt\t3877.2001-03-20.farmer.ham.txt\n",
            "1315.2000-06-09.farmer.ham.txt\t3878.2001-03-20.farmer.ham.txt\n",
            "1316.2000-06-11.farmer.ham.txt\t3879.2001-03-20.farmer.ham.txt\n",
            "1318.2000-06-12.farmer.ham.txt\t3880.2001-03-20.farmer.ham.txt\n",
            "1320.2000-06-12.farmer.ham.txt\t3882.2001-03-21.farmer.ham.txt\n",
            "1321.2000-06-12.farmer.ham.txt\t3884.2001-03-21.farmer.ham.txt\n",
            "1323.2000-06-12.farmer.ham.txt\t3886.2001-03-21.farmer.ham.txt\n",
            "1324.2000-06-12.farmer.ham.txt\t3888.2001-03-21.farmer.ham.txt\n",
            "1325.2000-06-12.farmer.ham.txt\t3889.2001-03-21.farmer.ham.txt\n",
            "1326.2000-06-12.farmer.ham.txt\t3892.2001-03-21.farmer.ham.txt\n",
            "1327.2000-06-13.farmer.ham.txt\t3895.2001-03-21.farmer.ham.txt\n",
            "1328.2000-06-13.farmer.ham.txt\t3896.2001-03-21.farmer.ham.txt\n",
            "1329.2000-06-13.farmer.ham.txt\t3898.2001-03-21.farmer.ham.txt\n",
            "1330.2000-06-13.farmer.ham.txt\t3899.2001-03-21.farmer.ham.txt\n",
            "1331.2000-06-13.farmer.ham.txt\t3901.2001-03-21.farmer.ham.txt\n",
            "1332.2000-06-13.farmer.ham.txt\t3902.2001-03-21.farmer.ham.txt\n",
            "1333.2000-06-13.farmer.ham.txt\t3903.2001-03-21.farmer.ham.txt\n",
            "1334.2000-06-13.farmer.ham.txt\t3904.2001-03-21.farmer.ham.txt\n",
            "1335.2000-06-13.farmer.ham.txt\t3905.2001-03-21.farmer.ham.txt\n",
            "1337.2000-06-13.farmer.ham.txt\t3906.2001-03-21.farmer.ham.txt\n",
            "1339.2000-06-13.farmer.ham.txt\t3907.2001-03-21.farmer.ham.txt\n",
            "1341.2000-06-13.farmer.ham.txt\t3908.2001-03-21.farmer.ham.txt\n",
            "1342.2000-06-14.farmer.ham.txt\t3909.2001-03-21.farmer.ham.txt\n",
            "1344.2000-06-14.farmer.ham.txt\t3911.2001-03-21.farmer.ham.txt\n",
            "1345.2000-06-14.farmer.ham.txt\t3914.2001-03-21.farmer.ham.txt\n",
            "1348.2000-06-14.farmer.ham.txt\t3916.2001-03-21.farmer.ham.txt\n",
            "1349.2000-06-14.farmer.ham.txt\t3917.2001-03-21.farmer.ham.txt\n",
            "1350.2000-06-14.farmer.ham.txt\t3918.2001-03-21.farmer.ham.txt\n",
            "1351.2000-06-14.farmer.ham.txt\t3919.2001-03-21.farmer.ham.txt\n",
            "1353.2000-06-14.farmer.ham.txt\t3920.2001-03-21.farmer.ham.txt\n",
            "1354.2000-06-15.farmer.ham.txt\t3922.2001-03-21.farmer.ham.txt\n",
            "1355.2000-06-15.farmer.ham.txt\t3924.2001-03-21.farmer.ham.txt\n",
            "1357.2000-06-15.farmer.ham.txt\t3925.2001-03-22.farmer.ham.txt\n",
            "1358.2000-06-15.farmer.ham.txt\t3926.2001-03-22.farmer.ham.txt\n",
            "1359.2000-06-15.farmer.ham.txt\t3927.2001-03-22.farmer.ham.txt\n",
            "1360.2000-06-15.farmer.ham.txt\t3929.2001-03-22.farmer.ham.txt\n",
            "1361.2000-06-15.farmer.ham.txt\t3930.2001-03-22.farmer.ham.txt\n",
            "1362.2000-06-15.farmer.ham.txt\t3932.2001-03-22.farmer.ham.txt\n",
            "1363.2000-06-15.farmer.ham.txt\t3933.2001-03-22.farmer.ham.txt\n",
            "1364.2000-06-16.farmer.ham.txt\t3935.2001-03-22.farmer.ham.txt\n",
            "1365.2000-06-16.farmer.ham.txt\t3937.2001-03-22.farmer.ham.txt\n",
            "1366.2000-06-16.farmer.ham.txt\t3939.2001-03-22.farmer.ham.txt\n",
            "1368.2000-06-16.farmer.ham.txt\t3940.2001-03-22.farmer.ham.txt\n",
            "1370.2000-06-16.farmer.ham.txt\t3942.2001-03-22.farmer.ham.txt\n",
            "1373.2000-06-16.farmer.ham.txt\t3943.2001-03-22.farmer.ham.txt\n",
            "1374.2000-06-16.farmer.ham.txt\t3945.2001-03-22.farmer.ham.txt\n",
            "1375.2000-06-16.farmer.ham.txt\t3946.2001-03-22.farmer.ham.txt\n",
            "1376.2000-06-16.farmer.ham.txt\t3948.2001-03-22.farmer.ham.txt\n",
            "1377.2000-06-16.farmer.ham.txt\t3950.2001-03-23.farmer.ham.txt\n",
            "1379.2000-06-16.farmer.ham.txt\t3951.2001-03-23.farmer.ham.txt\n",
            "1380.2000-06-17.farmer.ham.txt\t3952.2001-03-23.farmer.ham.txt\n",
            "1381.2000-06-17.farmer.ham.txt\t3955.2001-03-23.farmer.ham.txt\n",
            "1382.2000-06-17.farmer.ham.txt\t3956.2001-03-23.farmer.ham.txt\n",
            "1383.2000-06-17.farmer.ham.txt\t3957.2001-03-23.farmer.ham.txt\n",
            "1385.2000-06-17.farmer.ham.txt\t3958.2001-03-23.farmer.ham.txt\n",
            "1386.2000-06-17.farmer.ham.txt\t3961.2001-03-23.farmer.ham.txt\n",
            "1387.2000-06-17.farmer.ham.txt\t3964.2001-03-23.farmer.ham.txt\n",
            "1389.2000-06-17.farmer.ham.txt\t3967.2001-03-23.farmer.ham.txt\n",
            "1390.2000-06-19.farmer.ham.txt\t3969.2001-03-23.farmer.ham.txt\n",
            "1392.2000-06-19.farmer.ham.txt\t3971.2001-03-23.farmer.ham.txt\n",
            "1394.2000-06-19.farmer.ham.txt\t3972.2001-03-23.farmer.ham.txt\n",
            "1395.2000-06-19.farmer.ham.txt\t3974.2001-03-23.farmer.ham.txt\n",
            "1396.2000-06-19.farmer.ham.txt\t3975.2001-03-23.farmer.ham.txt\n",
            "1397.2000-06-19.farmer.ham.txt\t3976.2001-03-23.farmer.ham.txt\n",
            "1398.2000-06-19.farmer.ham.txt\t3977.2001-03-23.farmer.ham.txt\n",
            "1399.2000-06-19.farmer.ham.txt\t3978.2001-03-23.farmer.ham.txt\n",
            "1401.2000-06-20.farmer.ham.txt\t3980.2001-03-23.farmer.ham.txt\n",
            "1403.2000-06-20.farmer.ham.txt\t3981.2001-03-23.farmer.ham.txt\n",
            "1406.2000-06-20.farmer.ham.txt\t3984.2001-03-23.farmer.ham.txt\n",
            "1407.2000-06-20.farmer.ham.txt\t3986.2001-03-23.farmer.ham.txt\n",
            "1408.2000-06-20.farmer.ham.txt\t3989.2001-03-23.farmer.ham.txt\n",
            "1410.2000-06-20.farmer.ham.txt\t3991.2001-03-26.farmer.ham.txt\n",
            "1411.2000-06-20.farmer.ham.txt\t3992.2001-03-26.farmer.ham.txt\n",
            "1412.2000-06-20.farmer.ham.txt\t3993.2001-03-26.farmer.ham.txt\n",
            "1415.2000-06-20.farmer.ham.txt\t3995.2001-03-26.farmer.ham.txt\n",
            "1418.2000-06-21.farmer.ham.txt\t3996.2001-03-26.farmer.ham.txt\n",
            "1419.2000-06-21.farmer.ham.txt\t3997.2001-03-26.farmer.ham.txt\n",
            "1422.2000-06-21.farmer.ham.txt\t3998.2001-03-26.farmer.ham.txt\n",
            "1424.2000-06-21.farmer.ham.txt\t3999.2001-03-26.farmer.ham.txt\n",
            "1425.2000-06-21.farmer.ham.txt\t4000.2001-03-26.farmer.ham.txt\n",
            "1426.2000-06-21.farmer.ham.txt\t4002.2001-03-26.farmer.ham.txt\n",
            "1427.2000-06-21.farmer.ham.txt\t4003.2001-03-26.farmer.ham.txt\n",
            "1429.2000-06-21.farmer.ham.txt\t4005.2001-03-26.farmer.ham.txt\n",
            "1431.2000-06-21.farmer.ham.txt\t4006.2001-03-26.farmer.ham.txt\n",
            "1432.2000-06-21.farmer.ham.txt\t4007.2001-03-26.farmer.ham.txt\n",
            "1434.2000-06-21.farmer.ham.txt\t4008.2001-03-26.farmer.ham.txt\n",
            "1436.2000-06-21.farmer.ham.txt\t4010.2001-03-26.farmer.ham.txt\n",
            "1438.2000-06-21.farmer.ham.txt\t4011.2001-03-26.farmer.ham.txt\n",
            "1439.2000-06-21.farmer.ham.txt\t4012.2001-03-26.farmer.ham.txt\n",
            "1440.2000-06-22.farmer.ham.txt\t4013.2001-03-26.farmer.ham.txt\n",
            "1441.2000-06-22.farmer.ham.txt\t4015.2001-03-26.farmer.ham.txt\n",
            "1443.2000-06-22.farmer.ham.txt\t4017.2001-03-26.farmer.ham.txt\n",
            "1444.2000-06-22.farmer.ham.txt\t4019.2001-03-27.farmer.ham.txt\n",
            "1445.2000-06-22.farmer.ham.txt\t4020.2001-03-27.farmer.ham.txt\n",
            "1446.2000-06-22.farmer.ham.txt\t4021.2001-03-27.farmer.ham.txt\n",
            "1447.2000-06-22.farmer.ham.txt\t4022.2001-03-27.farmer.ham.txt\n",
            "1448.2000-06-22.farmer.ham.txt\t4023.2001-03-27.farmer.ham.txt\n",
            "1449.2000-06-22.farmer.ham.txt\t4024.2001-03-27.farmer.ham.txt\n",
            "1451.2000-06-22.farmer.ham.txt\t4025.2001-03-27.farmer.ham.txt\n",
            "1455.2000-06-22.farmer.ham.txt\t4027.2001-03-27.farmer.ham.txt\n",
            "1456.2000-06-22.farmer.ham.txt\t4028.2001-03-27.farmer.ham.txt\n",
            "1457.2000-06-22.farmer.ham.txt\t4029.2001-03-27.farmer.ham.txt\n",
            "1458.2000-06-22.farmer.ham.txt\t4032.2001-03-27.farmer.ham.txt\n",
            "1460.2000-06-22.farmer.ham.txt\t4036.2001-03-27.farmer.ham.txt\n",
            "1461.2000-06-22.farmer.ham.txt\t4037.2001-03-27.farmer.ham.txt\n",
            "1462.2000-06-22.farmer.ham.txt\t4038.2001-03-27.farmer.ham.txt\n",
            "1463.2000-06-22.farmer.ham.txt\t4040.2001-03-27.farmer.ham.txt\n",
            "1464.2000-06-22.farmer.ham.txt\t4043.2001-03-27.farmer.ham.txt\n",
            "1465.2000-06-22.farmer.ham.txt\t4044.2001-03-28.farmer.ham.txt\n",
            "1466.2000-06-22.farmer.ham.txt\t4045.2001-03-28.farmer.ham.txt\n",
            "1468.2000-06-23.farmer.ham.txt\t4046.2001-03-28.farmer.ham.txt\n",
            "1470.2000-06-23.farmer.ham.txt\t4047.2001-03-28.farmer.ham.txt\n",
            "1472.2000-06-23.farmer.ham.txt\t4049.2001-03-28.farmer.ham.txt\n",
            "1475.2000-06-23.farmer.ham.txt\t4050.2001-03-28.farmer.ham.txt\n",
            "1476.2000-06-23.farmer.ham.txt\t4052.2001-03-28.farmer.ham.txt\n",
            "1477.2000-06-23.farmer.ham.txt\t4053.2001-03-28.farmer.ham.txt\n",
            "1478.2000-06-23.farmer.ham.txt\t4054.2001-03-28.farmer.ham.txt\n",
            "1479.2000-06-23.farmer.ham.txt\t4056.2001-03-28.farmer.ham.txt\n",
            "1480.2000-06-23.farmer.ham.txt\t4058.2001-03-28.farmer.ham.txt\n",
            "1481.2000-06-26.farmer.ham.txt\t4059.2001-03-28.farmer.ham.txt\n",
            "1482.2000-06-26.farmer.ham.txt\t4060.2001-03-28.farmer.ham.txt\n",
            "1483.2000-06-26.farmer.ham.txt\t4062.2001-03-28.farmer.ham.txt\n",
            "1484.2000-06-26.farmer.ham.txt\t4063.2001-03-28.farmer.ham.txt\n",
            "1485.2000-06-26.farmer.ham.txt\t4064.2001-03-28.farmer.ham.txt\n",
            "1486.2000-06-26.farmer.ham.txt\t4066.2001-03-28.farmer.ham.txt\n",
            "1488.2000-06-26.farmer.ham.txt\t4068.2001-03-28.farmer.ham.txt\n",
            "1490.2000-06-26.farmer.ham.txt\t4069.2001-03-28.farmer.ham.txt\n",
            "1491.2000-06-26.farmer.ham.txt\t4070.2001-03-28.farmer.ham.txt\n",
            "1492.2000-06-27.farmer.ham.txt\t4071.2001-03-28.farmer.ham.txt\n",
            "1493.2000-06-27.farmer.ham.txt\t4072.2001-03-28.farmer.ham.txt\n",
            "1494.2000-06-27.farmer.ham.txt\t4073.2001-03-28.farmer.ham.txt\n",
            "1496.2000-06-27.farmer.ham.txt\t4074.2001-03-28.farmer.ham.txt\n",
            "1497.2000-06-27.farmer.ham.txt\t4075.2001-03-28.farmer.ham.txt\n",
            "1498.2000-06-27.farmer.ham.txt\t4076.2001-03-28.farmer.ham.txt\n",
            "1501.2000-06-27.farmer.ham.txt\t4079.2001-03-28.farmer.ham.txt\n",
            "1502.2000-06-27.farmer.ham.txt\t4080.2001-03-29.farmer.ham.txt\n",
            "1504.2000-06-27.farmer.ham.txt\t4081.2001-03-29.farmer.ham.txt\n",
            "1506.2000-06-27.farmer.ham.txt\t4082.2001-03-29.farmer.ham.txt\n",
            "1507.2000-06-27.farmer.ham.txt\t4084.2001-03-29.farmer.ham.txt\n",
            "1509.2000-06-27.farmer.ham.txt\t4085.2001-03-29.farmer.ham.txt\n",
            "1510.2000-06-27.farmer.ham.txt\t4086.2001-03-29.farmer.ham.txt\n",
            "1512.2000-06-27.farmer.ham.txt\t4088.2001-03-29.farmer.ham.txt\n",
            "1514.2000-06-27.farmer.ham.txt\t4089.2001-03-29.farmer.ham.txt\n",
            "1515.2000-06-27.farmer.ham.txt\t4090.2001-03-29.farmer.ham.txt\n",
            "1516.2000-06-27.farmer.ham.txt\t4092.2001-03-29.farmer.ham.txt\n",
            "1517.2000-06-27.farmer.ham.txt\t4094.2001-03-29.farmer.ham.txt\n",
            "1518.2000-06-28.farmer.ham.txt\t4095.2001-03-29.farmer.ham.txt\n",
            "1519.2000-06-28.farmer.ham.txt\t4096.2001-03-29.farmer.ham.txt\n",
            "1520.2000-06-28.farmer.ham.txt\t4098.2001-03-29.farmer.ham.txt\n",
            "1521.2000-06-28.farmer.ham.txt\t4100.2001-03-29.farmer.ham.txt\n",
            "1522.2000-06-28.farmer.ham.txt\t4103.2001-03-29.farmer.ham.txt\n",
            "1523.2000-06-28.farmer.ham.txt\t4105.2001-03-29.farmer.ham.txt\n",
            "1524.2000-06-28.farmer.ham.txt\t4106.2001-03-29.farmer.ham.txt\n",
            "1525.2000-06-28.farmer.ham.txt\t4107.2001-03-29.farmer.ham.txt\n",
            "1526.2000-06-28.farmer.ham.txt\t4108.2001-03-29.farmer.ham.txt\n",
            "1527.2000-06-28.farmer.ham.txt\t4109.2001-03-30.farmer.ham.txt\n",
            "1528.2000-06-28.farmer.ham.txt\t4112.2001-03-30.farmer.ham.txt\n",
            "1529.2000-06-28.farmer.ham.txt\t4114.2001-03-30.farmer.ham.txt\n",
            "1530.2000-06-28.farmer.ham.txt\t4116.2001-03-30.farmer.ham.txt\n",
            "1531.2000-06-28.farmer.ham.txt\t4117.2001-03-30.farmer.ham.txt\n",
            "1532.2000-06-28.farmer.ham.txt\t4118.2001-03-30.farmer.ham.txt\n",
            "1534.2000-06-29.farmer.ham.txt\t4121.2001-03-30.farmer.ham.txt\n",
            "1537.2000-06-29.farmer.ham.txt\t4122.2001-03-30.farmer.ham.txt\n",
            "1538.2000-06-29.farmer.ham.txt\t4125.2001-03-30.farmer.ham.txt\n",
            "1539.2000-06-29.farmer.ham.txt\t4126.2001-03-30.farmer.ham.txt\n",
            "1541.2000-06-29.farmer.ham.txt\t4129.2001-03-30.farmer.ham.txt\n",
            "1542.2000-06-29.farmer.ham.txt\t4130.2001-03-30.farmer.ham.txt\n",
            "1543.2000-06-29.farmer.ham.txt\t4131.2001-03-30.farmer.ham.txt\n",
            "1546.2000-06-29.farmer.ham.txt\t4133.2001-03-30.farmer.ham.txt\n",
            "1547.2000-06-29.farmer.ham.txt\t4134.2001-03-30.farmer.ham.txt\n",
            "1548.2000-06-29.farmer.ham.txt\t4136.2001-03-30.farmer.ham.txt\n",
            "1550.2000-06-29.farmer.ham.txt\t4138.2001-03-30.farmer.ham.txt\n",
            "1551.2000-06-29.farmer.ham.txt\t4139.2001-03-30.farmer.ham.txt\n",
            "1552.2000-06-29.farmer.ham.txt\t4140.2001-03-30.farmer.ham.txt\n",
            "1553.2000-06-29.farmer.ham.txt\t4141.2001-03-30.farmer.ham.txt\n",
            "1554.2000-06-29.farmer.ham.txt\t4143.2001-03-31.farmer.ham.txt\n",
            "1555.2000-06-29.farmer.ham.txt\t4144.2001-04-02.farmer.ham.txt\n",
            "1556.2000-06-29.farmer.ham.txt\t4145.2001-04-02.farmer.ham.txt\n",
            "1558.2000-06-29.farmer.ham.txt\t4146.2001-04-02.farmer.ham.txt\n",
            "1560.2000-06-29.farmer.ham.txt\t4147.2001-04-02.farmer.ham.txt\n",
            "1561.2000-06-29.farmer.ham.txt\t4148.2001-04-02.farmer.ham.txt\n",
            "1562.2000-06-30.farmer.ham.txt\t4149.2001-04-02.farmer.ham.txt\n",
            "1563.2000-06-30.farmer.ham.txt\t4150.2001-04-02.farmer.ham.txt\n",
            "1564.2000-06-30.farmer.ham.txt\t4151.2001-04-02.farmer.ham.txt\n",
            "1565.2000-06-30.farmer.ham.txt\t4153.2001-04-02.farmer.ham.txt\n",
            "1566.2000-06-30.farmer.ham.txt\t4154.2001-04-02.farmer.ham.txt\n",
            "1567.2000-06-30.farmer.ham.txt\t4155.2001-04-02.farmer.ham.txt\n",
            "1568.2000-06-30.farmer.ham.txt\t4156.2001-04-02.farmer.ham.txt\n",
            "1570.2000-06-30.farmer.ham.txt\t4157.2001-04-02.farmer.ham.txt\n",
            "1571.2000-06-30.farmer.ham.txt\t4158.2001-04-02.farmer.ham.txt\n",
            "1572.2000-07-03.farmer.ham.txt\t4159.2001-04-02.farmer.ham.txt\n",
            "1573.2000-07-05.farmer.ham.txt\t4160.2001-04-02.farmer.ham.txt\n",
            "1574.2000-07-05.farmer.ham.txt\t4162.2001-04-02.farmer.ham.txt\n",
            "1576.2000-07-05.farmer.ham.txt\t4163.2001-04-03.farmer.ham.txt\n",
            "1577.2000-07-06.farmer.ham.txt\t4164.2001-04-03.farmer.ham.txt\n",
            "1578.2000-07-06.farmer.ham.txt\t4165.2001-04-03.farmer.ham.txt\n",
            "1579.2000-07-06.farmer.ham.txt\t4167.2001-04-03.farmer.ham.txt\n",
            "1580.2000-07-06.farmer.ham.txt\t4168.2001-04-03.farmer.ham.txt\n",
            "1582.2000-07-06.farmer.ham.txt\t4169.2001-04-03.farmer.ham.txt\n",
            "1583.2000-07-06.farmer.ham.txt\t4170.2001-04-03.farmer.ham.txt\n",
            "1584.2000-07-06.farmer.ham.txt\t4171.2001-04-03.farmer.ham.txt\n",
            "1585.2000-07-07.farmer.ham.txt\t4173.2001-04-04.farmer.ham.txt\n",
            "1586.2000-07-07.farmer.ham.txt\t4174.2001-04-04.farmer.ham.txt\n",
            "1587.2000-07-07.farmer.ham.txt\t4176.2001-04-04.farmer.ham.txt\n",
            "1589.2000-07-07.farmer.ham.txt\t4177.2001-04-04.farmer.ham.txt\n",
            "1590.2000-07-10.farmer.ham.txt\t4178.2001-04-04.farmer.ham.txt\n",
            "1591.2000-07-10.farmer.ham.txt\t4179.2001-04-04.farmer.ham.txt\n",
            "1592.2000-07-10.farmer.ham.txt\t4180.2001-04-04.farmer.ham.txt\n",
            "1593.2000-07-10.farmer.ham.txt\t4181.2001-04-04.farmer.ham.txt\n",
            "1594.2000-07-10.farmer.ham.txt\t4182.2001-04-04.farmer.ham.txt\n",
            "1595.2000-07-10.farmer.ham.txt\t4183.2001-04-04.farmer.ham.txt\n",
            "1596.2000-07-10.farmer.ham.txt\t4184.2001-04-04.farmer.ham.txt\n",
            "1597.2000-07-10.farmer.ham.txt\t4185.2001-04-04.farmer.ham.txt\n",
            "1598.2000-07-10.farmer.ham.txt\t4186.2001-04-04.farmer.ham.txt\n",
            "1599.2000-07-11.farmer.ham.txt\t4187.2001-04-05.farmer.ham.txt\n",
            "1600.2000-07-11.farmer.ham.txt\t4189.2001-04-05.farmer.ham.txt\n",
            "1601.2000-07-11.farmer.ham.txt\t4191.2001-04-05.farmer.ham.txt\n",
            "1603.2000-07-11.farmer.ham.txt\t4192.2001-04-05.farmer.ham.txt\n",
            "1604.2000-07-11.farmer.ham.txt\t4194.2001-04-05.farmer.ham.txt\n",
            "1605.2000-07-11.farmer.ham.txt\t4195.2001-04-05.farmer.ham.txt\n",
            "1606.2000-07-11.farmer.ham.txt\t4199.2001-04-05.farmer.ham.txt\n",
            "1608.2000-07-11.farmer.ham.txt\t4200.2001-04-05.farmer.ham.txt\n",
            "1609.2000-07-11.farmer.ham.txt\t4202.2001-04-05.farmer.ham.txt\n",
            "1610.2000-07-11.farmer.ham.txt\t4203.2001-04-05.farmer.ham.txt\n",
            "1611.2000-07-11.farmer.ham.txt\t4205.2001-04-05.farmer.ham.txt\n",
            "1613.2000-07-12.farmer.ham.txt\t4206.2001-04-05.farmer.ham.txt\n",
            "1614.2000-07-12.farmer.ham.txt\t4209.2001-04-05.farmer.ham.txt\n",
            "1616.2000-07-12.farmer.ham.txt\t4210.2001-04-05.farmer.ham.txt\n",
            "1617.2000-07-12.farmer.ham.txt\t4212.2001-04-05.farmer.ham.txt\n",
            "1618.2000-07-12.farmer.ham.txt\t4213.2001-04-05.farmer.ham.txt\n",
            "1620.2000-07-12.farmer.ham.txt\t4214.2001-04-06.farmer.ham.txt\n",
            "1621.2000-07-12.farmer.ham.txt\t4215.2001-04-06.farmer.ham.txt\n",
            "1622.2000-07-12.farmer.ham.txt\t4216.2001-04-06.farmer.ham.txt\n",
            "1623.2000-07-13.farmer.ham.txt\t4217.2001-04-06.farmer.ham.txt\n",
            "1624.2000-07-13.farmer.ham.txt\t4218.2001-04-06.farmer.ham.txt\n",
            "1625.2000-07-13.farmer.ham.txt\t4219.2001-04-06.farmer.ham.txt\n",
            "1627.2000-07-13.farmer.ham.txt\t4220.2001-04-06.farmer.ham.txt\n",
            "1629.2000-07-13.farmer.ham.txt\t4222.2001-04-06.farmer.ham.txt\n",
            "1630.2000-07-13.farmer.ham.txt\t4223.2001-04-06.farmer.ham.txt\n",
            "1631.2000-07-13.farmer.ham.txt\t4228.2001-04-06.farmer.ham.txt\n",
            "1634.2000-07-13.farmer.ham.txt\t4231.2001-04-06.farmer.ham.txt\n",
            "1636.2000-07-13.farmer.ham.txt\t4232.2001-04-09.farmer.ham.txt\n",
            "1637.2000-07-13.farmer.ham.txt\t4234.2001-04-09.farmer.ham.txt\n",
            "1638.2000-07-13.farmer.ham.txt\t4235.2001-04-09.farmer.ham.txt\n",
            "1639.2000-07-13.farmer.ham.txt\t4236.2001-04-09.farmer.ham.txt\n",
            "1641.2000-07-14.farmer.ham.txt\t4237.2001-04-09.farmer.ham.txt\n",
            "1643.2000-07-14.farmer.ham.txt\t4240.2001-04-09.farmer.ham.txt\n",
            "1644.2000-07-14.farmer.ham.txt\t4241.2001-04-09.farmer.ham.txt\n",
            "1645.2000-07-14.farmer.ham.txt\t4244.2001-04-09.farmer.ham.txt\n",
            "1646.2000-07-14.farmer.ham.txt\t4245.2001-04-09.farmer.ham.txt\n",
            "1647.2000-07-14.farmer.ham.txt\t4246.2001-04-09.farmer.ham.txt\n",
            "1648.2000-07-14.farmer.ham.txt\t4247.2001-04-09.farmer.ham.txt\n",
            "1650.2000-07-14.farmer.ham.txt\t4248.2001-04-09.farmer.ham.txt\n",
            "1651.2000-07-14.farmer.ham.txt\t4250.2001-04-09.farmer.ham.txt\n",
            "1652.2000-07-14.farmer.ham.txt\t4251.2001-04-09.farmer.ham.txt\n",
            "1653.2000-07-14.farmer.ham.txt\t4253.2001-04-09.farmer.ham.txt\n",
            "1655.2000-07-17.farmer.ham.txt\t4255.2001-04-10.farmer.ham.txt\n",
            "1657.2000-07-17.farmer.ham.txt\t4256.2001-04-10.farmer.ham.txt\n",
            "1658.2000-07-17.farmer.ham.txt\t4257.2001-04-10.farmer.ham.txt\n",
            "1659.2000-07-17.farmer.ham.txt\t4258.2001-04-10.farmer.ham.txt\n",
            "1662.2000-07-17.farmer.ham.txt\t4259.2001-04-10.farmer.ham.txt\n",
            "1664.2000-07-17.farmer.ham.txt\t4261.2001-04-10.farmer.ham.txt\n",
            "1665.2000-07-17.farmer.ham.txt\t4263.2001-04-10.farmer.ham.txt\n",
            "1667.2000-07-17.farmer.ham.txt\t4264.2001-04-11.farmer.ham.txt\n",
            "1668.2000-07-17.farmer.ham.txt\t4265.2001-04-11.farmer.ham.txt\n",
            "1673.2000-07-17.farmer.ham.txt\t4267.2001-04-11.farmer.ham.txt\n",
            "1674.2000-07-18.farmer.ham.txt\t4268.2001-04-11.farmer.ham.txt\n",
            "1675.2000-07-18.farmer.ham.txt\t4269.2001-04-11.farmer.ham.txt\n",
            "1676.2000-07-18.farmer.ham.txt\t4271.2001-04-11.farmer.ham.txt\n",
            "1677.2000-07-18.farmer.ham.txt\t4272.2001-04-11.farmer.ham.txt\n",
            "1680.2000-07-18.farmer.ham.txt\t4273.2001-04-12.farmer.ham.txt\n",
            "1681.2000-07-18.farmer.ham.txt\t4274.2001-04-12.farmer.ham.txt\n",
            "1682.2000-07-19.farmer.ham.txt\t4275.2001-04-12.farmer.ham.txt\n",
            "1683.2000-07-19.farmer.ham.txt\t4276.2001-04-12.farmer.ham.txt\n",
            "1684.2000-07-19.farmer.ham.txt\t4278.2001-04-12.farmer.ham.txt\n",
            "1685.2000-07-19.farmer.ham.txt\t4279.2001-04-12.farmer.ham.txt\n",
            "1687.2000-07-19.farmer.ham.txt\t4280.2001-04-15.farmer.ham.txt\n",
            "1688.2000-07-19.farmer.ham.txt\t4281.2001-04-15.farmer.ham.txt\n",
            "1689.2000-07-20.farmer.ham.txt\t4282.2001-04-16.farmer.ham.txt\n",
            "1691.2000-07-20.farmer.ham.txt\t4285.2001-04-16.farmer.ham.txt\n",
            "1692.2000-07-20.farmer.ham.txt\t4287.2001-04-16.farmer.ham.txt\n",
            "1693.2000-07-20.farmer.ham.txt\t4288.2001-04-16.farmer.ham.txt\n",
            "1695.2000-07-20.farmer.ham.txt\t4290.2001-04-16.farmer.ham.txt\n",
            "1696.2000-07-20.farmer.ham.txt\t4291.2001-04-16.farmer.ham.txt\n",
            "1697.2000-07-20.farmer.ham.txt\t4292.2001-04-16.farmer.ham.txt\n",
            "1698.2000-07-21.farmer.ham.txt\t4293.2001-04-16.farmer.ham.txt\n",
            "1699.2000-07-21.farmer.ham.txt\t4294.2001-04-17.farmer.ham.txt\n",
            "1700.2000-07-21.farmer.ham.txt\t4295.2001-04-17.farmer.ham.txt\n",
            "1702.2000-07-21.farmer.ham.txt\t4296.2001-04-17.farmer.ham.txt\n",
            "1703.2000-07-21.farmer.ham.txt\t4297.2001-04-17.farmer.ham.txt\n",
            "1704.2000-07-21.farmer.ham.txt\t4298.2001-04-17.farmer.ham.txt\n",
            "1706.2000-07-21.farmer.ham.txt\t4300.2001-04-17.farmer.ham.txt\n",
            "1707.2000-07-24.farmer.ham.txt\t4301.2001-04-17.farmer.ham.txt\n",
            "1709.2000-07-24.farmer.ham.txt\t4302.2001-04-17.farmer.ham.txt\n",
            "1712.2000-07-24.farmer.ham.txt\t4303.2001-04-17.farmer.ham.txt\n",
            "1713.2000-07-24.farmer.ham.txt\t4305.2001-04-17.farmer.ham.txt\n",
            "1714.2000-07-24.farmer.ham.txt\t4307.2001-04-18.farmer.ham.txt\n",
            "1716.2000-07-24.farmer.ham.txt\t4309.2001-04-18.farmer.ham.txt\n",
            "1718.2000-07-24.farmer.ham.txt\t4310.2001-04-18.farmer.ham.txt\n",
            "1719.2000-07-24.farmer.ham.txt\t4311.2001-04-18.farmer.ham.txt\n",
            "1721.2000-07-24.farmer.ham.txt\t4312.2001-04-18.farmer.ham.txt\n",
            "1722.2000-07-24.farmer.ham.txt\t4313.2001-04-18.farmer.ham.txt\n",
            "1724.2000-07-25.farmer.ham.txt\t4315.2001-04-19.farmer.ham.txt\n",
            "1725.2000-07-25.farmer.ham.txt\t4316.2001-04-19.farmer.ham.txt\n",
            "1726.2000-07-25.farmer.ham.txt\t4318.2001-04-19.farmer.ham.txt\n",
            "1729.2000-07-25.farmer.ham.txt\t4319.2001-04-19.farmer.ham.txt\n",
            "1731.2000-07-25.farmer.ham.txt\t4322.2001-04-19.farmer.ham.txt\n",
            "1734.2000-07-25.farmer.ham.txt\t4324.2001-04-19.farmer.ham.txt\n",
            "1737.2000-07-25.farmer.ham.txt\t4325.2001-04-19.farmer.ham.txt\n",
            "1738.2000-07-25.farmer.ham.txt\t4327.2001-04-19.farmer.ham.txt\n",
            "1741.2000-07-25.farmer.ham.txt\t4329.2001-04-19.farmer.ham.txt\n",
            "1743.2000-07-25.farmer.ham.txt\t4330.2001-04-19.farmer.ham.txt\n",
            "1744.2000-07-25.farmer.ham.txt\t4331.2001-04-19.farmer.ham.txt\n",
            "1746.2000-07-25.farmer.ham.txt\t4332.2001-04-19.farmer.ham.txt\n",
            "1747.2000-07-26.farmer.ham.txt\t4333.2001-04-19.farmer.ham.txt\n",
            "1749.2000-07-26.farmer.ham.txt\t4334.2001-04-20.farmer.ham.txt\n",
            "1751.2000-07-26.farmer.ham.txt\t4335.2001-04-20.farmer.ham.txt\n",
            "1754.2000-07-26.farmer.ham.txt\t4336.2001-04-20.farmer.ham.txt\n",
            "1755.2000-07-26.farmer.ham.txt\t4337.2001-04-20.farmer.ham.txt\n",
            "1759.2000-07-26.farmer.ham.txt\t4338.2001-04-20.farmer.ham.txt\n",
            "1761.2000-07-26.farmer.ham.txt\t4341.2001-04-20.farmer.ham.txt\n",
            "1762.2000-07-27.farmer.ham.txt\t4343.2001-04-20.farmer.ham.txt\n",
            "1764.2000-07-27.farmer.ham.txt\t4345.2001-04-20.farmer.ham.txt\n",
            "1765.2000-07-27.farmer.ham.txt\t4346.2001-04-23.farmer.ham.txt\n",
            "1767.2000-07-27.farmer.ham.txt\t4347.2001-04-23.farmer.ham.txt\n",
            "1768.2000-07-27.farmer.ham.txt\t4348.2001-04-23.farmer.ham.txt\n",
            "1769.2000-07-27.farmer.ham.txt\t4349.2001-04-23.farmer.ham.txt\n",
            "1770.2000-07-27.farmer.ham.txt\t4351.2001-04-23.farmer.ham.txt\n",
            "1771.2000-07-27.farmer.ham.txt\t4352.2001-04-24.farmer.ham.txt\n",
            "1772.2000-07-27.farmer.ham.txt\t4353.2001-04-24.farmer.ham.txt\n",
            "1774.2000-07-27.farmer.ham.txt\t4354.2001-04-24.farmer.ham.txt\n",
            "1776.2000-07-27.farmer.ham.txt\t4357.2001-04-24.farmer.ham.txt\n",
            "1777.2000-07-27.farmer.ham.txt\t4358.2001-04-24.farmer.ham.txt\n",
            "1779.2000-07-28.farmer.ham.txt\t4360.2001-04-24.farmer.ham.txt\n",
            "1780.2000-07-28.farmer.ham.txt\t4361.2001-04-24.farmer.ham.txt\n",
            "1781.2000-07-28.farmer.ham.txt\t4362.2001-04-24.farmer.ham.txt\n",
            "1782.2000-07-28.farmer.ham.txt\t4364.2001-04-24.farmer.ham.txt\n",
            "1783.2000-07-28.farmer.ham.txt\t4365.2001-04-24.farmer.ham.txt\n",
            "1784.2000-07-28.farmer.ham.txt\t4367.2001-04-24.farmer.ham.txt\n",
            "1787.2000-07-28.farmer.ham.txt\t4368.2001-04-24.farmer.ham.txt\n",
            "1788.2000-07-28.farmer.ham.txt\t4369.2001-04-24.farmer.ham.txt\n",
            "1789.2000-07-28.farmer.ham.txt\t4371.2001-04-24.farmer.ham.txt\n",
            "1790.2000-07-28.farmer.ham.txt\t4372.2001-04-24.farmer.ham.txt\n",
            "1791.2000-07-28.farmer.ham.txt\t4374.2001-04-25.farmer.ham.txt\n",
            "1792.2000-07-28.farmer.ham.txt\t4375.2001-04-25.farmer.ham.txt\n",
            "1793.2000-07-28.farmer.ham.txt\t4376.2001-04-25.farmer.ham.txt\n",
            "1795.2000-07-28.farmer.ham.txt\t4378.2001-04-25.farmer.ham.txt\n",
            "1796.2000-07-30.farmer.ham.txt\t4379.2001-04-25.farmer.ham.txt\n",
            "1797.2000-07-31.farmer.ham.txt\t4381.2001-04-25.farmer.ham.txt\n",
            "1798.2000-07-31.farmer.ham.txt\t4383.2001-04-25.farmer.ham.txt\n",
            "1800.2000-07-31.farmer.ham.txt\t4386.2001-04-25.farmer.ham.txt\n",
            "1802.2000-07-31.farmer.ham.txt\t4387.2001-04-25.farmer.ham.txt\n",
            "1804.2000-07-31.farmer.ham.txt\t4388.2001-04-25.farmer.ham.txt\n",
            "1807.2000-07-31.farmer.ham.txt\t4390.2001-04-25.farmer.ham.txt\n",
            "1808.2000-07-31.farmer.ham.txt\t4391.2001-04-26.farmer.ham.txt\n",
            "1810.2000-07-31.farmer.ham.txt\t4393.2001-04-26.farmer.ham.txt\n",
            "1812.2000-07-31.farmer.ham.txt\t4395.2001-04-26.farmer.ham.txt\n",
            "1814.2000-07-31.farmer.ham.txt\t4396.2001-04-26.farmer.ham.txt\n",
            "1815.2000-07-31.farmer.ham.txt\t4397.2001-04-26.farmer.ham.txt\n",
            "1817.2000-07-31.farmer.ham.txt\t4398.2001-04-26.farmer.ham.txt\n",
            "1818.2000-07-31.farmer.ham.txt\t4399.2001-04-26.farmer.ham.txt\n",
            "1819.2000-07-31.farmer.ham.txt\t4400.2001-04-26.farmer.ham.txt\n",
            "1820.2000-07-31.farmer.ham.txt\t4401.2001-04-26.farmer.ham.txt\n",
            "1824.2000-07-31.farmer.ham.txt\t4402.2001-04-26.farmer.ham.txt\n",
            "1826.2000-07-31.farmer.ham.txt\t4404.2001-04-26.farmer.ham.txt\n",
            "1827.2000-07-31.farmer.ham.txt\t4406.2001-04-26.farmer.ham.txt\n",
            "1828.2000-07-31.farmer.ham.txt\t4407.2001-04-26.farmer.ham.txt\n",
            "1830.2000-07-31.farmer.ham.txt\t4408.2001-04-26.farmer.ham.txt\n",
            "1831.2000-08-01.farmer.ham.txt\t4409.2001-04-26.farmer.ham.txt\n",
            "1832.2000-08-01.farmer.ham.txt\t4410.2001-04-26.farmer.ham.txt\n",
            "1833.2000-08-01.farmer.ham.txt\t4413.2001-04-27.farmer.ham.txt\n",
            "1834.2000-08-01.farmer.ham.txt\t4415.2001-04-27.farmer.ham.txt\n",
            "1835.2000-08-01.farmer.ham.txt\t4416.2001-04-27.farmer.ham.txt\n",
            "1836.2000-08-01.farmer.ham.txt\t4418.2001-04-27.farmer.ham.txt\n",
            "1838.2000-08-01.farmer.ham.txt\t4423.2001-04-27.farmer.ham.txt\n",
            "1839.2000-08-01.farmer.ham.txt\t4425.2001-04-27.farmer.ham.txt\n",
            "1840.2000-08-01.farmer.ham.txt\t4426.2001-04-27.farmer.ham.txt\n",
            "1841.2000-08-01.farmer.ham.txt\t4427.2001-04-27.farmer.ham.txt\n",
            "1843.2000-08-02.farmer.ham.txt\t4429.2001-04-27.farmer.ham.txt\n",
            "1845.2000-08-02.farmer.ham.txt\t4431.2001-04-30.farmer.ham.txt\n",
            "1848.2000-08-02.farmer.ham.txt\t4432.2001-04-30.farmer.ham.txt\n",
            "1849.2000-08-02.farmer.ham.txt\t4433.2001-04-30.farmer.ham.txt\n",
            "1851.2000-08-02.farmer.ham.txt\t4434.2001-04-30.farmer.ham.txt\n",
            "1852.2000-08-02.farmer.ham.txt\t4435.2001-04-30.farmer.ham.txt\n",
            "1853.2000-08-02.farmer.ham.txt\t4436.2001-04-30.farmer.ham.txt\n",
            "1856.2000-08-02.farmer.ham.txt\t4438.2001-04-30.farmer.ham.txt\n",
            "1857.2000-08-02.farmer.ham.txt\t4439.2001-04-30.farmer.ham.txt\n",
            "1859.2000-08-03.farmer.ham.txt\t4440.2001-04-30.farmer.ham.txt\n",
            "1860.2000-08-03.farmer.ham.txt\t4443.2001-05-01.farmer.ham.txt\n",
            "1861.2000-08-03.farmer.ham.txt\t4444.2001-05-01.farmer.ham.txt\n",
            "1862.2000-08-03.farmer.ham.txt\t4445.2001-05-01.farmer.ham.txt\n",
            "1864.2000-08-03.farmer.ham.txt\t4447.2001-05-01.farmer.ham.txt\n",
            "1865.2000-08-03.farmer.ham.txt\t4448.2001-05-01.farmer.ham.txt\n",
            "1866.2000-08-04.farmer.ham.txt\t4449.2001-05-01.farmer.ham.txt\n",
            "1867.2000-08-04.farmer.ham.txt\t4451.2001-05-01.farmer.ham.txt\n",
            "1869.2000-08-04.farmer.ham.txt\t4452.2001-05-01.farmer.ham.txt\n",
            "1871.2000-08-06.farmer.ham.txt\t4454.2001-05-02.farmer.ham.txt\n",
            "1872.2000-08-07.farmer.ham.txt\t4457.2001-05-02.farmer.ham.txt\n",
            "1873.2000-08-07.farmer.ham.txt\t4458.2001-05-02.farmer.ham.txt\n",
            "1875.2000-08-07.farmer.ham.txt\t4460.2001-05-02.farmer.ham.txt\n",
            "1876.2000-08-07.farmer.ham.txt\t4461.2001-05-02.farmer.ham.txt\n",
            "1877.2000-08-07.farmer.ham.txt\t4462.2001-05-02.farmer.ham.txt\n",
            "1878.2000-08-07.farmer.ham.txt\t4465.2001-05-02.farmer.ham.txt\n",
            "1880.2000-08-07.farmer.ham.txt\t4466.2001-05-02.farmer.ham.txt\n",
            "1883.2000-08-07.farmer.ham.txt\t4468.2001-05-02.farmer.ham.txt\n",
            "1884.2000-08-07.farmer.ham.txt\t4471.2001-05-03.farmer.ham.txt\n",
            "1885.2000-08-07.farmer.ham.txt\t4474.2001-05-03.farmer.ham.txt\n",
            "1886.2000-08-07.farmer.ham.txt\t4477.2001-05-03.farmer.ham.txt\n",
            "1887.2000-08-07.farmer.ham.txt\t4480.2001-05-03.farmer.ham.txt\n",
            "1888.2000-08-07.farmer.ham.txt\t4484.2001-05-03.farmer.ham.txt\n",
            "1890.2000-08-08.farmer.ham.txt\t4488.2001-05-04.farmer.ham.txt\n",
            "1892.2000-08-08.farmer.ham.txt\t4490.2001-05-04.farmer.ham.txt\n",
            "1893.2000-08-09.farmer.ham.txt\t4491.2001-05-04.farmer.ham.txt\n",
            "1894.2000-08-09.farmer.ham.txt\t4492.2001-05-07.farmer.ham.txt\n",
            "1895.2000-08-09.farmer.ham.txt\t4494.2001-05-07.farmer.ham.txt\n",
            "1896.2000-08-09.farmer.ham.txt\t4495.2001-05-07.farmer.ham.txt\n",
            "1898.2000-08-09.farmer.ham.txt\t4496.2001-05-07.farmer.ham.txt\n",
            "1900.2000-08-09.farmer.ham.txt\t4498.2001-05-07.farmer.ham.txt\n",
            "1901.2000-08-09.farmer.ham.txt\t4499.2001-05-07.farmer.ham.txt\n",
            "1902.2000-08-09.farmer.ham.txt\t4500.2001-05-07.farmer.ham.txt\n",
            "1903.2000-08-09.farmer.ham.txt\t4501.2001-05-07.farmer.ham.txt\n",
            "1904.2000-08-10.farmer.ham.txt\t4502.2001-05-08.farmer.ham.txt\n",
            "1906.2000-08-10.farmer.ham.txt\t4503.2001-05-08.farmer.ham.txt\n",
            "1907.2000-08-10.farmer.ham.txt\t4504.2001-05-08.farmer.ham.txt\n",
            "1908.2000-08-10.farmer.ham.txt\t4506.2001-05-08.farmer.ham.txt\n",
            "1909.2000-08-10.farmer.ham.txt\t4507.2001-05-08.farmer.ham.txt\n",
            "1912.2000-08-10.farmer.ham.txt\t4508.2001-05-08.farmer.ham.txt\n",
            "1913.2000-08-10.farmer.ham.txt\t4509.2001-05-08.farmer.ham.txt\n",
            "1914.2000-08-10.farmer.ham.txt\t4511.2001-05-08.farmer.ham.txt\n",
            "1915.2000-08-10.farmer.ham.txt\t4512.2001-05-08.farmer.ham.txt\n",
            "1916.2000-08-10.farmer.ham.txt\t4514.2001-05-08.farmer.ham.txt\n",
            "1917.2000-08-10.farmer.ham.txt\t4515.2001-05-09.farmer.ham.txt\n",
            "1919.2000-08-11.farmer.ham.txt\t4516.2001-05-09.farmer.ham.txt\n",
            "1920.2000-08-11.farmer.ham.txt\t4519.2001-05-09.farmer.ham.txt\n",
            "1921.2000-08-11.farmer.ham.txt\t4521.2001-05-09.farmer.ham.txt\n",
            "1922.2000-08-11.farmer.ham.txt\t4522.2001-05-09.farmer.ham.txt\n",
            "1923.2000-08-11.farmer.ham.txt\t4523.2001-05-09.farmer.ham.txt\n",
            "1924.2000-08-11.farmer.ham.txt\t4525.2001-05-09.farmer.ham.txt\n",
            "1925.2000-08-11.farmer.ham.txt\t4526.2001-05-09.farmer.ham.txt\n",
            "1927.2000-08-11.farmer.ham.txt\t4527.2001-05-10.farmer.ham.txt\n",
            "1928.2000-08-11.farmer.ham.txt\t4528.2001-05-10.farmer.ham.txt\n",
            "1929.2000-08-11.farmer.ham.txt\t4529.2001-05-10.farmer.ham.txt\n",
            "1930.2000-08-12.farmer.ham.txt\t4530.2001-05-10.farmer.ham.txt\n",
            "1931.2000-08-12.farmer.ham.txt\t4531.2001-05-10.farmer.ham.txt\n",
            "1932.2000-08-13.farmer.ham.txt\t4533.2001-05-10.farmer.ham.txt\n",
            "1933.2000-08-14.farmer.ham.txt\t4534.2001-05-11.farmer.ham.txt\n",
            "1934.2000-08-14.farmer.ham.txt\t4535.2001-05-11.farmer.ham.txt\n",
            "1935.2000-08-14.farmer.ham.txt\t4536.2001-05-11.farmer.ham.txt\n",
            "1937.2000-08-14.farmer.ham.txt\t4538.2001-05-14.farmer.ham.txt\n",
            "1938.2000-08-14.farmer.ham.txt\t4539.2001-05-14.farmer.ham.txt\n",
            "1939.2000-08-14.farmer.ham.txt\t4540.2001-05-14.farmer.ham.txt\n",
            "1940.2000-08-14.farmer.ham.txt\t4541.2001-05-14.farmer.ham.txt\n",
            "1943.2000-08-14.farmer.ham.txt\t4542.2001-05-14.farmer.ham.txt\n",
            "1944.2000-08-14.farmer.ham.txt\t4543.2001-05-15.farmer.ham.txt\n",
            "1945.2000-08-15.farmer.ham.txt\t4544.2001-05-15.farmer.ham.txt\n",
            "1946.2000-08-15.farmer.ham.txt\t4545.2001-05-15.farmer.ham.txt\n",
            "1947.2000-08-15.farmer.ham.txt\t4546.2001-05-16.farmer.ham.txt\n",
            "1950.2000-08-15.farmer.ham.txt\t4549.2001-05-16.farmer.ham.txt\n",
            "1951.2000-08-16.farmer.ham.txt\t4550.2001-05-16.farmer.ham.txt\n",
            "1953.2000-08-16.farmer.ham.txt\t4553.2001-05-16.farmer.ham.txt\n",
            "1955.2000-08-16.farmer.ham.txt\t4555.2001-05-16.farmer.ham.txt\n",
            "1956.2000-08-16.farmer.ham.txt\t4556.2001-05-17.farmer.ham.txt\n",
            "1958.2000-08-16.farmer.ham.txt\t4557.2001-05-17.farmer.ham.txt\n",
            "1959.2000-08-16.farmer.ham.txt\t4559.2001-05-17.farmer.ham.txt\n",
            "1961.2000-08-16.farmer.ham.txt\t4560.2001-05-17.farmer.ham.txt\n",
            "1962.2000-08-16.farmer.ham.txt\t4561.2001-05-17.farmer.ham.txt\n",
            "1963.2000-08-17.farmer.ham.txt\t4563.2001-05-18.farmer.ham.txt\n",
            "1964.2000-08-17.farmer.ham.txt\t4564.2001-05-18.farmer.ham.txt\n",
            "1965.2000-08-17.farmer.ham.txt\t4565.2001-05-18.farmer.ham.txt\n",
            "1967.2000-08-17.farmer.ham.txt\t4567.2001-05-18.farmer.ham.txt\n",
            "1969.2000-08-17.farmer.ham.txt\t4569.2001-05-18.farmer.ham.txt\n",
            "1971.2000-08-17.farmer.ham.txt\t4571.2001-05-18.farmer.ham.txt\n",
            "1972.2000-08-17.farmer.ham.txt\t4572.2001-05-21.farmer.ham.txt\n",
            "1974.2000-08-18.farmer.ham.txt\t4573.2001-05-21.farmer.ham.txt\n",
            "1975.2000-08-18.farmer.ham.txt\t4574.2001-05-21.farmer.ham.txt\n",
            "1976.2000-08-18.farmer.ham.txt\t4575.2001-05-21.farmer.ham.txt\n",
            "1977.2000-08-18.farmer.ham.txt\t4578.2001-05-21.farmer.ham.txt\n",
            "1978.2000-08-19.farmer.ham.txt\t4579.2001-05-21.farmer.ham.txt\n",
            "1979.2000-08-21.farmer.ham.txt\t4580.2001-05-22.farmer.ham.txt\n",
            "1980.2000-08-21.farmer.ham.txt\t4581.2001-05-22.farmer.ham.txt\n",
            "1982.2000-08-21.farmer.ham.txt\t4582.2001-05-22.farmer.ham.txt\n",
            "1983.2000-08-21.farmer.ham.txt\t4583.2001-05-22.farmer.ham.txt\n",
            "1984.2000-08-21.farmer.ham.txt\t4585.2001-05-22.farmer.ham.txt\n",
            "1987.2000-08-21.farmer.ham.txt\t4586.2001-05-22.farmer.ham.txt\n",
            "1988.2000-08-21.farmer.ham.txt\t4587.2001-05-22.farmer.ham.txt\n",
            "1989.2000-08-21.farmer.ham.txt\t4588.2001-05-22.farmer.ham.txt\n",
            "1990.2000-08-21.farmer.ham.txt\t4590.2001-05-22.farmer.ham.txt\n",
            "1991.2000-08-22.farmer.ham.txt\t4591.2001-05-22.farmer.ham.txt\n",
            "1992.2000-08-22.farmer.ham.txt\t4592.2001-05-22.farmer.ham.txt\n",
            "1994.2000-08-22.farmer.ham.txt\t4593.2001-05-23.farmer.ham.txt\n",
            "1995.2000-08-22.farmer.ham.txt\t4594.2001-05-23.farmer.ham.txt\n",
            "1997.2000-08-22.farmer.ham.txt\t4595.2001-05-23.farmer.ham.txt\n",
            "1998.2000-08-22.farmer.ham.txt\t4596.2001-05-23.farmer.ham.txt\n",
            "1999.2000-08-22.farmer.ham.txt\t4597.2001-05-23.farmer.ham.txt\n",
            "2001.2000-08-22.farmer.ham.txt\t4599.2001-05-23.farmer.ham.txt\n",
            "2003.2000-08-22.farmer.ham.txt\t4601.2001-05-23.farmer.ham.txt\n",
            "2004.2000-08-22.farmer.ham.txt\t4603.2001-05-23.farmer.ham.txt\n",
            "2005.2000-08-22.farmer.ham.txt\t4604.2001-05-23.farmer.ham.txt\n",
            "2007.2000-08-23.farmer.ham.txt\t4605.2001-05-24.farmer.ham.txt\n",
            "2008.2000-08-23.farmer.ham.txt\t4607.2001-05-24.farmer.ham.txt\n",
            "2009.2000-08-23.farmer.ham.txt\t4608.2001-05-24.farmer.ham.txt\n",
            "2010.2000-08-23.farmer.ham.txt\t4609.2001-05-24.farmer.ham.txt\n",
            "2011.2000-08-23.farmer.ham.txt\t4610.2001-05-24.farmer.ham.txt\n",
            "2012.2000-08-23.farmer.ham.txt\t4613.2001-05-24.farmer.ham.txt\n",
            "2013.2000-08-23.farmer.ham.txt\t4614.2001-05-24.farmer.ham.txt\n",
            "2015.2000-08-23.farmer.ham.txt\t4616.2001-05-24.farmer.ham.txt\n",
            "2016.2000-08-23.farmer.ham.txt\t4617.2001-05-24.farmer.ham.txt\n",
            "2017.2000-08-24.farmer.ham.txt\t4618.2001-05-24.farmer.ham.txt\n",
            "2019.2000-08-24.farmer.ham.txt\t4619.2001-05-24.farmer.ham.txt\n",
            "2020.2000-08-24.farmer.ham.txt\t4621.2001-05-24.farmer.ham.txt\n",
            "2022.2000-08-24.farmer.ham.txt\t4622.2001-05-24.farmer.ham.txt\n",
            "2023.2000-08-24.farmer.ham.txt\t4623.2001-05-25.farmer.ham.txt\n",
            "2025.2000-08-24.farmer.ham.txt\t4624.2001-05-25.farmer.ham.txt\n",
            "2027.2000-08-24.farmer.ham.txt\t4625.2001-05-25.farmer.ham.txt\n",
            "2029.2000-08-24.farmer.ham.txt\t4626.2001-05-25.farmer.ham.txt\n",
            "2031.2000-08-24.farmer.ham.txt\t4627.2001-05-25.farmer.ham.txt\n",
            "2032.2000-08-24.farmer.ham.txt\t4628.2001-05-29.farmer.ham.txt\n",
            "2033.2000-08-25.farmer.ham.txt\t4630.2001-05-29.farmer.ham.txt\n",
            "2034.2000-08-25.farmer.ham.txt\t4631.2001-05-29.farmer.ham.txt\n",
            "2035.2000-08-25.farmer.ham.txt\t4632.2001-05-29.farmer.ham.txt\n",
            "2036.2000-08-25.farmer.ham.txt\t4633.2001-05-30.farmer.ham.txt\n",
            "2037.2000-08-25.farmer.ham.txt\t4634.2001-05-30.farmer.ham.txt\n",
            "2038.2000-08-25.farmer.ham.txt\t4635.2001-05-30.farmer.ham.txt\n",
            "2039.2000-08-25.farmer.ham.txt\t4636.2001-05-30.farmer.ham.txt\n",
            "2041.2000-08-25.farmer.ham.txt\t4638.2001-05-30.farmer.ham.txt\n",
            "2043.2000-08-25.farmer.ham.txt\t4639.2001-05-31.farmer.ham.txt\n",
            "2044.2000-08-25.farmer.ham.txt\t4640.2001-06-01.farmer.ham.txt\n",
            "2046.2000-08-25.farmer.ham.txt\t4641.2001-06-01.farmer.ham.txt\n",
            "2048.2000-08-25.farmer.ham.txt\t4642.2001-06-04.farmer.ham.txt\n",
            "2049.2000-08-25.farmer.ham.txt\t4644.2001-06-05.farmer.ham.txt\n",
            "2050.2000-08-28.farmer.ham.txt\t4645.2001-06-05.farmer.ham.txt\n",
            "2053.2000-08-28.farmer.ham.txt\t4646.2001-06-06.farmer.ham.txt\n",
            "2054.2000-08-28.farmer.ham.txt\t4648.2001-06-06.farmer.ham.txt\n",
            "2056.2000-08-28.farmer.ham.txt\t4649.2001-06-07.farmer.ham.txt\n",
            "2057.2000-08-28.farmer.ham.txt\t4650.2001-06-07.farmer.ham.txt\n",
            "2058.2000-08-28.farmer.ham.txt\t4651.2001-06-07.farmer.ham.txt\n",
            "2059.2000-08-28.farmer.ham.txt\t4654.2001-06-07.farmer.ham.txt\n",
            "2061.2000-08-29.farmer.ham.txt\t4656.2001-06-08.farmer.ham.txt\n",
            "2062.2000-08-29.farmer.ham.txt\t4659.2001-06-09.farmer.ham.txt\n",
            "2063.2000-08-29.farmer.ham.txt\t4660.2001-06-11.farmer.ham.txt\n",
            "2065.2000-08-29.farmer.ham.txt\t4661.2001-06-12.farmer.ham.txt\n",
            "2066.2000-08-29.farmer.ham.txt\t4662.2001-06-12.farmer.ham.txt\n",
            "2067.2000-08-29.farmer.ham.txt\t4663.2001-06-13.farmer.ham.txt\n",
            "2068.2000-08-29.farmer.ham.txt\t4664.2001-06-13.farmer.ham.txt\n",
            "2069.2000-08-29.farmer.ham.txt\t4666.2001-06-14.farmer.ham.txt\n",
            "2070.2000-08-29.farmer.ham.txt\t4667.2001-06-14.farmer.ham.txt\n",
            "2072.2000-08-29.farmer.ham.txt\t4669.2001-06-14.farmer.ham.txt\n",
            "2074.2000-08-30.farmer.ham.txt\t4670.2001-06-15.farmer.ham.txt\n",
            "2076.2000-08-30.farmer.ham.txt\t4671.2001-06-15.farmer.ham.txt\n",
            "2077.2000-08-30.farmer.ham.txt\t4672.2001-06-15.farmer.ham.txt\n",
            "2079.2000-08-30.farmer.ham.txt\t4673.2001-06-15.farmer.ham.txt\n",
            "2080.2000-08-30.farmer.ham.txt\t4674.2001-06-17.farmer.ham.txt\n",
            "2082.2000-08-30.farmer.ham.txt\t4676.2001-06-17.farmer.ham.txt\n",
            "2084.2000-08-30.farmer.ham.txt\t4679.2001-06-19.farmer.ham.txt\n",
            "2085.2000-08-30.farmer.ham.txt\t4681.2001-06-19.farmer.ham.txt\n",
            "2086.2000-08-30.farmer.ham.txt\t4682.2001-06-19.farmer.ham.txt\n",
            "2088.2000-08-30.farmer.ham.txt\t4683.2001-06-19.farmer.ham.txt\n",
            "2089.2000-08-30.farmer.ham.txt\t4684.2001-06-19.farmer.ham.txt\n",
            "2090.2000-08-30.farmer.ham.txt\t4685.2001-06-19.farmer.ham.txt\n",
            "2091.2000-08-30.farmer.ham.txt\t4686.2001-06-20.farmer.ham.txt\n",
            "2093.2000-08-30.farmer.ham.txt\t4688.2001-06-20.farmer.ham.txt\n",
            "2095.2000-08-30.farmer.ham.txt\t4690.2001-06-20.farmer.ham.txt\n",
            "2096.2000-08-30.farmer.ham.txt\t4691.2001-06-21.farmer.ham.txt\n",
            "2098.2000-08-30.farmer.ham.txt\t4692.2001-06-21.farmer.ham.txt\n",
            "2099.2000-08-30.farmer.ham.txt\t4693.2001-06-21.farmer.ham.txt\n",
            "2100.2000-08-30.farmer.ham.txt\t4694.2001-06-21.farmer.ham.txt\n",
            "2101.2000-08-30.farmer.ham.txt\t4695.2001-06-21.farmer.ham.txt\n",
            "2102.2000-08-30.farmer.ham.txt\t4696.2001-06-22.farmer.ham.txt\n",
            "2103.2000-08-30.farmer.ham.txt\t4699.2001-06-22.farmer.ham.txt\n",
            "2104.2000-08-31.farmer.ham.txt\t4700.2001-06-22.farmer.ham.txt\n",
            "2106.2000-08-31.farmer.ham.txt\t4701.2001-06-25.farmer.ham.txt\n",
            "2107.2000-08-31.farmer.ham.txt\t4702.2001-06-25.farmer.ham.txt\n",
            "2108.2000-08-31.farmer.ham.txt\t4703.2001-06-26.farmer.ham.txt\n",
            "2109.2000-08-31.farmer.ham.txt\t4704.2001-06-26.farmer.ham.txt\n",
            "2112.2000-08-31.farmer.ham.txt\t4705.2001-06-26.farmer.ham.txt\n",
            "2113.2000-09-01.farmer.ham.txt\t4706.2001-06-27.farmer.ham.txt\n",
            "2114.2000-09-01.farmer.ham.txt\t4707.2001-06-27.farmer.ham.txt\n",
            "2116.2000-09-01.farmer.ham.txt\t4708.2001-06-28.farmer.ham.txt\n",
            "2118.2000-09-01.farmer.ham.txt\t4709.2001-06-28.farmer.ham.txt\n",
            "2119.2000-09-01.farmer.ham.txt\t4710.2001-06-28.farmer.ham.txt\n",
            "2121.2000-09-01.farmer.ham.txt\t4711.2001-06-28.farmer.ham.txt\n",
            "2124.2000-09-01.farmer.ham.txt\t4713.2001-06-28.farmer.ham.txt\n",
            "2125.2000-09-01.farmer.ham.txt\t4716.2001-06-29.farmer.ham.txt\n",
            "2126.2000-09-01.farmer.ham.txt\t4717.2001-06-29.farmer.ham.txt\n",
            "2128.2000-09-01.farmer.ham.txt\t4718.2001-06-30.farmer.ham.txt\n",
            "2129.2000-09-01.farmer.ham.txt\t4719.2001-07-02.farmer.ham.txt\n",
            "2130.2000-09-01.farmer.ham.txt\t4721.2001-07-03.farmer.ham.txt\n",
            "2131.2000-09-01.farmer.ham.txt\t4723.2001-07-05.farmer.ham.txt\n",
            "2133.2000-09-01.farmer.ham.txt\t4726.2001-07-06.farmer.ham.txt\n",
            "2134.2000-09-01.farmer.ham.txt\t4728.2001-07-06.farmer.ham.txt\n",
            "2135.2000-09-01.farmer.ham.txt\t4729.2001-07-09.farmer.ham.txt\n",
            "2136.2000-09-01.farmer.ham.txt\t4730.2001-07-09.farmer.ham.txt\n",
            "2137.2000-09-01.farmer.ham.txt\t4731.2001-07-09.farmer.ham.txt\n",
            "2138.2000-09-01.farmer.ham.txt\t4732.2001-07-09.farmer.ham.txt\n",
            "2139.2000-09-01.farmer.ham.txt\t4734.2001-07-09.farmer.ham.txt\n",
            "2141.2000-09-01.farmer.ham.txt\t4736.2001-07-09.farmer.ham.txt\n",
            "2142.2000-09-05.farmer.ham.txt\t4738.2001-07-09.farmer.ham.txt\n",
            "2143.2000-09-05.farmer.ham.txt\t4739.2001-07-10.farmer.ham.txt\n",
            "2145.2000-09-05.farmer.ham.txt\t4742.2001-07-11.farmer.ham.txt\n",
            "2147.2000-09-05.farmer.ham.txt\t4744.2001-07-11.farmer.ham.txt\n",
            "2149.2000-09-05.farmer.ham.txt\t4747.2001-07-11.farmer.ham.txt\n",
            "2150.2000-09-05.farmer.ham.txt\t4748.2001-07-12.farmer.ham.txt\n",
            "2151.2000-09-05.farmer.ham.txt\t4750.2001-07-13.farmer.ham.txt\n",
            "2152.2000-09-05.farmer.ham.txt\t4751.2001-07-13.farmer.ham.txt\n",
            "2154.2000-09-05.farmer.ham.txt\t4752.2001-07-16.farmer.ham.txt\n",
            "2155.2000-09-05.farmer.ham.txt\t4753.2001-07-16.farmer.ham.txt\n",
            "2156.2000-09-05.farmer.ham.txt\t4756.2001-07-16.farmer.ham.txt\n",
            "2157.2000-09-05.farmer.ham.txt\t4757.2001-07-16.farmer.ham.txt\n",
            "2159.2000-09-05.farmer.ham.txt\t4758.2001-07-17.farmer.ham.txt\n",
            "2160.2000-09-05.farmer.ham.txt\t4759.2001-07-17.farmer.ham.txt\n",
            "2161.2000-09-06.farmer.ham.txt\t4760.2001-07-17.farmer.ham.txt\n",
            "2162.2000-09-06.farmer.ham.txt\t4761.2001-07-18.farmer.ham.txt\n",
            "2164.2000-09-06.farmer.ham.txt\t4762.2001-07-18.farmer.ham.txt\n",
            "2166.2000-09-06.farmer.ham.txt\t4763.2001-07-19.farmer.ham.txt\n",
            "2168.2000-09-06.farmer.ham.txt\t4764.2001-07-19.farmer.ham.txt\n",
            "2169.2000-09-06.farmer.ham.txt\t4765.2001-07-19.farmer.ham.txt\n",
            "2170.2000-09-06.farmer.ham.txt\t4767.2001-07-20.farmer.ham.txt\n",
            "2171.2000-09-06.farmer.ham.txt\t4768.2001-07-23.farmer.ham.txt\n",
            "2173.2000-09-06.farmer.ham.txt\t4769.2001-07-23.farmer.ham.txt\n",
            "2174.2000-09-07.farmer.ham.txt\t4770.2001-07-25.farmer.ham.txt\n",
            "2176.2000-09-07.farmer.ham.txt\t4772.2001-07-25.farmer.ham.txt\n",
            "2177.2000-09-07.farmer.ham.txt\t4773.2001-07-25.farmer.ham.txt\n",
            "2178.2000-09-07.farmer.ham.txt\t4775.2001-07-27.farmer.ham.txt\n",
            "2181.2000-09-07.farmer.ham.txt\t4776.2001-07-27.farmer.ham.txt\n",
            "2183.2000-09-07.farmer.ham.txt\t4779.2001-07-27.farmer.ham.txt\n",
            "2184.2000-09-07.farmer.ham.txt\t4780.2001-07-27.farmer.ham.txt\n",
            "2186.2000-09-08.farmer.ham.txt\t4781.2001-07-27.farmer.ham.txt\n",
            "2188.2000-09-08.farmer.ham.txt\t4782.2001-07-27.farmer.ham.txt\n",
            "2189.2000-09-08.farmer.ham.txt\t4783.2001-07-30.farmer.ham.txt\n",
            "2190.2000-09-08.farmer.ham.txt\t4784.2001-07-31.farmer.ham.txt\n",
            "2191.2000-09-08.farmer.ham.txt\t4785.2001-07-31.farmer.ham.txt\n",
            "2193.2000-09-08.farmer.ham.txt\t4786.2001-08-02.farmer.ham.txt\n",
            "2196.2000-09-08.farmer.ham.txt\t4788.2001-08-03.farmer.ham.txt\n",
            "2197.2000-09-09.farmer.ham.txt\t4789.2001-08-03.farmer.ham.txt\n",
            "2199.2000-09-11.farmer.ham.txt\t4791.2001-08-06.farmer.ham.txt\n",
            "2200.2000-09-11.farmer.ham.txt\t4793.2001-08-07.farmer.ham.txt\n",
            "2202.2000-09-11.farmer.ham.txt\t4795.2001-08-07.farmer.ham.txt\n",
            "2203.2000-09-11.farmer.ham.txt\t4797.2001-08-09.farmer.ham.txt\n",
            "2204.2000-09-11.farmer.ham.txt\t4798.2001-08-09.farmer.ham.txt\n",
            "2205.2000-09-12.farmer.ham.txt\t4800.2001-08-09.farmer.ham.txt\n",
            "2207.2000-09-12.farmer.ham.txt\t4801.2001-08-10.farmer.ham.txt\n",
            "2208.2000-09-12.farmer.ham.txt\t4802.2001-08-10.farmer.ham.txt\n",
            "2210.2000-09-12.farmer.ham.txt\t4804.2001-08-10.farmer.ham.txt\n",
            "2212.2000-09-12.farmer.ham.txt\t4805.2001-08-10.farmer.ham.txt\n",
            "2213.2000-09-12.farmer.ham.txt\t4807.2001-08-12.farmer.ham.txt\n",
            "2214.2000-09-12.farmer.ham.txt\t4809.2001-08-13.farmer.ham.txt\n",
            "2216.2000-09-12.farmer.ham.txt\t4811.2001-08-13.farmer.ham.txt\n",
            "2219.2000-09-12.farmer.ham.txt\t4812.2001-08-13.farmer.ham.txt\n",
            "2220.2000-09-12.farmer.ham.txt\t4814.2001-08-14.farmer.ham.txt\n",
            "2221.2000-09-12.farmer.ham.txt\t4816.2001-08-14.farmer.ham.txt\n",
            "2223.2000-09-12.farmer.ham.txt\t4817.2001-08-14.farmer.ham.txt\n",
            "2224.2000-09-12.farmer.ham.txt\t4819.2001-08-14.farmer.ham.txt\n",
            "2225.2000-09-12.farmer.ham.txt\t4820.2001-08-14.farmer.ham.txt\n",
            "2226.2000-09-12.farmer.ham.txt\t4821.2001-08-14.farmer.ham.txt\n",
            "2228.2000-09-13.farmer.ham.txt\t4823.2001-08-15.farmer.ham.txt\n",
            "2230.2000-09-13.farmer.ham.txt\t4825.2001-08-15.farmer.ham.txt\n",
            "2232.2000-09-13.farmer.ham.txt\t4826.2001-08-16.farmer.ham.txt\n",
            "2233.2000-09-13.farmer.ham.txt\t4828.2001-08-17.farmer.ham.txt\n",
            "2235.2000-09-13.farmer.ham.txt\t4829.2001-08-17.farmer.ham.txt\n",
            "2236.2000-09-13.farmer.ham.txt\t4830.2001-08-17.farmer.ham.txt\n",
            "2237.2000-09-13.farmer.ham.txt\t4831.2001-08-21.farmer.ham.txt\n",
            "2238.2000-09-13.farmer.ham.txt\t4832.2001-08-21.farmer.ham.txt\n",
            "2239.2000-09-13.farmer.ham.txt\t4835.2001-08-21.farmer.ham.txt\n",
            "2240.2000-09-14.farmer.ham.txt\t4836.2001-08-21.farmer.ham.txt\n",
            "2241.2000-09-14.farmer.ham.txt\t4837.2001-08-24.farmer.ham.txt\n",
            "2243.2000-09-14.farmer.ham.txt\t4838.2001-08-24.farmer.ham.txt\n",
            "2244.2000-09-14.farmer.ham.txt\t4839.2001-08-24.farmer.ham.txt\n",
            "2245.2000-09-15.farmer.ham.txt\t4840.2001-08-28.farmer.ham.txt\n",
            "2246.2000-09-15.farmer.ham.txt\t4842.2001-08-29.farmer.ham.txt\n",
            "2249.2000-09-15.farmer.ham.txt\t4844.2001-08-29.farmer.ham.txt\n",
            "2250.2000-09-15.farmer.ham.txt\t4846.2001-08-29.farmer.ham.txt\n",
            "2251.2000-09-15.farmer.ham.txt\t4847.2001-08-29.farmer.ham.txt\n",
            "2252.2000-09-15.farmer.ham.txt\t4849.2001-08-30.farmer.ham.txt\n",
            "2253.2000-09-15.farmer.ham.txt\t4851.2001-08-30.farmer.ham.txt\n",
            "2256.2000-09-15.farmer.ham.txt\t4852.2001-08-30.farmer.ham.txt\n",
            "2257.2000-09-15.farmer.ham.txt\t4853.2001-08-30.farmer.ham.txt\n",
            "2259.2000-09-18.farmer.ham.txt\t4855.2001-08-31.farmer.ham.txt\n",
            "2260.2000-09-18.farmer.ham.txt\t4857.2001-09-04.farmer.ham.txt\n",
            "2261.2000-09-18.farmer.ham.txt\t4858.2001-09-04.farmer.ham.txt\n",
            "2262.2000-09-18.farmer.ham.txt\t4860.2001-09-05.farmer.ham.txt\n",
            "2264.2000-09-18.farmer.ham.txt\t4861.2001-09-05.farmer.ham.txt\n",
            "2266.2000-09-18.farmer.ham.txt\t4863.2001-09-06.farmer.ham.txt\n",
            "2267.2000-09-18.farmer.ham.txt\t4865.2001-09-06.farmer.ham.txt\n",
            "2269.2000-09-18.farmer.ham.txt\t4867.2001-09-07.farmer.ham.txt\n",
            "2272.2000-09-18.farmer.ham.txt\t4868.2001-09-07.farmer.ham.txt\n",
            "2273.2000-09-19.farmer.ham.txt\t4869.2001-09-07.farmer.ham.txt\n",
            "2274.2000-09-19.farmer.ham.txt\t4871.2001-09-07.farmer.ham.txt\n",
            "2276.2000-09-19.farmer.ham.txt\t4873.2001-09-07.farmer.ham.txt\n",
            "2277.2000-09-19.farmer.ham.txt\t4874.2001-09-07.farmer.ham.txt\n",
            "2278.2000-09-19.farmer.ham.txt\t4875.2001-09-09.farmer.ham.txt\n",
            "2279.2000-09-19.farmer.ham.txt\t4876.2001-09-10.farmer.ham.txt\n",
            "2282.2000-09-19.farmer.ham.txt\t4879.2001-09-10.farmer.ham.txt\n",
            "2284.2000-09-19.farmer.ham.txt\t4880.2001-09-10.farmer.ham.txt\n",
            "2286.2000-09-19.farmer.ham.txt\t4883.2001-09-10.farmer.ham.txt\n",
            "2288.2000-09-19.farmer.ham.txt\t4884.2001-09-10.farmer.ham.txt\n",
            "2289.2000-09-19.farmer.ham.txt\t4886.2001-09-12.farmer.ham.txt\n",
            "2291.2000-09-19.farmer.ham.txt\t4888.2001-09-12.farmer.ham.txt\n",
            "2292.2000-09-20.farmer.ham.txt\t4889.2001-09-12.farmer.ham.txt\n",
            "2294.2000-09-20.farmer.ham.txt\t4892.2001-09-12.farmer.ham.txt\n",
            "2295.2000-09-20.farmer.ham.txt\t4893.2001-09-12.farmer.ham.txt\n",
            "2297.2000-09-20.farmer.ham.txt\t4895.2001-09-12.farmer.ham.txt\n",
            "2298.2000-09-20.farmer.ham.txt\t4896.2001-09-13.farmer.ham.txt\n",
            "2299.2000-09-20.farmer.ham.txt\t4897.2001-09-13.farmer.ham.txt\n",
            "2300.2000-09-21.farmer.ham.txt\t4899.2001-09-13.farmer.ham.txt\n",
            "2303.2000-09-21.farmer.ham.txt\t4900.2001-09-13.farmer.ham.txt\n",
            "2305.2000-09-21.farmer.ham.txt\t4901.2001-09-13.farmer.ham.txt\n",
            "2306.2000-09-21.farmer.ham.txt\t4902.2001-09-14.farmer.ham.txt\n",
            "2307.2000-09-21.farmer.ham.txt\t4903.2001-09-14.farmer.ham.txt\n",
            "2308.2000-09-21.farmer.ham.txt\t4905.2001-09-14.farmer.ham.txt\n",
            "2309.2000-09-21.farmer.ham.txt\t4907.2001-09-15.farmer.ham.txt\n",
            "2310.2000-09-21.farmer.ham.txt\t4909.2001-09-17.farmer.ham.txt\n",
            "2311.2000-09-21.farmer.ham.txt\t4910.2001-09-17.farmer.ham.txt\n",
            "2312.2000-09-21.farmer.ham.txt\t4912.2001-09-17.farmer.ham.txt\n",
            "2313.2000-09-21.farmer.ham.txt\t4914.2001-09-17.farmer.ham.txt\n",
            "2314.2000-09-21.farmer.ham.txt\t4915.2001-09-18.farmer.ham.txt\n",
            "2315.2000-09-22.farmer.ham.txt\t4916.2001-09-18.farmer.ham.txt\n",
            "2316.2000-09-22.farmer.ham.txt\t4918.2001-09-18.farmer.ham.txt\n",
            "2317.2000-09-22.farmer.ham.txt\t4919.2001-09-19.farmer.ham.txt\n",
            "2318.2000-09-22.farmer.ham.txt\t4920.2001-09-19.farmer.ham.txt\n",
            "2319.2000-09-22.farmer.ham.txt\t4921.2001-09-19.farmer.ham.txt\n",
            "2320.2000-09-22.farmer.ham.txt\t4923.2001-09-20.farmer.ham.txt\n",
            "2321.2000-09-22.farmer.ham.txt\t4925.2001-09-21.farmer.ham.txt\n",
            "2323.2000-09-22.farmer.ham.txt\t4926.2001-09-21.farmer.ham.txt\n",
            "2324.2000-09-22.farmer.ham.txt\t4927.2001-09-21.farmer.ham.txt\n",
            "2325.2000-09-25.farmer.ham.txt\t4928.2001-09-24.farmer.ham.txt\n",
            "2326.2000-09-25.farmer.ham.txt\t4929.2001-09-24.farmer.ham.txt\n",
            "2327.2000-09-25.farmer.ham.txt\t4930.2001-09-25.farmer.ham.txt\n",
            "2328.2000-09-25.farmer.ham.txt\t4932.2001-09-25.farmer.ham.txt\n",
            "2329.2000-09-25.farmer.ham.txt\t4933.2001-09-26.farmer.ham.txt\n",
            "2330.2000-09-25.farmer.ham.txt\t4934.2001-09-26.farmer.ham.txt\n",
            "2331.2000-09-25.farmer.ham.txt\t4936.2001-09-27.farmer.ham.txt\n",
            "2332.2000-09-25.farmer.ham.txt\t4937.2001-09-27.farmer.ham.txt\n",
            "2334.2000-09-25.farmer.ham.txt\t4941.2001-09-27.farmer.ham.txt\n",
            "2335.2000-09-26.farmer.ham.txt\t4942.2001-09-27.farmer.ham.txt\n",
            "2336.2000-09-26.farmer.ham.txt\t4945.2001-09-28.farmer.ham.txt\n",
            "2337.2000-09-26.farmer.ham.txt\t4946.2001-09-28.farmer.ham.txt\n",
            "2339.2000-09-26.farmer.ham.txt\t4948.2001-10-01.farmer.ham.txt\n",
            "2341.2000-09-26.farmer.ham.txt\t4949.2001-10-01.farmer.ham.txt\n",
            "2342.2000-09-26.farmer.ham.txt\t4950.2001-10-01.farmer.ham.txt\n",
            "2343.2000-09-26.farmer.ham.txt\t4951.2001-10-01.farmer.ham.txt\n",
            "2344.2000-09-26.farmer.ham.txt\t4953.2001-10-02.farmer.ham.txt\n",
            "2345.2000-09-26.farmer.ham.txt\t4954.2001-10-03.farmer.ham.txt\n",
            "2346.2000-09-26.farmer.ham.txt\t4956.2001-10-03.farmer.ham.txt\n",
            "2349.2000-09-26.farmer.ham.txt\t4957.2001-10-04.farmer.ham.txt\n",
            "2350.2000-09-26.farmer.ham.txt\t4959.2001-10-04.farmer.ham.txt\n",
            "2351.2000-09-26.farmer.ham.txt\t4960.2001-10-04.farmer.ham.txt\n",
            "2352.2000-09-26.farmer.ham.txt\t4961.2001-10-05.farmer.ham.txt\n",
            "2355.2000-09-26.farmer.ham.txt\t4962.2001-10-09.farmer.ham.txt\n",
            "2356.2000-09-26.farmer.ham.txt\t4963.2001-10-10.farmer.ham.txt\n",
            "2357.2000-09-27.farmer.ham.txt\t4965.2001-10-11.farmer.ham.txt\n",
            "2359.2000-09-27.farmer.ham.txt\t4966.2001-10-11.farmer.ham.txt\n",
            "2360.2000-09-27.farmer.ham.txt\t4967.2001-10-11.farmer.ham.txt\n",
            "2361.2000-09-27.farmer.ham.txt\t4968.2001-10-12.farmer.ham.txt\n",
            "2363.2000-09-27.farmer.ham.txt\t4970.2001-10-12.farmer.ham.txt\n",
            "2366.2000-09-27.farmer.ham.txt\t4972.2001-10-12.farmer.ham.txt\n",
            "2368.2000-09-27.farmer.ham.txt\t4974.2001-10-12.farmer.ham.txt\n",
            "2369.2000-09-28.farmer.ham.txt\t4975.2001-10-15.farmer.ham.txt\n",
            "2370.2000-09-28.farmer.ham.txt\t4976.2001-10-15.farmer.ham.txt\n",
            "2372.2000-09-28.farmer.ham.txt\t4977.2001-10-15.farmer.ham.txt\n",
            "2373.2000-09-28.farmer.ham.txt\t4978.2001-10-15.farmer.ham.txt\n",
            "2375.2000-09-28.farmer.ham.txt\t4980.2001-10-15.farmer.ham.txt\n",
            "2376.2000-09-28.farmer.ham.txt\t4981.2001-10-15.farmer.ham.txt\n",
            "2378.2000-09-28.farmer.ham.txt\t4982.2001-10-16.farmer.ham.txt\n",
            "2379.2000-09-28.farmer.ham.txt\t4983.2001-10-16.farmer.ham.txt\n",
            "2380.2000-09-28.farmer.ham.txt\t4986.2001-10-17.farmer.ham.txt\n",
            "2382.2000-09-28.farmer.ham.txt\t4987.2001-10-18.farmer.ham.txt\n",
            "2383.2000-09-28.farmer.ham.txt\t4989.2001-10-18.farmer.ham.txt\n",
            "2384.2000-09-28.farmer.ham.txt\t4992.2001-10-18.farmer.ham.txt\n",
            "2385.2000-09-28.farmer.ham.txt\t4995.2001-10-19.farmer.ham.txt\n",
            "2386.2000-09-28.farmer.ham.txt\t4996.2001-10-19.farmer.ham.txt\n",
            "2387.2000-09-28.farmer.ham.txt\t4997.2001-10-22.farmer.ham.txt\n",
            "2388.2000-09-29.farmer.ham.txt\t4998.2001-10-22.farmer.ham.txt\n",
            "2389.2000-09-29.farmer.ham.txt\t4999.2001-10-23.farmer.ham.txt\n",
            "2390.2000-09-29.farmer.ham.txt\t5000.2001-10-23.farmer.ham.txt\n",
            "2392.2000-09-29.farmer.ham.txt\t5001.2001-10-24.farmer.ham.txt\n",
            "2393.2000-09-29.farmer.ham.txt\t5003.2001-10-24.farmer.ham.txt\n",
            "2394.2000-09-29.farmer.ham.txt\t5004.2001-10-24.farmer.ham.txt\n",
            "2395.2000-09-29.farmer.ham.txt\t5005.2001-10-24.farmer.ham.txt\n",
            "2396.2000-09-29.farmer.ham.txt\t5008.2001-10-25.farmer.ham.txt\n",
            "2397.2000-09-29.farmer.ham.txt\t5010.2001-10-25.farmer.ham.txt\n",
            "2400.2000-09-29.farmer.ham.txt\t5012.2001-10-25.farmer.ham.txt\n",
            "2401.2000-09-29.farmer.ham.txt\t5013.2001-10-26.farmer.ham.txt\n",
            "2402.2000-09-29.farmer.ham.txt\t5014.2001-10-26.farmer.ham.txt\n",
            "2404.2000-09-29.farmer.ham.txt\t5015.2001-10-26.farmer.ham.txt\n",
            "2405.2000-09-29.farmer.ham.txt\t5016.2001-10-29.farmer.ham.txt\n",
            "2407.2000-09-29.farmer.ham.txt\t5017.2001-10-30.farmer.ham.txt\n",
            "2409.2000-10-02.farmer.ham.txt\t5019.2001-10-30.farmer.ham.txt\n",
            "2411.2000-10-02.farmer.ham.txt\t5021.2001-10-30.farmer.ham.txt\n",
            "2412.2000-10-02.farmer.ham.txt\t5022.2001-10-30.farmer.ham.txt\n",
            "2413.2000-10-02.farmer.ham.txt\t5023.2001-10-30.farmer.ham.txt\n",
            "2414.2000-10-02.farmer.ham.txt\t5024.2001-10-30.farmer.ham.txt\n",
            "2415.2000-10-02.farmer.ham.txt\t5025.2001-10-31.farmer.ham.txt\n",
            "2418.2000-10-02.farmer.ham.txt\t5026.2001-10-31.farmer.ham.txt\n",
            "2419.2000-10-02.farmer.ham.txt\t5027.2001-10-31.farmer.ham.txt\n",
            "2420.2000-10-02.farmer.ham.txt\t5029.2001-10-31.farmer.ham.txt\n",
            "2422.2000-10-02.farmer.ham.txt\t5030.2001-10-31.farmer.ham.txt\n",
            "2424.2000-10-02.farmer.ham.txt\t5033.2001-10-31.farmer.ham.txt\n",
            "2425.2000-10-02.farmer.ham.txt\t5034.2001-11-01.farmer.ham.txt\n",
            "2426.2000-10-03.farmer.ham.txt\t5035.2001-11-02.farmer.ham.txt\n",
            "2427.2000-10-03.farmer.ham.txt\t5037.2001-11-02.farmer.ham.txt\n",
            "2428.2000-10-03.farmer.ham.txt\t5038.2001-11-05.farmer.ham.txt\n",
            "2429.2000-10-03.farmer.ham.txt\t5040.2001-11-05.farmer.ham.txt\n",
            "2431.2000-10-03.farmer.ham.txt\t5041.2001-11-06.farmer.ham.txt\n",
            "2432.2000-10-03.farmer.ham.txt\t5043.2001-11-06.farmer.ham.txt\n",
            "2434.2000-10-03.farmer.ham.txt\t5044.2001-11-06.farmer.ham.txt\n",
            "2436.2000-10-03.farmer.ham.txt\t5045.2001-11-06.farmer.ham.txt\n",
            "2438.2000-10-03.farmer.ham.txt\t5046.2001-11-06.farmer.ham.txt\n",
            "2439.2000-10-03.farmer.ham.txt\t5047.2001-11-06.farmer.ham.txt\n",
            "2440.2000-10-03.farmer.ham.txt\t5048.2001-11-07.farmer.ham.txt\n",
            "2441.2000-10-04.farmer.ham.txt\t5049.2001-11-07.farmer.ham.txt\n",
            "2443.2000-10-04.farmer.ham.txt\t5050.2001-11-07.farmer.ham.txt\n",
            "2444.2000-10-04.farmer.ham.txt\t5052.2001-11-07.farmer.ham.txt\n",
            "2445.2000-10-04.farmer.ham.txt\t5053.2001-11-08.farmer.ham.txt\n",
            "2446.2000-10-04.farmer.ham.txt\t5054.2001-11-08.farmer.ham.txt\n",
            "2448.2000-10-05.farmer.ham.txt\t5056.2001-11-08.farmer.ham.txt\n",
            "2449.2000-10-05.farmer.ham.txt\t5059.2001-11-08.farmer.ham.txt\n",
            "2450.2000-10-05.farmer.ham.txt\t5061.2001-11-09.farmer.ham.txt\n",
            "2451.2000-10-05.farmer.ham.txt\t5062.2001-11-09.farmer.ham.txt\n",
            "2453.2000-10-05.farmer.ham.txt\t5063.2001-11-12.farmer.ham.txt\n",
            "2454.2000-10-05.farmer.ham.txt\t5064.2001-11-12.farmer.ham.txt\n",
            "2456.2000-10-05.farmer.ham.txt\t5065.2001-11-13.farmer.ham.txt\n",
            "2457.2000-10-05.farmer.ham.txt\t5067.2001-11-13.farmer.ham.txt\n",
            "2459.2000-10-05.farmer.ham.txt\t5069.2001-11-14.farmer.ham.txt\n",
            "2460.2000-10-05.farmer.ham.txt\t5070.2001-11-14.farmer.ham.txt\n",
            "2461.2000-10-05.farmer.ham.txt\t5073.2001-11-14.farmer.ham.txt\n",
            "2463.2000-10-05.farmer.ham.txt\t5074.2001-11-14.farmer.ham.txt\n",
            "2464.2000-10-05.farmer.ham.txt\t5075.2001-11-15.farmer.ham.txt\n",
            "2465.2000-10-05.farmer.ham.txt\t5076.2001-11-19.farmer.ham.txt\n",
            "2467.2000-10-05.farmer.ham.txt\t5077.2001-11-19.farmer.ham.txt\n",
            "2469.2000-10-05.farmer.ham.txt\t5078.2001-11-20.farmer.ham.txt\n",
            "2470.2000-10-05.farmer.ham.txt\t5080.2001-11-20.farmer.ham.txt\n",
            "2471.2000-10-06.farmer.ham.txt\t5082.2001-11-21.farmer.ham.txt\n",
            "2473.2000-10-06.farmer.ham.txt\t5084.2001-11-26.farmer.ham.txt\n",
            "2474.2000-10-06.farmer.ham.txt\t5085.2001-11-26.farmer.ham.txt\n",
            "2476.2000-10-06.farmer.ham.txt\t5086.2001-11-27.farmer.ham.txt\n",
            "2477.2000-10-06.farmer.ham.txt\t5088.2001-11-27.farmer.ham.txt\n",
            "2478.2000-10-06.farmer.ham.txt\t5091.2001-11-29.farmer.ham.txt\n",
            "2479.2000-10-06.farmer.ham.txt\t5092.2001-11-29.farmer.ham.txt\n",
            "2481.2000-10-09.farmer.ham.txt\t5093.2001-11-30.farmer.ham.txt\n",
            "2482.2000-10-09.farmer.ham.txt\t5094.2001-11-30.farmer.ham.txt\n",
            "2485.2000-10-09.farmer.ham.txt\t5095.2001-12-02.farmer.ham.txt\n",
            "2486.2000-10-10.farmer.ham.txt\t5097.2001-12-04.farmer.ham.txt\n",
            "2487.2000-10-10.farmer.ham.txt\t5098.2001-12-05.farmer.ham.txt\n",
            "2489.2000-10-10.farmer.ham.txt\t5100.2001-12-07.farmer.ham.txt\n",
            "2492.2000-10-10.farmer.ham.txt\t5102.2001-12-08.farmer.ham.txt\n",
            "2493.2000-10-10.farmer.ham.txt\t5104.2001-12-11.farmer.ham.txt\n",
            "2494.2000-10-10.farmer.ham.txt\t5106.2001-12-11.farmer.ham.txt\n",
            "2496.2000-10-10.farmer.ham.txt\t5108.2001-12-11.farmer.ham.txt\n",
            "2497.2000-10-10.farmer.ham.txt\t5109.2001-12-11.farmer.ham.txt\n",
            "2499.2000-10-10.farmer.ham.txt\t5111.2001-12-11.farmer.ham.txt\n",
            "2501.2000-10-10.farmer.ham.txt\t5113.2001-12-11.farmer.ham.txt\n",
            "2502.2000-10-10.farmer.ham.txt\t5114.2001-12-11.farmer.ham.txt\n",
            "2503.2000-10-10.farmer.ham.txt\t5116.2001-12-11.farmer.ham.txt\n",
            "2504.2000-10-10.farmer.ham.txt\t5117.2001-12-12.farmer.ham.txt\n",
            "2506.2000-10-10.farmer.ham.txt\t5118.2001-12-12.farmer.ham.txt\n",
            "2507.2000-10-11.farmer.ham.txt\t5120.2001-12-13.farmer.ham.txt\n",
            "2509.2000-10-11.farmer.ham.txt\t5121.2001-12-13.farmer.ham.txt\n",
            "2510.2000-10-11.farmer.ham.txt\t5122.2001-12-13.farmer.ham.txt\n",
            "2513.2000-10-11.farmer.ham.txt\t5124.2001-12-13.farmer.ham.txt\n",
            "2515.2000-10-11.farmer.ham.txt\t5125.2001-12-14.farmer.ham.txt\n",
            "2516.2000-10-11.farmer.ham.txt\t5126.2001-12-14.farmer.ham.txt\n",
            "2517.2000-10-12.farmer.ham.txt\t5127.2001-12-14.farmer.ham.txt\n",
            "2519.2000-10-12.farmer.ham.txt\t5129.2001-12-17.farmer.ham.txt\n",
            "2521.2000-10-12.farmer.ham.txt\t5130.2001-12-17.farmer.ham.txt\n",
            "2523.2000-10-13.farmer.ham.txt\t5131.2001-12-19.farmer.ham.txt\n",
            "2524.2000-10-13.farmer.ham.txt\t5133.2001-12-20.farmer.ham.txt\n",
            "2525.2000-10-13.farmer.ham.txt\t5134.2001-12-20.farmer.ham.txt\n",
            "2527.2000-10-13.farmer.ham.txt\t5135.2001-12-20.farmer.ham.txt\n",
            "2528.2000-10-13.farmer.ham.txt\t5137.2001-12-26.farmer.ham.txt\n",
            "2531.2000-10-13.farmer.ham.txt\t5139.2002-01-02.farmer.ham.txt\n",
            "2532.2000-10-13.farmer.ham.txt\t5140.2002-01-02.farmer.ham.txt\n",
            "2533.2000-10-13.farmer.ham.txt\t5141.2002-01-02.farmer.ham.txt\n",
            "2534.2000-10-13.farmer.ham.txt\t5142.2002-01-02.farmer.ham.txt\n",
            "2535.2000-10-14.farmer.ham.txt\t5144.2002-01-04.farmer.ham.txt\n",
            "2536.2000-10-16.farmer.ham.txt\t5146.2002-01-04.farmer.ham.txt\n",
            "2537.2000-10-16.farmer.ham.txt\t5147.2002-01-04.farmer.ham.txt\n",
            "2538.2000-10-16.farmer.ham.txt\t5148.2002-01-04.farmer.ham.txt\n",
            "2541.2000-10-16.farmer.ham.txt\t5149.2002-01-04.farmer.ham.txt\n",
            "2542.2000-10-16.farmer.ham.txt\t5150.2002-01-07.farmer.ham.txt\n",
            "2543.2000-10-16.farmer.ham.txt\t5151.2002-01-07.farmer.ham.txt\n",
            "2544.2000-10-16.farmer.ham.txt\t5152.2002-01-07.farmer.ham.txt\n",
            "2545.2000-10-16.farmer.ham.txt\t5153.2002-01-07.farmer.ham.txt\n",
            "2546.2000-10-16.farmer.ham.txt\t5156.2002-01-07.farmer.ham.txt\n",
            "2547.2000-10-16.farmer.ham.txt\t5158.2002-01-07.farmer.ham.txt\n",
            "2548.2000-10-17.farmer.ham.txt\t5159.2002-01-07.farmer.ham.txt\n",
            "2550.2000-10-17.farmer.ham.txt\t5161.2002-01-08.farmer.ham.txt\n",
            "2551.2000-10-17.farmer.ham.txt\t5162.2002-01-09.farmer.ham.txt\n",
            "2553.2000-10-17.farmer.ham.txt\t5165.2002-01-09.farmer.ham.txt\n",
            "2556.2000-10-17.farmer.ham.txt\t5166.2002-01-09.farmer.ham.txt\n",
            "2558.2000-10-17.farmer.ham.txt\t5168.2002-01-10.farmer.ham.txt\n",
            "2559.2000-10-17.farmer.ham.txt\t5169.2002-01-11.farmer.ham.txt\n",
            "2560.2000-10-17.farmer.ham.txt\t5172.2002-01-11.farmer.ham.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLqTwzJoyRz"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "import os\n",
        "import codecs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJl6H8UmMu22"
      },
      "source": [
        "def init_lists(folder):\n",
        "    key_list = []\n",
        "    file_list = os.listdir(folder)\n",
        "    for filename in file_list:\n",
        "        f = codecs.open(folder + filename, 'r', encoding='utf-8', errors='ignore')\n",
        "        key_list.append(f.read())\n",
        "    f.close()\n",
        "    return key_list\n",
        "\n",
        "all_mails = list()\n",
        "spam = init_lists('./enron1/spam/')\n",
        "ham = init_lists('./enron1/ham/')\n",
        "# リストにした迷惑メール(spam)と、通常のメール(ham)を別のリストにコピーし、迷惑メールの場合はラベルを1に、そうでない場合は0にする\n",
        "all_mails = [(mail, '1') for mail in spam]\n",
        "all_mails += [(mail, '0') for mail in ham]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pandas\n",
        "\n",
        "データフレームのこと。簡単にいえば表にするということ"
      ],
      "metadata": {
        "id": "BT9k-qvCdpsR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6chOK7N1t4"
      },
      "source": [
        "import pandas as pd\n",
        "# DataFrameにメールの文面とラベルを列に設定してロードする\n",
        "df = pd.DataFrame(all_mails, columns=['text', 'label'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GH8UEqbOiAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b18e7636-47bd-4383-bc67-7f184b097f16"
      },
      "source": [
        "df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text label\n",
              "0     Subject: homeowners - get more money in your p...     1\n",
              "1     Subject: pain is killing you\\r\\nsun , 05 dec 2...     1\n",
              "2     Subject: vulgar\\r\\nmuniz ,\\r\\ngovenment don ' ...     1\n",
              "3     Subject: special offers - various\\r\\ntoday ' s...     1\n",
              "4     Subject: down . load - dvd , mp 3 , music , pl...     1\n",
              "...                                                 ...   ...\n",
              "5167  Subject: re : basin production from ga 213\\r\\n...     0\n",
              "5168  Subject: fw : calpine daily gas nomination\\r\\n...     0\n",
              "5169  Subject: purchase and sale nominations - eastr...     0\n",
              "5170  Subject: the houston expl dec 2000\\r\\ndarren :...     0\n",
              "5171  Subject: eastrans nomination change effective ...     0\n",
              "\n",
              "[5172 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c74934bc-11d6-4690-b56f-c931bb3c1484\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: homeowners - get more money in your p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: pain is killing you\\r\\nsun , 05 dec 2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: vulgar\\r\\nmuniz ,\\r\\ngovenment don ' ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: special offers - various\\r\\ntoday ' s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: down . load - dvd , mp 3 , music , pl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>Subject: re : basin production from ga 213\\r\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>Subject: fw : calpine daily gas nomination\\r\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>Subject: purchase and sale nominations - eastr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>Subject: the houston expl dec 2000\\r\\ndarren :...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>Subject: eastrans nomination change effective ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5172 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c74934bc-11d6-4690-b56f-c931bb3c1484')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c74934bc-11d6-4690-b56f-c931bb3c1484 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c74934bc-11d6-4690-b56f-c931bb3c1484');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-79be1cee-dff4-4ed9-9119-6a6e8b5e44e4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79be1cee-dff4-4ed9-9119-6a6e8b5e44e4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-79be1cee-dff4-4ed9-9119-6a6e8b5e44e4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_795bc94d-4b55-4801-b519-7a9c9b1f654b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_795bc94d-4b55-4801-b519-7a9c9b1f654b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5172,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4994,\n        \"samples\": [\n          \"Subject: dell pentium 4 2 . 8 ghz system\\r\\n$ 585 . 00\\r\\nthis dell system features a powerful\\r\\ncombination with the intel pentium 4 2 . 8 ghz processor\\r\\nand 256 mb ram . a large 40 gb hard disk drive plays host\\r\\nto microsoft windows xp home edition . a cd - rw drive ,\\r\\ndvd - rom drive and a floppy disk drive are all\\r\\npre - installed . integrated graphics and integrated audio\\r\\nare included to get you up and running\\r\\n.\\r\\nprocessor\\r\\nram\\r\\nhdd\\r\\ndrive\\r\\no / s\\r\\nothers\\r\\np 4 2 . 8 ghz\\r\\n256 mb\\r\\n40 gb\\r\\ndvd / cdrw + fdd\\r\\nwinxp home\\r\\nvga + sound\\r\\nvisit : http : / / www . computron - me . com for deals !\\r\\nyour one stop\\r\\ndistributorjebel ali duty free zonewww . computron - me . com\\r\\nfor latest clearance sale listing contact our\\r\\nsales department .\\r\\nonly limited quantities available on selected\\r\\nspecials ! ! ! !\\r\\nif you have any\\r\\ncomplaints / suggestions contact customerservice @ computron - me . com\\r\\ncompaq\\r\\nhewlett packard\\r\\n3 com\\r\\ndell\\r\\nintel\\r\\niomega\\r\\nepson\\r\\naopen\\r\\ncreative\\r\\ntoshiba\\r\\napc\\r\\ncisco\\r\\nus\\r\\nrobotics\\r\\nmicrosoft\\r\\ncanon\\r\\nintellinet\\r\\ntargus\\r\\nviewsonic\\r\\nibm\\r\\nsony\\r\\n- - - - - - - and lots more\\r\\n! ! !\\r\\ntel + 971 4 8834464\\r\\nall prices in u . s . dollars , ex - works ,\\r\\nfax + 971 4 8834454\\r\\njebel ali duty free zone\\r\\nwww . computron - me . com\\r\\nprices and availability subject to change\\r\\nusa - canada u . a . e .\\r\\nwithout\\r\\nnotice .\\r\\nto receive our special offers\\r\\nin plain\\r\\ntext format reply to this\\r\\nmail with the request * for export only\\r\\n*\\r\\nthis\\r\\nemail can not be considered spam as long as we include : contact\\r\\ninformation remove instructions . this message is intended for dealer\\r\\nand resellers only . if you have somehow gotten on this list in error , or\\r\\nfor any other reason would like to be removed , please reply with \\\" remove\\r\\n\\\" in the subject line of your message . this message is being sent to you\\r\\nin compliance with the federal legislation for commercial e - mail\\r\\n( h . r . 4176 - section 101 paragraph ( e ) ( 1 ) ( a ) and bill s . 1618 title iii\\r\\npassed by the 105 th u . s . congress .\\r\\nall logos and\\r\\ntrademarks are the property of their respective ownerstoshiba for export\\r\\nonly\\r\\nproducts may not be exactly as shown\\r\\nabove\\r\\n- -\\r\\nto unsubscribe from : computron 8 , just follow this link :\\r\\nclick the link , or copy and paste the address into your browser .\",\n          \"Subject: nb real vallum , x . anax , l . evitra . . soma . . much more . . . . . . us p ` harmacies\\r\\nverrotst trapsgewijs wetswijzigingen\\r\\nthe biggest phaermacy store ! save over 80 % ! more than 3 , 000 , 000 satiqsfied\\r\\ncustomers this year !\\r\\norder these pills : ; ^ so + m + a p / n / termin v / a / lium . xan @ x\\r\\nwe ship us international low price , overnite delivery , privacy !\\r\\nq w http : / / vbfd . is . baewo . com / 29 /\\r\\nit was at a five o ' clock tea . a young man came to the hostess to apologize\\r\\nfor his lateness . so good of you to come , mr . jones , and where is your\\r\\nbrother ? you see we ' re very busy in the office and only one of us could\\r\\ncome , so we tossed up for it . how nice ! and so original , too ! and you\\r\\nwon ? no , said the young man absently , i lost !\\r\\na man goes to church and starts talking to god . he says : god , what is a\\r\\nmillion dollars to you ? and god says : a penny , then the man says : god ,\\r\\nwhat is a million years to you ? and god says : a second , then the man\\r\\nsays : god , can i have a penny ? and god says in a second\\r\\ninsatisfecha 3 barbirrucioo 2 lupanaria , manaza marcescente .\\r\\n\",\n          \"Subject: hpl nom for february 3 , 2001\\r\\n( see attached file : hplno 203 . xls )\\r\\n- hplno 203 . xls\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"0\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "通常は50000のデータに対して行うが、メモリの都合上、10000に制限する"
      ],
      "metadata": {
        "id": "dViYvUj_i3Es"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsbz6P6dO6RS"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# TfidfVectorizerを初期化する。stop_wordsにenglishを指定し、一般的な単語を除外する\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\", lowercase=False, max_features=10000)\n",
        "\n",
        "X = tfidf.fit_transform(df['text'])\n",
        "column_names = tfidf.get_feature_names_out()\n",
        "\n",
        "# Xにベクトル化した値を整形して代入\n",
        "X = pd.DataFrame(X.toarray())\n",
        "X = X.astype('float')\n",
        "# カラム名を設定\n",
        "X.columns = column_names\n",
        "y = df['label'].astype('float')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSy_aU8Cixg6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "e8ad90f8-045a-4b06-d8c8-4c65a95f5ab7"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>000000</th>\n",
              "      <th>000000000002858</th>\n",
              "      <th>000000000049773</th>\n",
              "      <th>000080</th>\n",
              "      <th>000099</th>\n",
              "      <th>0001</th>\n",
              "      <th>00018</th>\n",
              "      <th>00020608</th>\n",
              "      <th>0004</th>\n",
              "      <th>0005</th>\n",
              "      <th>0008</th>\n",
              "      <th>001</th>\n",
              "      <th>0010</th>\n",
              "      <th>001001</th>\n",
              "      <th>0012</th>\n",
              "      <th>001452</th>\n",
              "      <th>002</th>\n",
              "      <th>0022</th>\n",
              "      <th>00221</th>\n",
              "      <th>0025</th>\n",
              "      <th>0027</th>\n",
              "      <th>0028</th>\n",
              "      <th>0029</th>\n",
              "      <th>00298</th>\n",
              "      <th>003</th>\n",
              "      <th>0030</th>\n",
              "      <th>003002</th>\n",
              "      <th>0031</th>\n",
              "      <th>0033</th>\n",
              "      <th>0038</th>\n",
              "      <th>004</th>\n",
              "      <th>0042</th>\n",
              "      <th>0043</th>\n",
              "      <th>0044</th>\n",
              "      <th>0045</th>\n",
              "      <th>0046</th>\n",
              "      <th>0047</th>\n",
              "      <th>...</th>\n",
              "      <th>zv</th>\n",
              "      <th>zve</th>\n",
              "      <th>zvikydqu</th>\n",
              "      <th>zvjc</th>\n",
              "      <th>zvp</th>\n",
              "      <th>zvrkxjmex</th>\n",
              "      <th>zvx</th>\n",
              "      <th>zw</th>\n",
              "      <th>zwallet</th>\n",
              "      <th>zwdm</th>\n",
              "      <th>zwftnqlp</th>\n",
              "      <th>zwiers</th>\n",
              "      <th>zwmdjvr</th>\n",
              "      <th>zwoegen</th>\n",
              "      <th>zwu</th>\n",
              "      <th>zxaghur</th>\n",
              "      <th>zxgwvpiadobe</th>\n",
              "      <th>zxgwvpihere</th>\n",
              "      <th>zxgwvpiimg</th>\n",
              "      <th>zxgwvpimacromedia</th>\n",
              "      <th>zxgwvpimicrosoft</th>\n",
              "      <th>zxgwvpinorton</th>\n",
              "      <th>zxjcxz</th>\n",
              "      <th>zxklh</th>\n",
              "      <th>zxzmcnbf</th>\n",
              "      <th>zyban</th>\n",
              "      <th>zyjvit</th>\n",
              "      <th>zykfe</th>\n",
              "      <th>zyl</th>\n",
              "      <th>zynsdirnh</th>\n",
              "      <th>zynve</th>\n",
              "      <th>zyqtaqlt</th>\n",
              "      <th>zyrtec</th>\n",
              "      <th>zyyqywp</th>\n",
              "      <th>zzezrjok</th>\n",
              "      <th>zzn</th>\n",
              "      <th>zzo</th>\n",
              "      <th>zzocb</th>\n",
              "      <th>zzso</th>\n",
              "      <th>zzsyt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.511833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.180055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>0.049459</td>\n",
              "      <td>0.015846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023266</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5172 rows × 50157 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            00       000  0000  000000  ...  zzo  zzocb  zzso  zzsyt\n",
              "0     0.511833  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "1     0.180055  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "2     0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "3     0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "4     0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "...        ...       ...   ...     ...  ...  ...    ...   ...    ...\n",
              "5167  0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5168  0.049459  0.015846   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5169  0.000000  0.023266   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5170  0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "5171  0.000000  0.000000   0.0     0.0  ...  0.0    0.0   0.0    0.0\n",
              "\n",
              "[5172 rows x 50157 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna-integration[lightgbm]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBttKKTMezRr",
        "outputId": "0f9528c7-7db8-48a0-c981-e70a290ed1f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna-integration[lightgbm] in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.4.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (4.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from optuna-integration[lightgbm]) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm->optuna-integration[lightgbm]) (1.15.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[lightgbm]) (6.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->optuna-integration[lightgbm]) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[lightgbm]) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[lightgbm]) (3.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM6apRkrlvoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee9acb8-3dc6-4b38-fd23-29bdfbef1a44"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna.integration.lightgbm as olgb\n",
        "import optuna\n",
        "\n",
        "# データセットを訓練用とテスト用に分割\n",
        "X_train, X_test, y_train, y_test =\\\n",
        " train_test_split(X, y, test_size=0.2, shuffle=True, random_state=101)\n",
        "\n",
        "# LightGBM用のデータセットに変換\n",
        "train = olgb.Dataset(X_train, y_train)\n",
        "\n",
        "# パラメータの設定\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"verbosity\": -1,\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "}\n",
        "\n",
        "# 交差検証を使用したハイパーパラメータの探索\n",
        "tuner = olgb.LightGBMTunerCV(params, train, num_boost_round=100)\n",
        "\n",
        "# ハイパーパラメータ探索の実行\n",
        "tuner.run()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-22 09:35:11,026] A new study created in memory with name: no-name-e8a4fb7c-9a34-44af-a9ef-73a7685cd86f\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "feature_fraction, val_score: 0.082508:   0%|          | 0/7 [00:19<?, ?it/s]\u001b[A\n",
            "feature_fraction, val_score: 0.082508:  14%|#4        | 1/7 [00:19<01:59, 19.84s/it]\u001b[A[I 2025-07-22 09:35:30,880] Trial 0 finished with value: 0.08250770028678737 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.08250770028678737.\n",
            "\n",
            "feature_fraction, val_score: 0.082508:  14%|#4        | 1/7 [00:19<01:59, 19.84s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.076984:  14%|#4        | 1/7 [00:42<01:59, 19.84s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.076984:  29%|##8       | 2/7 [00:42<01:47, 21.43s/it]\u001b[A[I 2025-07-22 09:35:53,429] Trial 1 finished with value: 0.07698446009961908 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.07698446009961908.\n",
            "\n",
            "feature_fraction, val_score: 0.076984:  29%|##8       | 2/7 [00:42<01:47, 21.43s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.076202:  29%|##8       | 2/7 [01:06<01:47, 21.43s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.076202:  43%|####2     | 3/7 [01:06<01:29, 22.44s/it]\u001b[A[I 2025-07-22 09:36:17,071] Trial 2 finished with value: 0.07620209749110936 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.07620209749110936.\n",
            "\n",
            "feature_fraction, val_score: 0.076202:  43%|####2     | 3/7 [01:06<01:29, 22.44s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.076202:  43%|####2     | 3/7 [01:23<01:29, 22.44s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.076202:  57%|#####7    | 4/7 [01:23<01:01, 20.55s/it]\u001b[A[I 2025-07-22 09:36:34,729] Trial 3 finished with value: 0.07911178679096935 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.07620209749110936.\n",
            "\n",
            "feature_fraction, val_score: 0.076202:  57%|#####7    | 4/7 [01:23<01:01, 20.55s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.073438:  57%|#####7    | 4/7 [01:44<01:01, 20.55s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.073438:  71%|#######1  | 5/7 [01:44<00:41, 20.63s/it]\u001b[A[I 2025-07-22 09:36:55,507] Trial 4 finished with value: 0.07343816565629167 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "feature_fraction, val_score: 0.073438:  71%|#######1  | 5/7 [01:44<00:41, 20.63s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.073438:  71%|#######1  | 5/7 [02:03<00:41, 20.63s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.073438:  86%|########5 | 6/7 [02:03<00:20, 20.02s/it]\u001b[A[I 2025-07-22 09:37:14,336] Trial 5 finished with value: 0.0825583415935831 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "feature_fraction, val_score: 0.073438:  86%|########5 | 6/7 [02:03<00:20, 20.02s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.073438:  86%|########5 | 6/7 [02:22<00:20, 20.02s/it]\u001b[A\n",
            "feature_fraction, val_score: 0.073438: 100%|##########| 7/7 [02:22<00:00, 19.61s/it]\u001b[A[I 2025-07-22 09:37:33,111] Trial 6 finished with value: 0.07974888377901498 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.07343816565629167.\n",
            "feature_fraction, val_score: 0.073438: 100%|##########| 7/7 [02:22<00:00, 20.30s/it]\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "num_leaves, val_score: 0.073438:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "num_leaves, val_score: 0.073438:   0%|          | 0/20 [00:22<?, ?it/s]\u001b[A\n",
            "num_leaves, val_score: 0.073438:   5%|5         | 1/20 [00:22<07:10, 22.66s/it]\u001b[A[I 2025-07-22 09:37:55,791] Trial 7 finished with value: 0.07660155858868069 and parameters: {'num_leaves': 44}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:   5%|5         | 1/20 [00:22<07:10, 22.66s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:   5%|5         | 1/20 [00:55<07:10, 22.66s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  10%|#         | 2/20 [00:55<08:37, 28.76s/it]\u001b[A[I 2025-07-22 09:38:28,825] Trial 8 finished with value: 0.07845654316980054 and parameters: {'num_leaves': 227}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  10%|#         | 2/20 [00:55<08:37, 28.76s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  10%|#         | 2/20 [01:27<08:37, 28.76s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  15%|#5        | 3/20 [01:27<08:33, 30.23s/it]\u001b[A[I 2025-07-22 09:39:00,805] Trial 9 finished with value: 0.07845654316980054 and parameters: {'num_leaves': 215}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  15%|#5        | 3/20 [01:27<08:33, 30.23s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  15%|#5        | 3/20 [01:58<08:33, 30.23s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  20%|##        | 4/20 [01:58<08:10, 30.66s/it]\u001b[A[I 2025-07-22 09:39:32,123] Trial 10 finished with value: 0.07521611470242406 and parameters: {'num_leaves': 23}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  20%|##        | 4/20 [01:59<08:10, 30.66s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  20%|##        | 4/20 [02:19<08:10, 30.66s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  25%|##5       | 5/20 [02:19<06:44, 26.94s/it]\u001b[A[I 2025-07-22 09:39:52,458] Trial 11 finished with value: 0.07910466313569028 and parameters: {'num_leaves': 17}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  25%|##5       | 5/20 [02:19<06:44, 26.94s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  25%|##5       | 5/20 [02:49<06:44, 26.94s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  30%|###       | 6/20 [02:49<06:30, 27.90s/it]\u001b[A[I 2025-07-22 09:40:22,235] Trial 12 finished with value: 0.07911124117948297 and parameters: {'num_leaves': 105}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  30%|###       | 6/20 [02:49<06:30, 27.90s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  30%|###       | 6/20 [03:23<06:30, 27.90s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  35%|###5      | 7/20 [03:23<06:32, 30.17s/it]\u001b[A[I 2025-07-22 09:40:57,056] Trial 13 finished with value: 0.07803748365701664 and parameters: {'num_leaves': 112}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  35%|###5      | 7/20 [03:23<06:32, 30.17s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  35%|###5      | 7/20 [03:38<06:32, 30.17s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  40%|####      | 8/20 [03:38<05:03, 25.31s/it]\u001b[A[I 2025-07-22 09:41:11,964] Trial 14 finished with value: 0.16363104787969912 and parameters: {'num_leaves': 4}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  40%|####      | 8/20 [03:38<05:03, 25.31s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  40%|####      | 8/20 [04:12<05:03, 25.31s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  45%|####5     | 9/20 [04:12<05:06, 27.83s/it]\u001b[A[I 2025-07-22 09:41:45,339] Trial 15 finished with value: 0.0784565431338694 and parameters: {'num_leaves': 171}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  45%|####5     | 9/20 [04:12<05:06, 27.83s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  45%|####5     | 9/20 [04:37<05:06, 27.83s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  50%|#####     | 10/20 [04:37<04:30, 27.06s/it]\u001b[A[I 2025-07-22 09:42:10,678] Trial 16 finished with value: 0.07817111591285573 and parameters: {'num_leaves': 69}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  50%|#####     | 10/20 [04:37<04:30, 27.06s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  50%|#####     | 10/20 [05:09<04:30, 27.06s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  55%|#####5    | 11/20 [05:09<04:17, 28.64s/it]\u001b[A[I 2025-07-22 09:42:42,886] Trial 17 finished with value: 0.07845654318856869 and parameters: {'num_leaves': 176}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  55%|#####5    | 11/20 [05:09<04:17, 28.64s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  55%|#####5    | 11/20 [05:35<04:17, 28.64s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  60%|######    | 12/20 [05:35<03:41, 27.64s/it]\u001b[A[I 2025-07-22 09:43:08,254] Trial 18 finished with value: 0.07876594130315537 and parameters: {'num_leaves': 74}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  60%|######    | 12/20 [05:35<03:41, 27.64s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  60%|######    | 12/20 [06:07<03:41, 27.64s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  65%|######5   | 13/20 [06:07<03:24, 29.22s/it]\u001b[A[I 2025-07-22 09:43:41,089] Trial 19 finished with value: 0.07845651607358892 and parameters: {'num_leaves': 151}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  65%|######5   | 13/20 [06:07<03:24, 29.22s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  65%|######5   | 13/20 [06:30<03:24, 29.22s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  70%|#######   | 14/20 [06:30<02:43, 27.29s/it]\u001b[A[I 2025-07-22 09:44:03,933] Trial 20 finished with value: 0.07717346313106185 and parameters: {'num_leaves': 46}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  70%|#######   | 14/20 [06:30<02:43, 27.29s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  70%|#######   | 14/20 [06:59<02:43, 27.29s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  75%|#######5  | 15/20 [06:59<02:18, 27.68s/it]\u001b[A[I 2025-07-22 09:44:32,505] Trial 21 finished with value: 0.07872728874772286 and parameters: {'num_leaves': 93}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  75%|#######5  | 15/20 [06:59<02:18, 27.68s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  75%|#######5  | 15/20 [07:44<02:18, 27.68s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  80%|########  | 16/20 [07:44<02:12, 33.06s/it]\u001b[A[I 2025-07-22 09:45:18,078] Trial 22 finished with value: 0.07845649475451572 and parameters: {'num_leaves': 146}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  80%|########  | 16/20 [07:44<02:12, 33.06s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  80%|########  | 16/20 [08:17<02:12, 33.06s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  85%|########5 | 17/20 [08:17<01:38, 32.90s/it]\u001b[A[I 2025-07-22 09:45:50,592] Trial 23 finished with value: 0.07420711226696029 and parameters: {'num_leaves': 33}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  85%|########5 | 17/20 [08:17<01:38, 32.90s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  85%|########5 | 17/20 [08:44<01:38, 32.90s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  90%|######### | 18/20 [08:44<01:02, 31.11s/it]\u001b[A[I 2025-07-22 09:46:17,546] Trial 24 finished with value: 0.07498904160213093 and parameters: {'num_leaves': 34}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  90%|######### | 18/20 [08:44<01:02, 31.11s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  90%|######### | 18/20 [09:14<01:02, 31.11s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  95%|#########5| 19/20 [09:14<00:30, 30.87s/it]\u001b[A[I 2025-07-22 09:46:47,851] Trial 25 finished with value: 0.07692144401762062 and parameters: {'num_leaves': 49}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "num_leaves, val_score: 0.073438:  95%|#########5| 19/20 [09:14<00:30, 30.87s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438:  95%|#########5| 19/20 [09:49<00:30, 30.87s/it]\u001b[A\n",
            "num_leaves, val_score: 0.073438: 100%|##########| 20/20 [09:49<00:00, 31.99s/it]\u001b[A[I 2025-07-22 09:47:22,465] Trial 26 finished with value: 0.07858242880619795 and parameters: {'num_leaves': 79}. Best is trial 4 with value: 0.07343816565629167.\n",
            "num_leaves, val_score: 0.073438: 100%|##########| 20/20 [09:49<00:00, 29.47s/it]\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "bagging, val_score: 0.073438:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "bagging, val_score: 0.073438:   0%|          | 0/10 [00:46<?, ?it/s]\u001b[A\n",
            "bagging, val_score: 0.073438:  10%|#         | 1/10 [00:46<06:54, 46.02s/it]\u001b[A[I 2025-07-22 09:48:08,504] Trial 27 finished with value: 0.07348386015146095 and parameters: {'bagging_fraction': 0.9262225822808051, 'bagging_freq': 2}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  10%|#         | 1/10 [00:46<06:54, 46.02s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  10%|#         | 1/10 [01:22<06:54, 46.02s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  20%|##        | 2/10 [01:22<05:24, 40.62s/it]\u001b[A[I 2025-07-22 09:48:45,351] Trial 28 finished with value: 0.07537274605620294 and parameters: {'bagging_fraction': 0.9612833892898849, 'bagging_freq': 2}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  20%|##        | 2/10 [01:22<05:24, 40.62s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  20%|##        | 2/10 [01:54<05:24, 40.62s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  30%|###       | 3/10 [01:54<04:16, 36.58s/it]\u001b[A[I 2025-07-22 09:49:17,131] Trial 29 finished with value: 0.07465996485693042 and parameters: {'bagging_fraction': 0.8338874137840059, 'bagging_freq': 4}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  30%|###       | 3/10 [01:54<04:16, 36.58s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  30%|###       | 3/10 [02:14<04:16, 36.58s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  40%|####      | 4/10 [02:14<03:00, 30.16s/it]\u001b[A[I 2025-07-22 09:49:37,447] Trial 30 finished with value: 0.07962530269734154 and parameters: {'bagging_fraction': 0.579090744461453, 'bagging_freq': 1}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  40%|####      | 4/10 [02:14<03:00, 30.16s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  40%|####      | 4/10 [02:39<03:00, 30.16s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  50%|#####     | 5/10 [02:39<02:20, 28.14s/it]\u001b[A[I 2025-07-22 09:50:01,991] Trial 31 finished with value: 0.07460075116599058 and parameters: {'bagging_fraction': 0.9001639997316556, 'bagging_freq': 6}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  50%|#####     | 5/10 [02:39<02:20, 28.14s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  50%|#####     | 5/10 [03:04<02:20, 28.14s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  60%|######    | 6/10 [03:04<01:47, 26.97s/it]\u001b[A[I 2025-07-22 09:50:26,687] Trial 32 finished with value: 0.07612959583716891 and parameters: {'bagging_fraction': 0.9948495810282034, 'bagging_freq': 7}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  60%|######    | 6/10 [03:04<01:47, 26.97s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  60%|######    | 6/10 [03:27<01:47, 26.97s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  70%|#######   | 7/10 [03:27<01:17, 25.83s/it]\u001b[A[I 2025-07-22 09:50:50,188] Trial 33 finished with value: 0.07811765236558788 and parameters: {'bagging_fraction': 0.7649367556955089, 'bagging_freq': 7}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  70%|#######   | 7/10 [03:27<01:17, 25.83s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  70%|#######   | 7/10 [03:54<01:17, 25.83s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  80%|########  | 8/10 [03:54<00:52, 26.24s/it]\u001b[A[I 2025-07-22 09:51:17,313] Trial 34 finished with value: 0.074169408418411 and parameters: {'bagging_fraction': 0.8464894451372804, 'bagging_freq': 4}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  80%|########  | 8/10 [03:54<00:52, 26.24s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  80%|########  | 8/10 [04:33<00:52, 26.24s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  90%|######### | 9/10 [04:33<00:29, 29.98s/it]\u001b[A[I 2025-07-22 09:51:55,493] Trial 35 finished with value: 0.07535710836796153 and parameters: {'bagging_fraction': 0.6734937222677351, 'bagging_freq': 3}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "bagging, val_score: 0.073438:  90%|######### | 9/10 [04:33<00:29, 29.98s/it]\u001b[A\n",
            "bagging, val_score: 0.073438:  90%|######### | 9/10 [04:53<00:29, 29.98s/it]\u001b[A\n",
            "bagging, val_score: 0.073438: 100%|##########| 10/10 [04:53<00:00, 27.15s/it]\u001b[A[I 2025-07-22 09:52:16,330] Trial 36 finished with value: 0.08758117379440715 and parameters: {'bagging_fraction': 0.4474374143418089, 'bagging_freq': 5}. Best is trial 4 with value: 0.07343816565629167.\n",
            "bagging, val_score: 0.073438: 100%|##########| 10/10 [04:53<00:00, 29.39s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "feature_fraction_stage2, val_score: 0.073438:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "feature_fraction_stage2, val_score: 0.073438:   0%|          | 0/3 [00:23<?, ?it/s]\u001b[A\n",
            "feature_fraction_stage2, val_score: 0.073438:  33%|###3      | 1/3 [00:23<00:46, 23.20s/it]\u001b[A[I 2025-07-22 09:52:39,548] Trial 37 finished with value: 0.07603385135929512 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.073438:  33%|###3      | 1/3 [00:23<00:46, 23.20s/it]\u001b[A\n",
            "feature_fraction_stage2, val_score: 0.073438:  33%|###3      | 1/3 [00:46<00:46, 23.20s/it]\u001b[A\n",
            "feature_fraction_stage2, val_score: 0.073438:  67%|######6   | 2/3 [00:46<00:23, 23.55s/it]\u001b[A[I 2025-07-22 09:53:03,349] Trial 38 finished with value: 0.07672817098483628 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.073438:  67%|######6   | 2/3 [00:47<00:23, 23.55s/it]\u001b[A\n",
            "feature_fraction_stage2, val_score: 0.073438:  67%|######6   | 2/3 [01:08<00:23, 23.55s/it]\u001b[A\n",
            "feature_fraction_stage2, val_score: 0.073438: 100%|##########| 3/3 [01:08<00:00, 22.40s/it]\u001b[A[I 2025-07-22 09:53:24,380] Trial 39 finished with value: 0.07571784004905471 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 4 with value: 0.07343816565629167.\n",
            "feature_fraction_stage2, val_score: 0.073438: 100%|##########| 3/3 [01:08<00:00, 22.68s/it]\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:   0%|          | 0/20 [00:21<?, ?it/s]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:   5%|5         | 1/20 [00:21<06:50, 21.60s/it]\u001b[A[I 2025-07-22 09:53:45,997] Trial 40 finished with value: 0.07540080758825257 and parameters: {'lambda_l1': 0.005241275776144935, 'lambda_l2': 0.4141980297556856}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:   5%|5         | 1/20 [00:21<06:50, 21.60s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:   5%|5         | 1/20 [00:43<06:50, 21.60s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  10%|#         | 2/20 [00:43<06:31, 21.73s/it]\u001b[A[I 2025-07-22 09:54:07,830] Trial 41 finished with value: 0.0734381659212046 and parameters: {'lambda_l1': 1.2445376211664214e-08, 'lambda_l2': 1.66899822205156e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  10%|#         | 2/20 [00:43<06:31, 21.73s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  10%|#         | 2/20 [01:05<06:31, 21.73s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  15%|#5        | 3/20 [01:05<06:12, 21.91s/it]\u001b[A[I 2025-07-22 09:54:29,956] Trial 42 finished with value: 0.07343816666710704 and parameters: {'lambda_l1': 1.1276391934451833e-07, 'lambda_l2': 1.1909039383928041e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  15%|#5        | 3/20 [01:05<06:12, 21.91s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  15%|#5        | 3/20 [01:26<06:12, 21.91s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  20%|##        | 4/20 [01:26<05:44, 21.51s/it]\u001b[A[I 2025-07-22 09:54:50,862] Trial 43 finished with value: 0.073438166042067 and parameters: {'lambda_l1': 2.9431960129129758e-08, 'lambda_l2': 1.6259005163502633e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  20%|##        | 4/20 [01:26<05:44, 21.51s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  20%|##        | 4/20 [01:48<05:44, 21.51s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  25%|##5       | 5/20 [01:48<05:23, 21.56s/it]\u001b[A[I 2025-07-22 09:55:12,496] Trial 44 finished with value: 0.07343816592554128 and parameters: {'lambda_l1': 1.5665067013990767e-08, 'lambda_l2': 1.5350553548321997e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  25%|##5       | 5/20 [01:48<05:23, 21.56s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  25%|##5       | 5/20 [02:10<05:23, 21.56s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  30%|###       | 6/20 [02:10<05:03, 21.71s/it]\u001b[A[I 2025-07-22 09:55:34,512] Trial 45 finished with value: 0.07343816595326116 and parameters: {'lambda_l1': 2.1126985554858848e-08, 'lambda_l2': 1.3599036255129169e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  30%|###       | 6/20 [02:10<05:03, 21.71s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  30%|###       | 6/20 [02:32<05:03, 21.71s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  35%|###5      | 7/20 [02:32<04:43, 21.82s/it]\u001b[A[I 2025-07-22 09:55:56,562] Trial 46 finished with value: 0.07343816590021453 and parameters: {'lambda_l1': 1.202150233219819e-08, 'lambda_l2': 1.3423662911271759e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  35%|###5      | 7/20 [02:32<04:43, 21.82s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  35%|###5      | 7/20 [02:53<04:43, 21.82s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  40%|####      | 8/20 [02:53<04:20, 21.71s/it]\u001b[A[I 2025-07-22 09:56:18,023] Trial 47 finished with value: 0.07343816590007321 and parameters: {'lambda_l1': 1.0950641886609097e-08, 'lambda_l2': 1.4206941016142587e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  40%|####      | 8/20 [02:53<04:20, 21.71s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  40%|####      | 8/20 [03:15<04:20, 21.71s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  45%|####5     | 9/20 [03:15<03:58, 21.65s/it]\u001b[A[I 2025-07-22 09:56:39,542] Trial 48 finished with value: 0.07343816609130482 and parameters: {'lambda_l1': 2.2506143491274466e-08, 'lambda_l2': 2.7534354053958458e-08}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  45%|####5     | 9/20 [03:15<03:58, 21.65s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  45%|####5     | 9/20 [03:37<03:58, 21.65s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073438:  50%|#####     | 10/20 [03:37<03:37, 21.75s/it]\u001b[A[I 2025-07-22 09:57:01,512] Trial 49 finished with value: 0.07343820148105593 and parameters: {'lambda_l1': 1.1485531625824794e-08, 'lambda_l2': 4.3267762657018214e-06}. Best is trial 4 with value: 0.07343816565629167.\n",
            "\n",
            "regularization_factors, val_score: 0.073438:  50%|#####     | 10/20 [03:37<03:37, 21.75s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  50%|#####     | 10/20 [03:58<03:37, 21.75s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  55%|#####5    | 11/20 [03:58<03:15, 21.77s/it]\u001b[A[I 2025-07-22 09:57:23,328] Trial 50 finished with value: 0.07341043209913636 and parameters: {'lambda_l1': 8.587393421629943e-06, 'lambda_l2': 2.8219826687938732e-06}. Best is trial 50 with value: 0.07341043209913636.\n",
            "\n",
            "regularization_factors, val_score: 0.073410:  55%|#####5    | 11/20 [03:58<03:15, 21.77s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  55%|#####5    | 11/20 [04:20<03:15, 21.77s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  60%|######    | 12/20 [04:20<02:52, 21.59s/it]\u001b[A[I 2025-07-22 09:57:44,516] Trial 51 finished with value: 0.0734382121053883 and parameters: {'lambda_l1': 4.511633283390562e-06, 'lambda_l2': 1.3307265327110688e-06}. Best is trial 50 with value: 0.07341043209913636.\n",
            "\n",
            "regularization_factors, val_score: 0.073410:  60%|######    | 12/20 [04:20<02:52, 21.59s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  60%|######    | 12/20 [04:38<02:52, 21.59s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  65%|######5   | 13/20 [04:38<02:23, 20.55s/it]\u001b[A[I 2025-07-22 09:58:02,658] Trial 52 finished with value: 0.13285394318770366 and parameters: {'lambda_l1': 7.208248404143627, 'lambda_l2': 9.38183196539146e-07}. Best is trial 50 with value: 0.07341043209913636.\n",
            "\n",
            "regularization_factors, val_score: 0.073410:  65%|######5   | 13/20 [04:38<02:23, 20.55s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  65%|######5   | 13/20 [05:08<02:23, 20.55s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073410:  70%|#######   | 14/20 [05:08<02:21, 23.51s/it]\u001b[A[I 2025-07-22 09:58:33,025] Trial 53 finished with value: 0.07343817911650088 and parameters: {'lambda_l1': 1.5996887058400218e-06, 'lambda_l2': 1.0739852713634799e-07}. Best is trial 50 with value: 0.07341043209913636.\n",
            "\n",
            "regularization_factors, val_score: 0.073410:  70%|#######   | 14/20 [05:08<02:21, 23.51s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  70%|#######   | 14/20 [05:44<02:21, 23.51s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  75%|#######5  | 15/20 [05:44<02:16, 27.31s/it]\u001b[A[I 2025-07-22 09:59:09,144] Trial 54 finished with value: 0.07320582637534587 and parameters: {'lambda_l1': 1.464541374160437e-06, 'lambda_l2': 0.00013758501010691882}. Best is trial 54 with value: 0.07320582637534587.\n",
            "\n",
            "regularization_factors, val_score: 0.073206:  75%|#######5  | 15/20 [05:44<02:16, 27.31s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  75%|#######5  | 15/20 [06:14<02:16, 27.31s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  80%|########  | 16/20 [06:14<01:52, 28.06s/it]\u001b[A[I 2025-07-22 09:59:38,936] Trial 55 finished with value: 0.07441402604585243 and parameters: {'lambda_l1': 5.305549984554552e-06, 'lambda_l2': 0.00066068472217203}. Best is trial 54 with value: 0.07320582637534587.\n",
            "\n",
            "regularization_factors, val_score: 0.073206:  80%|########  | 16/20 [06:14<01:52, 28.06s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  80%|########  | 16/20 [06:41<01:52, 28.06s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  85%|########5 | 17/20 [06:41<01:22, 27.61s/it]\u001b[A[I 2025-07-22 10:00:05,511] Trial 56 finished with value: 0.0738119034820354 and parameters: {'lambda_l1': 0.0005192773863296144, 'lambda_l2': 0.000117615422871922}. Best is trial 54 with value: 0.07320582637534587.\n",
            "\n",
            "regularization_factors, val_score: 0.073206:  85%|########5 | 17/20 [06:41<01:22, 27.61s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  85%|########5 | 17/20 [07:03<01:22, 27.61s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  90%|######### | 18/20 [07:03<00:52, 26.07s/it]\u001b[A[I 2025-07-22 10:00:27,992] Trial 57 finished with value: 0.0732057006499554 and parameters: {'lambda_l1': 6.194258120577604e-07, 'lambda_l2': 0.00012299581974464658}. Best is trial 57 with value: 0.0732057006499554.\n",
            "\n",
            "regularization_factors, val_score: 0.073206:  90%|######### | 18/20 [07:03<00:52, 26.07s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  90%|######### | 18/20 [07:24<00:52, 26.07s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073206:  95%|#########5| 19/20 [07:24<00:24, 24.56s/it]\u001b[A[I 2025-07-22 10:00:49,039] Trial 58 finished with value: 0.07333173953283534 and parameters: {'lambda_l1': 7.220522812488134e-07, 'lambda_l2': 0.00021658489526550414}. Best is trial 57 with value: 0.0732057006499554.\n",
            "\n",
            "regularization_factors, val_score: 0.073206:  95%|#########5| 19/20 [07:24<00:24, 24.56s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073062:  95%|#########5| 19/20 [07:46<00:24, 24.56s/it]\u001b[A\n",
            "regularization_factors, val_score: 0.073062: 100%|##########| 20/20 [07:46<00:00, 23.83s/it]\u001b[A[I 2025-07-22 10:01:11,158] Trial 59 finished with value: 0.07306171886067706 and parameters: {'lambda_l1': 7.3427863750627e-07, 'lambda_l2': 0.0002931636750276039}. Best is trial 59 with value: 0.07306171886067706.\n",
            "regularization_factors, val_score: 0.073062: 100%|##########| 20/20 [07:46<00:00, 23.34s/it]\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:   0%|          | 0/5 [00:20<?, ?it/s]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  20%|##        | 1/5 [00:20<01:20, 20.02s/it]\u001b[A[I 2025-07-22 10:01:31,204] Trial 60 finished with value: 0.09060870615956765 and parameters: {'min_child_samples': 50}. Best is trial 59 with value: 0.07306171886067706.\n",
            "\n",
            "min_child_samples, val_score: 0.073062:  20%|##        | 1/5 [00:20<01:20, 20.02s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  20%|##        | 1/5 [00:37<01:20, 20.02s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  40%|####      | 2/5 [00:37<00:55, 18.40s/it]\u001b[A[I 2025-07-22 10:01:48,463] Trial 61 finished with value: 0.12659394038410623 and parameters: {'min_child_samples': 100}. Best is trial 59 with value: 0.07306171886067706.\n",
            "\n",
            "min_child_samples, val_score: 0.073062:  40%|####      | 2/5 [00:37<00:55, 18.40s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  40%|####      | 2/5 [01:03<00:55, 18.40s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  60%|######    | 3/5 [01:03<00:43, 21.98s/it]\u001b[A[I 2025-07-22 10:02:14,710] Trial 62 finished with value: 0.0734593469544832 and parameters: {'min_child_samples': 5}. Best is trial 59 with value: 0.07306171886067706.\n",
            "\n",
            "min_child_samples, val_score: 0.073062:  60%|######    | 3/5 [01:03<00:43, 21.98s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  60%|######    | 3/5 [01:27<00:43, 21.98s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  80%|########  | 4/5 [01:27<00:22, 22.74s/it]\u001b[A[I 2025-07-22 10:02:38,625] Trial 63 finished with value: 0.07483640998853988 and parameters: {'min_child_samples': 10}. Best is trial 59 with value: 0.07306171886067706.\n",
            "\n",
            "min_child_samples, val_score: 0.073062:  80%|########  | 4/5 [01:27<00:22, 22.74s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062:  80%|########  | 4/5 [01:48<00:22, 22.74s/it]\u001b[A\n",
            "min_child_samples, val_score: 0.073062: 100%|##########| 5/5 [01:48<00:00, 22.26s/it]\u001b[A[I 2025-07-22 10:03:00,033] Trial 64 finished with value: 0.0756617319416104 and parameters: {'min_child_samples': 25}. Best is trial 59 with value: 0.07306171886067706.\n",
            "min_child_samples, val_score: 0.073062: 100%|##########| 5/5 [01:48<00:00, 21.77s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRzES3x3h39u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebedab3f-6d58-4be6-b985-766bec0ba9cb"
      },
      "source": [
        "print(\"Best score:\", 1 - tuner.best_score)\n",
        "best_params = tuner.best_params\n",
        "\n",
        "print(\"Best Params: \")\n",
        "for key, value in best_params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score: 0.926938281139323\n",
            "Best Params: \n",
            "    objective: binary\n",
            "    verbosity: -1\n",
            "    boosting_type: gbdt\n",
            "    feature_pre_filter: False\n",
            "    lambda_l1: 7.3427863750627e-07\n",
            "    lambda_l2: 0.0002931636750276039\n",
            "    num_leaves: 31\n",
            "    feature_fraction: 0.4\n",
            "    bagging_fraction: 1.0\n",
            "    bagging_freq: 0\n",
            "    min_child_samples: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrsH156viBTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6553fd7e-e185-40ee-933b-eba4151c66de"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# 訓練データとテストデータを設定\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data = lgb.Dataset(X_test, label=y_test)\n",
        "\n",
        "# ハイパーパラメータ探索で特定した値を設定\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "    'lambda_l1': best_params['lambda_l1'],\n",
        "    'lambda_l2': best_params['lambda_l2'],\n",
        "    'num_leaves': best_params['num_leaves'],\n",
        "    'feature_fraction': best_params['feature_fraction'],\n",
        "    'bagging_fraction': best_params['bagging_fraction'],\n",
        "    'bagging_freq': best_params['bagging_freq'],\n",
        "    'min_child_samples': best_params['min_child_samples']\n",
        "}\n",
        "\n",
        "# 訓練の実施\n",
        "gbm = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    num_boost_round=100\n",
        ")\n",
        "\n",
        "# テスト用データを使って予測する\n",
        "preds = gbm.predict(X_test)\n",
        "# 返り値は確率になっているので四捨五入する\n",
        "pred_labels = np.rint(preds)\n",
        "# 正解率と混同行列の出力\n",
        "print(\"Accuracy: {:.5f} %\".format(100 * accuracy_score(y_test, pred_labels)))\n",
        "print(confusion_matrix(y_test, pred_labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.84058 %\n",
            "[[729  10]\n",
            " [  2 294]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## なぜSubjectが寄与しているのか\n",
        "\n",
        "これは、spamメールはあまりSubjectを書かず、非spamメールはしっかりとSubjectを書くからと推測できる\n",
        "\n",
        "memo:\n",
        "あとで書く"
      ],
      "metadata": {
        "id": "3k5I8JfomL90"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyVAAWRyjzXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "a8d29672-6df3-45a7-d58b-94d053139357"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "lgb.plot_importance(gbm, figsize=(12, 6), max_num_features=10)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4xugBNu57WA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594109d3-45fa-4cb4-d66d-7890bc677e22"
      },
      "source": [
        "spam_rows = (df.label == '1')\n",
        "spam_data = df[spam_rows]\n",
        "\n",
        "count = 0\n",
        "for i in spam_data['text']:\n",
        "    count = count + i.count('subject')\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGDnU49e6ji4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9737762a-61dc-4700-a74e-15c39a50cdb2"
      },
      "source": [
        "legit_rows = (df.label == '0')\n",
        "legit_data = df[legit_rows]\n",
        "\n",
        "count = 0\n",
        "for i in legit_data['text']:\n",
        "    count = count + i.count('subject')\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2733\n"
          ]
        }
      ]
    }
  ]
}